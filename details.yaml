email: kanaparthinayan@gmail.com
integrations:
  hubspot:
    user_id: dghjdg
  mailchimp:
    user_id: dghj
  salesforce:
    user_id: dghjdghj
knowledge_base:
- content: "1\nA systematic review of the use of Deep Learning in\nSatellite Imagery\
    \ for Agriculture\nBrandon Victor , Aiden Nibali , Zhen He\nAbstract\u2014Agriculturalresearchisessentialforincreasingfood\
    \ and thus applying them across huge areas [61]. Compared\nproduction to meet\
    \ the needs of a rapidly growing human to ground-level images, satellite images\
    \ have lower spatial\npopulation.Collectinglarge quantitiesof agricultural datahelps\n\
    3 resolutions, higher spectral resolution and are typically pro-\nto improve decision\
    \ making for better food security at various\n2 cessed to obtain re\uFB02ectances\
    \ (a physical measurement), so\nlevels: from international trade and policy decisions,\
    \ down to\n0\nindividual farmers. Recently, there has been great interest in these\
    \ algorithms have typically operated per-pixel, ignoring\n2\nusingsatelliteimagestocollectagriculturaldataoverhugeareas\
    \ the contextual or spatial information around them. This is\n \nc and at different\
    \ scales. As more satellite images have become in stark contrast with generic\
    \ computer vision research -\ne available at various different spatial, spectral\
    \ and temporal\nand Convolutional Neural Networks (CNNs) in particular -\nD resolutions\
    \ many researchers have sought to utilise these extra\nwhich has always emphasised\
    \ learning spatial relationships.\n  dimensions \u2014 along with the recent successes\
    \ in deep learning\n5 \u2014 to effectively translate from satellite images to\
    \ agriculturally However,the greatsuccesses of genericcomputervision have\n1 relevant\
    \ data. This systematic review of 193 studies describes encouragedresearcherstotransferthese\
    \ popularalgorithmsto\n \n  a taxonomy of the various ways deep learning is being\
    \ used many application areas [6], includingEarth Observation tasks\n]\non satellite\
    \ images for agriculture and compares it to generic\nV [70,12],andwe\uFB01ndthatthistrendhasalsosuccessfullybeen\n\
    computervision.Thebreadthof agriculturaltasksareidenti\uFB01ed\nC and the trends\
    \ within each analysed. As an overall trend, adopted for agricultural tasks.\n\
    . Convolutional Neural Networks (CNNs) consistently outperform In this review,\
    \ we systematically identi\uFB01ed 193 studies\ns older machine learning methods,\
    \ whereas Long Short-Term at the intersection of deep learning techniques, satellite\
    \ im-\nc\n[ Memory (LSTM) models do not. Unfortunately, there is a lack agery\
    \ and agricultural applications (see Section II). To our\n  ofdirectcomparisonsbetweenmethodsforallagriculturaltasks,\n\
    \  knowledge this is the \uFB01rst such systematic review. We start\n2 highlighting\
    \ the need for benchmarking on public datasets.\nby describing how satellite images\
    \ differ from ground-based\nv\n2 Index Terms\u2014Systematic Review, Deep learning,\
    \ Satellite im- images, and thus how deep learning approaches on satellite\nagery,\
    \ Agriculture, Computer Vision\n7 images typically differ (Section III). We highlight\
    \ relevant\n2 modern deep learning methods and architectures (Section IV)\n1\n\
    and thus describe a taxonomy of methods for how each\n0 I. INTRODUCTION\nmodelisactuallybeingapplied,speci\uFB01\
    callytosatelliteimages\n0. THEREarebigagriculturalchallengescoming.Thehuman (Section\
    \ V). We identify various different agricultural tasks,\n1 population is expected\
    \ to increase signi\uFB01cantly in the\nanddescribe them eachin moredetail(Section\
    \ VI), including\n2 next decades [115], which will require an estimated global\n\
    thetrendswithineachwithrespecttothetaxonomyofmethods\n2\nyield increase of 25-70%[47],\
    \ along with a changing climate\n: from earlier.\nv bringing additional challenges\
    \ [111] and the need to reduce\nWefoundthattherewereveryfewexamplesofmoderndeep\n\
    Xi the environmentalimpact of agriculture [36]. learning methods from before 2020,\
    \ but since then they have\nRemote sensing is an extremely useful tool because\
    \ it\nr becomeincreasinglypopular,withanexplosionofresearchin\na provides a non-destructive\
    \ and non-intrusive way to monitor\njust the last few years, mostly in crop segmentation\
    \ and yield\nagricultural \uFB01elds simultaneously at a \uFB01ne level of detail\
    \ and\nprediction. We found that where spatial ConvolutionalNeural\nacross wide\
    \ areas and times. This makes it a technology that\nNetworks (CNNs) were used,\
    \ they consistently outperformed\ncan be used for fast and targeted interventionsat\
    \ a farm-level\ntraditional machine learning methods across all tasks, but,\n\
    [40], regional studies of ecological change over time [94],\nspeci\uFB01cally\
    \ in the case of yield prediction, this was not\ncounty-level yield prediction\
    \ for logistics [31] and interna-\ntrue of Long Short-Term Memory models (LSTMs).\
    \ There\ntional trade decisions [71]. To achieve these, there are many\nwere few\
    \ papers that included attention-based models (both\nsources of worldwide satellite\
    \ imagery freely available to the\nViT[117] and custom architectures [34]), but\
    \ there was no\npublic and the most popular for agricultural purposes are:\nconsistentimprovement.Therewere\
    \ manyworksthatdirectly\nSentinel [113, 24], Landsat [95] and MODIS. Each of these\n\
    followed generic computer vision research, simply applying\nsatellite programs\
    \ store and manage enormous collections of\npopulararchitectures,andmanythatdidnot,butunlikegeneric\n\
    historical worldwideimagery,e.g. Sentineladded 7.34 PiB of\ncomputer vision research,\
    \ very few works utilised benchmark\nimagery to their archive in 2021 [102].\n\
    datasets or compared results with others at all. There were\nMuch research has\
    \ gone into translating these satellite many works that utilised extra spectral\
    \ data available in\nimages into agriculturally relevant information [38, 128,\
    \ 55],\nsatelliteimages,butveryfewusedthegeolocationdataortook\nadvantage of the\
    \ multi-scale inputs available, so we conclude\nBrandon Victor, Aiden Nibali and\
    \ Zhen He work within the School of\nwithrecommendationsforfutureresearchdirectionstoaddress\n\
    Computing, Engineering andMathematical Sciences atLaTrobeUniversity,\nMelbourne,\
    \ Victoria, Australia these gaps.2\nII. SEARCH STRATEGY often signi\uFB01cantly\
    \ better. Almost all satellite imagery have at\nleast 4 colour channels (red,\
    \ green, blue and near-infrared),\nTo create an initial list of papers, we used\
    \ a search query\nmany have more than 10 colour channels (e.g. Sentinel-2),\n\
    for Clarivate\u2019s Web of Science. To broadly \uFB01nd papers at the\nand some\
    \ have over 100 different colour channels [105],\nintersection of deep learning,\
    \ satellite images and agriculture,\nprovidingsigni\uFB01cantlymoreinformationperpixelthantypical\n\
    we used both generic and speci\uFB01c terms for each (see Table\nground-based\
    \ sources. Additionally, satellite image sensors\nI). For deep learning, this\
    \ was speci\uFB01c algorithm names. For\nare calibrated to obtain functions for\
    \ converting from sensor\nagriculture this was speci\uFB01c crop names from the\
    \ Cropland\nbrightness to re\uFB02ectance - a physical property of the imaged\n\
    Data Layer [116]. The resultant tagged library of studies is\nsurface,independentofilluminationandsensor-whichallows\n\
    available as supplementary materials.\nquantitative analysis of the Earth\u2019\
    s surface.\nThis initial search yielded 770 studies. We performed an\nTheoretically,\
    \ with a suf\uFB01ciently precise sensor - and con-\ninitial rapid pass through\
    \ the collection of studies to \uFB01lter out\nverting to re\uFB02ectance values\
    \ - all surfaces could be uniquely\nstudiesthatwerenotattheintersectionofdeeplearning,satel-\n\
    identi\uFB01ed by matching each pixel to a spectral signature\nlite imagery and\
    \ agriculture, ultimately yielding 193 studies.\nmeasuredinalab.Indeed,thisidealisthebasisofmanyhand-\n\
    The majority of these studies were for crop segmentationand\ncrafted models (e.g.\
    \ Linear Mixture Model [2]). However,\nyield prediction, thus, the studies for\
    \ those tasks were further\nsuch a precise sensor does not exist, and signi\uFB01\
    cant noise\n\uFB01ltered as follows:\nis introduced by the lack of spatial and\
    \ spectral resolutions,\n\u2022 2020andearlier:studyisincludedifithasatleastxcita-\n\
    atmosphericeffectsandothererrorsin calculatingre\uFB02ectance,\ntions on Google\
    \ Scholar (x=50 for crop segmentation;\nleading to the dominance of machine learning\
    \ algorithms to\nx=25 for yield prediction)\nlearnthevariedappearancesofsurfacesfromthedata[67,58].\n\
    \u2022 Jan 2021 - October 2022: all were included.\nTherearecurrentlymanysourcesoffreelyavailablesatellite\n\
    WedidnotincludemethodsusingUAVimagerybecausewe\nimagerywithworldwidecoveragetotrainthesealgorithms.In\n\
    were interested in methods for resolving the tension between\nthe reviewed studies,\
    \ the most common were:\nobjectsizeandpixelsizeinsatelliteimagery.Forcropsegmen-\n\
    \u2022 Moderate Resolution Imaging Spectroradiometer\ntation studies (Section\
    \ VI-A), we only include studies which\n(MODIS) imagery at 250-1000m resolution\
    \ which has\nused multiple agricultural classes. Soil monitoring studies\nbeen\
    \ publicly available since 2000, along with many\n(SectionVI-B)oftenonlyimpliedanagriculturalsigni\uFB01\
    cance,\nmodel-based maps, such as land surface temperatures,\nbut, since soil\
    \ has such a strong in\uFB02uence on agriculture, and\nevapotranspirationand leaf\
    \ area index (LAI).\nrelatively few studies, we include all found soil monitoring\n\
    \u2022 Landsat imagery which has been freely available to the\nstudies, even if\
    \ they did not explicitly have an agricultural\npublic since 2008 [137], of which\
    \ most reviewed studies\nmotivation.\nused Landsat-8 imagery at 30m resolution.\n\
    Although this review is systematic, it is not exhaustive,\n\u2022 Sentinel imagery\
    \ from the Sentinel program of the Eu-\nand not just because of the above \uFB01\
    ltering. By limiting the\nropean Space Agency which has provided optical im-\n\
    review to studies indexed by Clarivate\u2019s Web of Science, we\nageryat10-60mresolutionandSyntheticApertureRadar\n\
    are deliberately selecting for higher pro\uFB01le works than if we\n(SAR) imagery\
    \ at 5-40m resolution since 2014.\nincludedsearchesacross all publishedliterature.Additionally,\n\
    The resolution of these data sources can dictate the res-\nthe search terms may\
    \ not reveal all possible relevant studies,\nolution at which analysis can be\
    \ performed; for example,\nhowever, we believe that they are suf\uFB01cient to\
    \ return a repre-\ncounty-level yield prediction always uses MODIS imagery\nsentative\
    \ sample of all relevant studies.\nand \uFB01eld-level yield prediction always\
    \ uses Landsat/Sentinel\nThere was also some inconsistency in terminology in the\n\
    imagery. These are obvious pairings because MODIS pixels\nreviewedstudies.Intheinterestofclarity,andtoassistanyone\n\
    are largerthan individual\uFB01elds, andimagesof entirecounties\nunfamiliar with\
    \ these terms, the variations are summarised in\nusingLandsat/Sentinelimagerywouldrequireanunreasonable\n\
    Table II.\namount of disk space and computation time. At the coarser\nresolutions,\
    \ there was a strong preference in the reviewed\nIII. SATELLITEIMAGES articles\
    \ to pose the problem as just time series analysis,\nObjects imaged by satellites\
    \ are typically signi\uFB01cantly rather than a spatio-temporal one. Further,\
    \ in several works\nsmaller than the ground spatial distance (GSD) covered by\
    \ [53, 103, 78] and datasets like LUCAS [19], the problem is\neach pixel. For\
    \ example, the colour of each pixel in a satel- posedasasingle-pixelproblem,onlyprovidinglabelsforaset\n\
    lite image of farmland might be aggregated from hundreds, of sparsely distributed\
    \ points. Although this doesn\u2019t preclude\nthousands or even millions of individual\
    \ plants. This massive the use of CNNs [52], such a dataset discourages it.\n\
    differencein scale between objectand pixelsizes has encour- Spatial resolution\
    \ in satellite imagery has increased over\naged researchers to focus on understanding\
    \ the contents of the years, such that some commercial satellite providers now\n\
    individual pixels with per-pixel algorithms [8, 9], rather than sell images with\
    \ resolution as \uFB01ne as 34cm per pixel, a\nthe typical computer vision approaches\
    \ which primarily use resolution suf\uFB01ciently \uFB01ne to detect individual\
    \ trees from\nthe structured pattern of multiple spatially-related pixels to satellite\
    \ images [37, 65, 30, 66]. This increased resolution\nunderstand an image [32,\
    \ 123]. has encouragedsatellite imagery analysis to utilise the spatial\nWhile\
    \ the spatial resolution relative to the imaged objects information - as in generic\
    \ computer vision - as well as the\nis much worse for satellite imagery, the spectral\
    \ resolution is higher spectral resolution and re\uFB02ectance calibration typically3\n\
    TABLEI\nTHESEARCHTERMSUSEDINTHEQUERYFORCLARIVATE\u2019SWEBOFSCIENCE.THEREISAN\"\
    AND\"BETWEENEACHTOP-LEVELCONCEPT(I.E.[DEEP\nLEARNING]AND[SATELLITE]AND[AGRICULTURE]),ANDAN\"\
    OR\"BETWEENEACHTERMUNDERTHAT.THELISTOFSPECIFICCROPSCOMESFROM\nTHECDL[116].THESEARCHINTERFACEENFORCESALIMITTOTHENUMBEROF\"\
    ALL\"SEARCHTERMS,SOONLYTHEABSTRACTANDTOPICWERE\nSEARCHEDFORSPECIFICAGRICULTURETERMS.THEFULLLISTOFAGRICULTURALTERMSISAVAILABLEINTHESUPPLEMENTARYMATERIALS\n\
    SECTION.\nDeep Learning Satellite Agriculture\nAll All All Abstract Topic\nDeepLearn*,CNN,RNN,LSTM,\
    \ Satellite Farm, Wheat, Corn, Maize, Orchard, Coffee, Vineyard, *wheat, *\uFB02\
    ower*,\nGRU,Transformer,NeuralNetwork, Agri*, Soy,Rice,Cotton,Sorghum,Peanut*,Tobacco,Bar-\
    \ *berries, *melon*,\nDeepBeliefNetwork, Autoencoder Crop ley,Grain,Rye,Oat,Millet,Speltz,Canola,...[+52\
    \ *berry\nmore]\nTABLEII\nSOMEDEFINITIONSFOR(SOMETIMESINCONSISTENT)TERMINOLOGYFOUNDINTHELITERATURE.\n\
    Words Idea\nRadiative transfer;re\uFB02ectance; backscatter Re\uFB02ectanceistheproportionoflightwhichre\uFB02\
    ectsoffofasurface.Thisisaphysicalproperty\nof the surface, and can be measured\
    \ in a laboratory. Radiative transfer models describe the\nphysical process of\
    \ re\uFB02ectance, while backscatter is re\uFB02ectance that is the result of\
    \ arti\uFB01cial\nlighting, typically microwaves.\nSub-pixel fractional estimation;\
    \ Linear Unmix- Amodelofapixelasbeingsomeproportionofjustafewtypesoflandcover,andthusevery\n\
    ingModel;LinearMixture Model pixel\u2019scolourisexplainable asan(oftenlinear)combinationofthesecovertypes(seeSection\n\
    III)\nDownscale; upsample;\uFB01nerresolution Downscaling and upsampling can have\
    \ the same meaning because there is a con\uFB02ict in\nterminologybetweenremotesensingscientistsandcomputerscientists,withinversemeanings.\n\
    Inthisreview, wehaveused\u201Ccoarser\u201D or\u201C\uFB01ner\u201Dtoavoidconfusion.\n\
    Multitemporalimages;timeseries;SatelliteIm- Indicates the use of temporal data.\
    \ Generally, stacked images of the same location over\nageTimeSeries (SITS);temporaldata\
    \ weeks/months (seeSection V)\nMulti-layerperceptron(MLP);Arti\uFB01cialNeural\
    \ Although ANN can technically refer toany Neural Network, itis typically usedto\
    \ refer to a\nNetwork(ANN);DeepNeuralNetwork(DNN) smallMLP.Generally, DNNrefers\
    \ toanMLP,butaDCNNreferstoaCNNspeci\uFB01cally.\nModelinversion Training a statistical\
    \ model to predict the inputs of a theoretical model from either ground-\nmeasuredoutputs,oroutputsofthetheoretical\
    \ modelitself.Agoodsummaryofthewaysthis\nisusedisgivenin[128].\nObject-based;\
    \ \uFB01eld-based; parcel-based; super- Usingaggregated colourinformation acrossawholeobjector\uFB01\
    eldorparcelorsuperpixel for\npixel prediction.\nused for satellite images (e.g.\
    \ [26, 99, 121]). We note that performance. In all studies reviewed in all tasks\
    \ except yield\nalthough spatio-temporal input has the richest information, prediction,moderndeeplearningmethodsoutperformedtradi-\n\
    it is not always available. For example, very-high resolution tionalmachinelearningmethods.Inyieldprediction,2DCNNs\n\
    commercial satellite imagery is expensive and sparsely col- consistently outperformed\
    \ traditional machine learning meth-\nlected, thus most studies using commercial\
    \ satellite imagery ods, but LSTMs did not.\noperated on a relatively small number\
    \ of individual images In the literature, various algorithms are called \u201C\
    deep learn-\n(e.g. [90, 18, 101]). ing\u201D. In this review, we refer to three\
    \ main types of modern\ndeep learning: CNNs, RNNs and Attention. With a decade\n\
    since AlexNet [60], and an explosion of research, Convo-\nIV. DEEPLEARNING\nlutional\
    \ Neural Networks (CNNs) are the current de facto\nIn many domains, machine learning\
    \ has found accurate standard in generic computer vision tasks. Recurrent Neural\n\
    relationships in spite of many variations in appearance and Networks (RNNs) are\
    \ a common deep learning method for\nmuch noise. The data-drivennature of machine\
    \ learningtech- sequence modelling; almost all cases of which use either\nniqueshandlessuchvariationsandmodelsarbitrarilycomplex\
    \ a Long Short-term Memory (LSTM) or a Gated Recurrent\nrelationships while simultaneously\
    \ including tools to prevent Unit (GRU) version of RNNs. \u201CAttention\u201D\
    \ can mean many\nover\uFB01ttingtothenoise.Wefoundthatinsingle-pixelproblems,\
    \ different things; here we will use it to mean, speci\uFB01cally,\nRandomForests(RFs),\
    \ SupportVectorMachines(SVMs)and multi-headattention as describedby [117], as\
    \ this is the basis\nMulti-layerPerceptrons(MLPs)weregenerallyclosecompeti- for\
    \ the recently popularised Vision Transformers [23] which\ntors,witheachmethodbeingmoreaccurateindifferentstudies\
    \ have outperformed CNNs on recent ImageNet competitions.\nin roughly equal proportions\
    \ (e.g. [29, 54, 103]). In this review we use \u201Cdeep learning\u201D to mean\
    \ any neural\nComparedtoothermachinelearningmethods,deeplearning networkmethod,and\u201C\
    moderndeeplearning\u201DtoexcludeMLP-\nis known to be able to construct signi\uFB01\
    cantly more complex only algorithms. We will not discuss the technical details\
    \ of\nmodels[39],allowingthemtobemorerobusttonoisytraining these deep learning\
    \ algorithmsin this review; instead we will\ndata. Another major bene\uFB01t of\
    \ deep learning models is that mention the most signi\uFB01cant modern advances\
    \ and refer the\nmanual feature extraction is no longer required because the reader\
    \ to existing explanations for more details [39, 12, 55].\nmodel learns to create\
    \ its own features. This comes at the The ImageNet classi\uFB01cation dataset\
    \ [21] has had an enor-\nprice of requiring larger datasets to observe this improved\
    \ mous in\uFB02uence on the trajectory of computer vision research.4\ncontextualcluesin\
    \ itsprediction.Thus,we createa taxonomy\nof input types to help understand how\
    \ satellite images are\nbeing used differently across studies.\nIn Figure 1, we\
    \ highlight the initial data shapes used\nin existing literature: a single pixel\
    \ (type P-x), a temporal\nsequence of pixels (type T-x), a single image (type\
    \ S-x) or\na temporalsequenceof images(type ST-x). Then,in Figure2\nwedescribeourtaxonomyofdifferentinterpretationsofthose\n\
    data shapes which authors have used to structure their data\nfor use in modern\
    \ deep learning algorithms. We name these\ninterpretationsby their initial data\
    \ shape as the \uFB01rst character\nandtheirinterpretedshapeas the secondcharacter.Theinitial\n\
    data shapes can then be interpreted as one of: a vector of\nfeatures (type X-f),\
    \ a sequence of pixels (type X-s), a single\nimage(typeX-i),animagecube(typeX-c),oranobject(type\n\
    X-o). For example, type T-s denotes an interpretation of a\ntemporalsequenceofpixels(T)formodelsthattakeadvantage\n\
    of the fact that it is a sequence (s).\nTraditional machine learning methods such\
    \ as Random\nForests (RFs), Support Vector Machines (SVMs) and Multi-\nFig. 1.\
    \ Depending on the images available, a problem can be posed as a layer Perceptrons\
    \ (MLPs) generally require a 1D vector of\nrelationship between a single pixel\
    \ input (blue cell) from a single image\nfeaturesasinput(typesP-fandT-f),butmoderndeeplearning\n\
    (yellowgridofcells)andeachprediction(redcell),oritcanincludecontextual\npixelsfromspatialand/ortemporaldomains(bluegridofcells).Thebottom\
    \ methodsgenerallyhaveamulti-dimensional/sequentialinter-\nrightsituation isalsocalledspatio-temporal\
    \ (ST)data. pretation of the data (see Table III). Several papers reframed\nthedatatomakespeci\uFB01\
    cmoderndeeplearningmethodsmore\nobviouscandidates.Inparticular,treatingspectralinformation\n\
    It is common - when deep learning is applied to a new\nas a sequence in order\
    \ to apply sequence analysis algorithms.\ndomain - for authors to use architecturesthat\
    \ achieved a high\nFor example, type P-f and type P-s have precisely the same\n\
    rankintheImageNetcompetition.Inparticular,AlexNet[60],\ndata, but by interpreting\
    \ a single pixel (type P) as a sequence\nVGG [104]andResNet [44] havereceivedthemostattention.\n\
    of colours (type P-s), 1DCNNs and LSTMs become obvious\nSimilarly for segmentation\
    \ models, models that performed\nmodelchoices. Similarly,temporaldata (type T)\
    \ can be inter-\nwell on the MS COCO and PASCALVOC datasets have been\npreted\
    \ as a spectral/temporal \u201Cimage\u201D (type T-i), and spatial\nadopted. The\
    \ most popular segmentation architectures are\ndata(typeS)canbeinterpretedasaspatial/spectralimagecube\n\
    based on UNet [93] and DeepLabv3 [17].\n(typeS-c)tousehigherdimensionalCNNkernels.Interpreting\n\
    Two of the most signi\uFB01cant innovations of modern deep\nspectral information\
    \ as a sequence is rarely theoretically\nlearningare focusedaroundtrainingdeepermodels:skip\
    \ con-\njusti\uFB01ed, but multiple authors noted improved performance\nnections\
    \ [44] and inter-layer normalisation (e.g. BatchNorm\ndoing so [61, 20, 101].\n\
    [50], LayerNorm [4], etc). These two ideas have been almost\nSometimestheinterpretationcomesaboutbecauseoflabels.\n\
    universally adopted by all popular modern deep learning\nIn yield prediction especially\
    \ (see Section VI-E), ground\narchitectures, and with modern programming libraries\
    \ these\nlabels are often annotated at a \uFB01eld or county or country\nare easily\
    \ incorporated into custom architectures created by\nlevel (collectively, \u201C\
    objects\u201D) which are shown as types S-o\nindividual studies (e.g. [5, 33]).\
    \ Many works reviewed also\nand ST-o, depending on whether temporal data was included.\n\
    used Dropout [46]; another popular addition to training deep\nIn such cases, the\
    \ relationship between the colour in the\nlearning models for training more robust\
    \ models.\npixels and the \uFB01nal prediction are not necessarily present in\n\
    each and every pixel contained within the the object, so a\nV. COMMON METHODS\n\
    common method is to aggregate the information within an\nA. Taxonomy\nobject before\
    \ a model sees the data. Most commonly, the\nSatellite images are quantised measurements\
    \ of our real colour information is averaged, however [57] showed good\nworldalongmultipledimensions:onespectral,twospatialand\
    \ performance by computing a colour histogram per county\nonetemporal.Inthebestcaseeverypredictionisbasedona4-\
    \ instead. These interpretations remove the spatial component,\ndimensional data\
    \ cube of spatio-temporal (ST) data, but such so after aggregation, S-o is subsequently\
    \ re-interpreted as\ndata can be computationally expensive to use or impractical\
    \ either P-f or P-s, and ST-o is subsequently re-interpreted as\nto obtain, so\
    \ many works operate on data without a spatial or one of T-f, T-s or T-i.\ntemporal\
    \ (or both) dimension. The shape of input data puts It is worth noting that a\
    \ single 2D image is actually a\nimportantemphasisandlimitationsonmodelstrainedonsuch\
    \ three-dimensionaltensorofdata:twospatialandonespectral.\ndata: for example,\
    \ LSTMs are usually applied by processing A 2DCNN operates on this 3D data by\
    \ treating the spectral\neach temporal sequence of pixels independently, which\
    \ can informationasthe\u201Cchannels\u201Ddimension.Similarly,atemporal\nobservechangesovertime,butwouldn\u2019\
    tbeabletousespatial stack of 2D images is a four-dimensional tensor of data: two5\n\
    Fig.2. Thedatacanbeinterpreted indifferentwaystoallowtheuseofdifferentmodels.Eachofthesedatashape/interpretations\
    \ pairsisgivenanamelike\nTypeX-xtodenotetheoriginal typeandit\u2019sinterpretation.\
    \ The\uFB01rstcolumnofinterpretations havenotemporalcomponent, whilethesecondcolumndoes.\n\
    The top row treat the input as a 1D vector with no special ordering. The second\
    \ row treat the input as a 1D sequence. The third row treat the input as an\n\
    image.Thefourthrowtreattheinputasanimagecube.Thelastrowaggregatenon-squarespatialinformationtoproduce\uFB01\
    xedsizefeaturesformodelinput.\nAlthoughspectralinformationisdepictedhere,severalstudiesreplacedthespectralinformationwithasetofotherfeatures:vegetationindices,topographical,\n\
    atmospheric, soil,etc.\nspatial, onespectralandonetemporal.A 3DCNN operateson\
    \ imagery by obscuring the targets of interest. It is common\na 4D \u201Cimage\
    \ cube\u201D. Thus, in the literature, an \u201Cimage cube\u201D to simply exclude\
    \ single and multitemporal pixels that are\nmay referto the 3D data froma single\
    \ 2D imageafter adding occludedbyclouds[61]whenoperatingata pixellevel(Type\n\
    a singleton \u201Cchannels\u201D dimension (type S-c), or it may refer PorTypeT),orinterpolatethecolourinformationfromearlier\n\
    to the standard 4D data, using the spectral information as the and later images\
    \ (e.g. [48, 5, 49]) when using temporal data\n\u201Cchannels\u201D dimension\
    \ (type ST-c). (Type T or ST). Another common strategy is to create single\nThe\
    \ terminology used for this taxonomy can be used for image composites from images\
    \ taken at different times (e.g.\ncombinations not shown in Figure 2. For example,\
    \ [15] and [120, 68]). Some authors remove entire images from their\n[82] both\
    \ interpreted spatiotemporal as an image (type ST- training set if there is too\
    \ much cloud cover [76]. Discarding\ni) without aggregationand in completely differentways.\
    \ This entire samples reduces the number of examples available for\ntaxonomydoesnotexhaustivelydescribeeverypossiblewayto\
    \ modeltraining,andwhenusingmultitemporaldata,discarding\nuse data with modern\
    \ deep learning algorithms, but describes either the whole multitemporal pixel\
    \ or individual images\nthe main cases with a consistent terminology. in the sequence\
    \ degrades performance. [91] collected both\nLandsat-8andSentinel-2images,andwhenaSentinel-2image\n\
    B. Clouds was too cloudy,replaced it with a Landsat-8image. And [75]\nshowamethodtoexplicitlyencodevariabletemporalsampling\n\
    Cloud cover and other atmospheric effects present sig-\ninto a recurrent model\u2019\
    s architecture to prevent performance\nni\uFB01cant challenges to Earth Observation\
    \ tasks using optical6\nTABLEIII\nEACHMODELHASAREQUIREDINPUTSHAPE,ANDEACHDATAINTERPRETATIONISINTENDEDTORE-ARRANGETHEINPUTTOFITTHEMODEL.TYPE\n\
    X-FISANYFEATURESTACKINTERPRETATION,TYPEX-SISANYSEQUENCEINTERPRETATION,TYPEX-IISANYIMAGEINTERPRETATIONANDTYPE\n\
    X-CISANYIMAGECUBEINTERPRETATION(SEEFIGURE2).\nN\nN\nR n\nTree SVM MLP 1DCNN 2DCNN\
    \ 3DCNN RNN CNN+ Attentio\nTypeX-f X X X\nTypeX-s X X X\nTypeX-i X X\nTypeX-c\
    \ X X X\ndegradation. Other authors argue that deep learning is robust in the\
    \ reviewed articles (98/193),and within LULC crop seg-\ntooccasionalentireimagesbeingcompletelycoveredincloud\
    \ mentationwasthemostpopularsubtask(73/98LULCstudies;\nand use the data without\
    \ explicitly handling clouds [26, 114]. see Table VI and supplementarymaterials).\
    \ This popularityis\nCloud cover poses no issue for Synthetic Aperture Radar not\
    \ surprising, as land cover mapping is considered the most\n(SAR)imagery,socloudcovercanbemitigatedbyusingboth\
    \ important descriptor of the environment [45]. The power of\nopticalandSAR imagery(e.g.[124]).Fewworkstookadvan-\
    \ LULCiswidelyrecognisedandgovernmentsacrosstheworld\ntage of Sentinel-1 SAR imagery\
    \ in addition to their own, but publicly provide large-scale LULC maps (e.g. [116,\
    \ 19, 1]),\nthosethatdidnotedimprovedperformance[124,77,109,81]. createdthrougha\
    \ combinationof visualinspectionof satellite\nimagery, census information, local\
    \ expertise and automated\nmethods (e.g. linear unmixing model). Automated methods\n\
    C. Temporal mismatch\nare the least reliable of these, but are the easiest to\
    \ scale up.\nGround-basedin situ measurementsare generally not coor- Thus, the\
    \ goal of research into LULC and crop segmentation\ndinated with satellite imagery.\
    \ Instead the measurements are is to improve the quality of the automated methods\
    \ so that\ntaken, and then paired with images at the closest available eventually\
    \ they become at least as reliable as expert humans.\ntime, leading to a temporalmismatch.\
    \ In the reviewed studies\nWhen creating data sources for developing LULC models\n\
    there are three methods for handling this temporal mismatch\nit is impossible\
    \ to both manually annotate every pixel and\n(roughly in order of popularity):\
    \ ignore it; interpolate ground\nthen manually verify each \uFB01eld at ground\
    \ level. There is\nlabels to match image collection date [59]; or interpolate\
    \ im-\nalso inherent ambiguity of what is visible in these images,\nages to match\
    \ measurement date [10]. Ignoring the mismatch\nso, even with the huge manual\
    \ effort that goes into creating\nis popular because it is a reasonable action\
    \ to take if the\nthese data sources, they are known to have signi\uFB01cant error\n\
    property is not expected to change signi\uFB01cantly during the\nin them; e.g.\
    \ the Cropland Data Layer (CDL) [116] has an\ntimescale of mismatch, and most\
    \ properties of interest do not\nerrorrateof5-15%formajorcroptypes[11].ManyEuropean\n\
    change much over a few days to a week.\ncountries require that farmers register\
    \ what crops they grow -\nalong with farm boundaries - when applying for government\n\
    VI. TASKS rebates.Notably,France,Switzerland,Norwayandothershave\nstarted to provide\
    \ this data publicly in a quasi-anonymised\nThe reviewed studies were manually\
    \ categorised into one\nform providing huge data sources of labels to train machine\n\
    of 5 groups of tasks (see Table IV). These categories were\nlearning models, and\
    \ is the basis of most public benchmark\ndetermined based on the papers reviewed,\
    \ rather than being\ndatasets for LULC. These initiatives create high quality\
    \ data\nimposedfromthebeginningandareroughlyarrangedinorder\nsources with few\
    \ errors, although it should be noted that\noftheplant\u2019slifecycle:\uFB01\
    rst,weconsiderhowdeeplearningis\nfarmers may accidentally or deliberately misreport\
    \ the crops\nusedtodescribewherecropsarebeinggrownandthelocation\nthey are growing\
    \ [43], so even these are not error-free.\nof other farm equipment/landmarks(Section\
    \ VI-A). Next, we\nThis review makes a distinction between a data source and\n\
    explorehowdeeplearningisusedto evaluatethe soil\u2019shealth\na benchmarkdataset.Theformerisa\
    \ livingcollectionof data\n(SectionVI-B).Wethenconsidermethodsforobservingplants\n\
    that is frequently updated and covers wide areas, whereas a\nafter establishment:\
    \ evaluating the plant\u2019s growth (Section\nbenchmarkdatasetisa\uFB01xedsetofimagesandlabelsonwhich\n\
    VI-C), monitoring damage from disease or disaster (Section\ndifferent methods\
    \ can be compared directly across studies.\nVI-D), and \uFB01nally estimating\
    \ crop yield (Section VI-E). See\nLULC was the only task to have any benchmark\
    \ dataset or\nsupplementary materials for the full list of studies.\nnamed data\
    \ sources. See Table V for the list of data sources\nand benchmark datasets used\
    \ by the reviewed studies.\nA. Land Use and Land Cover\nDespite the availability\
    \ of this data, only 22 out of the 73\nThe task of Land Use and Land Cover (LULC)\
    \ is to either reviewed crop segmentation studies used continually updated\nclassify\
    \ each pixel of satellite/UAV imagery (segment), or government data sources, and\
    \ 9 used benchmark datasets\ndetect speci\uFB01c regions/objects in the images.\
    \ LULC is by far (mostly, their own). Over half (46/73) described methods\nthe\
    \ most common use of deep learning in satellite imagery for obtaining their own\
    \ segmentation maps. There are three7\nTABLEIV\nNUMBEROFPAPERSFOREACHTASK.BYFAR,CROPSEGMENTATIONWASTHEMOSTPOPULAR,FOLLOWEDBYCOUNTY-LEVELYIELDPREDICTION.\n\
    Land Use, Land Cover Soil Monitoring Plant Growth Disease/Damage Yield Est.\n\
    CropSegmentation (73) Moisture(14) Canopy cover/LAI(14) Disease(6) County-level\
    \ (23)\nFieldBoundary(8) Nutrients (6) GrowthStage(2) Damage(4) Field-level (7)\n\
    TreeCrownDelineation (6) Salinity (4) Other(3) Plot-level (2)\nDamDetection (4)\
    \ Pixel-level (2)\nOther(8) Other(7)\nLandsat\nTime\nType ST-c\n3DCNN,\nCrop\n\
    Spatial/Temporal 2DCNN+RNN,\nSegment.\nor Transformer\nImage cube\nFig.3. OneofthemorecommoninputmethodsforCropSegmentation\
    \ wasspatiotemporal datatreated asa4Dimagecube(TypeST-c).Thistypeofdata\ntypicallycomesfromLandsatorSentineldatasourceswhichprovideimagesatauniformtemporalresolution,andcanbeusedina3DCNN,or2DCNN/RNN\n\
    hybrid,orTransformermodels.\nTABLEV\nIDENTIFIEDCROPSEGMENTATIONSATELLITEBENCHMARKDATASETSANDDATASOURCES.BENCHMARKDATASETS(THOSEWITHATICKINB)HAVEA\n\
    CLEARLYDEFINEDSIZE,ANDTHUSCANBEUSEDTOCOMPAREDIFFERENTMETHODS.ONLYTHEMOSTPOPULARPUBLICGOVERNMENT\n\
    (NON-BENCHMARK)SOURCESAREINCLUDEDHERE.\nName Labels Location Years Size Source\
    \ B\nLUCAS[19] PointData Europe 2006-2018 63,000points;11.8MB In Situ / X\nVisual\n\
    Munichdataset [97] Shape\uFB01le Munich 2016-2017 137,000\uFB01elds;41.5GB Govt.\
    \ X\nBreizhCrops [98] Superpixels Brittany 2017 750,000 superpixel se- Govt. X\n\
    quences; 4.6GB\nZueriCrop[114] Shape\uFB01le Switzerland 2019 116,000\uFB01elds;38.5GB\
    \ Govt. X\nReunionIsland[25] Shape\uFB01le Reunion Island 2019 50,000\uFB01elds;290MB\
    \ Model X\nCampoVerde[100] Shape\uFB01le Brazil 2015-2016 513\uFB01elds;6.7GB\
    \ Visual X\nUOS2[83] Segmentation Spain 2020 1958x 256x256 tiles; Visual X\n5.5GB\n\
    PASTIS-R[35] Segmentation France 2019 2433x 128x128 tiles; Govt. X\n54GB\nSen4AgriNet\
    \ [106] Segmentation France, 2019-2020 250,000x S2 images; Govt. X\nCatalonia\
    \ 10TB\nFrenchLandParcel Shape\uFB01le France - - -\nIdenti\uFB01cation System\n\
    CroplandDataLayer Segmentation US - - -\n[116]\nCorineLandCover Segmentation Europe\
    \ - - -8\nmethods studies used to do this: manual \uFB01eld survey (26/73), reviewed\
    \ studies was Kussul et al. [61], who used their own\nmanual image survey (17/73),and\
    \ automated methods (8/73). custom architectures with \uFB01ve convolution layers\
    \ using a\nManual \uFB01eld surveys are the more dif\uFB01cult, expensive and\
    \ dataset of 100,000s of labelled pixels from \uFB01eld surveys and\nreliable\
    \ way to obtain ground data for training models. Using found that 2DCNNs outperformed\
    \ RF, MLP and 1DCNNs.\nan automated method to obtain training data for models\
    \ is From this time onwards, the majority of the papers reviewed\ncheaper and\
    \ less reliable, and largely limits deep learning used modern deep learning (excludingpurely\
    \ MLP methods):\nmodels to matching the automated method\u2019s dynamics, rather\
    \ there were 28 deep learning studies reviewed from 2021 and\nthan allowing it\
    \ to learn the true distribution, so a few works 21 of those used modern deep\
    \ learning methods.\nused a combination of each. For example, Rahimi-Ajdadi Most\
    \ studies in crop segmentation utilising 2DCNNs cre-\nand Khani [89] gathered\
    \ 55 data points from \uFB01eld surveys, ated their own architectures/ arrangementof\
    \ layers, typically\n360 from visual inspection and 550 from automatedmethods.\
    \ favouring shallower networks (<10 layers), with only a few\nAnd Zhou et al.\
    \ [136] and Hamer et al. [43] used automated using common architectures used in\
    \ generic computer vision\nsystems to initially label their satellite images,\
    \ then manually like VGG, ResNet and UNet (e.g. [52, 99, 121]). However,\n\uFB01\
    x the errors. Several works relied entirely on manual image using those existing\
    \ architectures was extremely common\nsurveys (e.g. [52, 78]), which is less reliable\
    \ than ground in all other LULC tasks, with all but two studies [84, 72]\nsurveys,howeveronlySaraliogluandGungor[101]\
    \ described using an existing architecture, and several using pretrained\na validation\
    \ method for their manual image survey. weights from ImageNet (e.g. [64, 30]).\
    \ There were two main\n1) Trends and recommendations: The most common data algorithms\
    \ used to process spatiotemporal data (Type ST-c;\nsources for the reviewed LULC\
    \ studies were the Sentinel- see Figure 3) the \uFB01rst is to use a 3DCNN (e.g.\
    \ [52, 124, 33]),\n1/Sentinel-2/Landsat-8satellites:18,40and10studies,respec-\
    \ and the second is to use 2DCNNs on the images and then\ntively,outof the 73\
    \ crop segmentationpapers. The Sentinel-1 use RNNs(GRUs/LSTMs)on theoutputs(e.g.[96,\
    \ 63,108]),\nsatellites provides SAR imagery (active microwave imaging), howeverthesemethodswerenotcomparedagainsteachother.\n\
    and the Sentinel-2 and Landsat-8 satellites provides multi- In generic computer\
    \ vision, transformers [23] are state-of-\nspectralopticalimagery(passiveimaging).Conceptually,these\
    \ the-artonsomemajorbenchmarks,soonemightwonderabout\ndifferent modalities contain\
    \ complementary information, and their performanceon satellite tasks. There were\
    \ 8 studies that\n9studiesusedbothtypesofdata.Ofthese,6studiesevaluated directly\
    \ referenced transformer networks, and a further 6 that\nthe bene\uFB01t of using\
    \ both image sources, and consistently used a similar multi-head attention mechanism\
    \ as is used in\nfound that it improved performance compared to using only transformers.\
    \ In all works that compared a transformer net-\none source [124, 77, 109]. Speci\uFB01\
    cally, while Ofori-Ampofo work to other moderndeep learning methods,the transformer\n\
    et al. [81] found that late fusion (averaging two model\u2019s performed equal\
    \ or worse [96, 131, 114, 75, 107, 106]. The\noutputs) was the most effective,\
    \ Garnot et al. [35] compared main other attention method used is a model called\
    \ Pixel-Set\nfusion types in many different scenarios and concluded with Encoder\
    \ and Temporal Attention Encoder (PSE-TAE) [34].\nrecommendationsfor each scenario.\
    \ This was only compared against other methods in a single\nOut of all of the\
    \ tasks reviewed in this paper, the deep study, and it was out-performedby a 1DCNN\
    \ with a Squeeze\nlearning methods for crop segmentation were the most varied\
    \ and Excitation module [107]. It has been noted that typical\nand novel, with\
    \ researchers using every different type from transformer networks require even\
    \ more training data than\nthe taxonomy in Section V-A. There seems to be two\
    \ main CNNs [23], stating that even ImageNet (1 million labelled\nreasons for\
    \ this: \uFB01rst is the popularityof the task, and second images) is too small,\
    \ so it is possible that the datasets used\nis the relative ease of obtaining\
    \ data, allowing datasets large in these satellite studies are simply not large\
    \ enough for\nenough to train modern deep learning methods. Most works transformer\
    \ networks to begin to outperform CNNs.\nreviewed were using at least 2000 data\
    \ points, and many LSTMsandGRUsaredrop-inreplacementsforoneanother\nwere in the\
    \ 10,000s, which - while small by deep learning when using RNNs, so it is possible\
    \ to compare these directly.\nstandards - are signi\uFB01cantly larger than datasets\
    \ used for There were 4 studies that found GRUs to perform better than\nthe other\
    \ reviewed satellite tasks. All major modern deep LSTMs, and 2 studies that found\
    \ the inverse.\nlearning algorithms are represented in the reviewed papers:\n\
    1DCNNs (19 studies), 2DCNNs (27), 3DCNNs (8), LSTMs\nB. Soil health\n(22), GRUs\
    \ (9), ConvLSTM/ConvGRU (7) and transformers\n(8)/other attention (6), with many\
    \ studies comparing between Soilhealthhasanimpactonallsurfacevegetation,however\n\
    these methods. In the reviewed articles, the best modern itcanbedif\uFB01culttomeasurefromspace.We\
    \ are-asalways-\ndeeplearningmethods(CNN/RNN/Attn)outperformedalltree limited\
    \ to measuring properties that cause a visible change\n(22 comparisons) (including\
    \ RF (21 comparisons)), SVM (12 within the spectra used to image the surface.\
    \ There were\ncomparisons)and MLP (6 comparisons)methodsin all cases. only 24\
    \ using deep learning to measure soil properties using\nAnecdotally, it was observed\
    \ that in many studies there were satellite images (see Table VII). These can\
    \ be put into three\nseveraldeeplearningalgorithmstested,andalmostallofthese groups:measuringsoil\
    \ moisture(14),soilnutrients(6)or soil\noutperformedtrees,SVMsandMLPsaswell.ForLULCtasks\
    \ salinity (4). In this section we include several papers which\nother than crop\
    \ segmentation, almost all of them posed the werenotspeci\uFB01callyonagricultural\uFB01\
    elds,sincethedistinction\nproblem as Type S-i and used 2D spatial CNNs (22/25).\
    \ between \u201Cagricultural\u201D and not isn\u2019t very clear. Only three of\n\
    The \uFB01rst use of modern deep learning techniques in the these studies used\
    \ modern deep learning methods and most9\nTABLEVI\nCOUNTSOFSTUDIESONLANDCOVERANDLANDUSE(LULC).VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHELABELSCOLUMN:FS\n\
    =FIELDSURVEY,IS=IMAGESURVEY,MB=MODEL-BASED,GOVT.=GOVERNMENT.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPES\n\
    INTHESAMESTUDY.SOMEUNCOMMONTYPESNOTSHOWN;FORFULLLISTSEESUPPLEMENTARYMATERIALS.\n\
    n VI Labels Model Type\nFS IS MB Govt. Dataset Tree SVM MLP CNN RNN Attn P-f P-s\
    \ T-f T-s S-i ST-c S-o(P-f) ST-o(T-f) ST-o(T-s)\nCrop Seg. 73 25 26 17 8 18 10\
    \ 28 21 23 54 31 14 17 3 12 18 18 18 2 4 7\nField Bounds 8 0 0 7 0 2 0 0 0 0 8\
    \ 0 0 0 0 0 0 8 0 0 0 0\nDamDet. 4 0 0 3 0 0 0 0 1 0 3 0 0 1 0 0 0 3 0 0 0 0\n\
    Tree Bounds 6 1 2 4 0 0 0 0 0 2 3 1 1 2 0 0 0 4 0 0 0 0\nOther 8 0 2 7 0 1 0 0\
    \ 0 0 8 0 0 0 0 0 0 8 0 0 0 0\nTABLEVII\nCOUNTSOFSTUDIESONSOILHEALTH.NISTHETOTALNUMBEROFSTUDIES.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHELABELS\n\
    COLUMN:FS=FIELDSURVEY,MBT/FSE=MODEL-BASEDFORTRAINANDFIELDSURVEYFOREVALUATION,SELF=SELF-LABELLED,GOVT.=\n\
    GOVERNMENT.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPESINTHESAMESTUDY.\nn VI Labels\
    \ Model Type\ne\nFS MBt/FS Self Govt. Tree SVM MLP CNN RNN P-f T-s S-i S-o(P-f)\n\
    Moisture 14 6 6 5 2 1 3 2 14 1 1 12 1 1 1\nNutrients 6 2 6 0 0 0 4 2 6 0 0 4 0\
    \ 0 1\nSalinity 4 3 4 0 0 0 1 2 3 1 0 3 0 1 0\nusing only an MLP (Type P-f; see\
    \ Figure 4) and did not over 500 data points. The three other studies [125, 86,\
    \ 41]\ncompare against any other method. only used MLPs and were small in scope,\
    \ with less than 100\nMapping soil moisture is useful for understanding hydro-\
    \ data points each.\nlogic processes, vegetation states, and climatic conditions\n\
    [27]. Active microwave imaging is often used to predict soil C. Plant physiology\n\
    moisturebecausethedielectricpropertiesofsoilchangeswith\nLeaf Area Index (LAI)\
    \ and Canopy Cover have a history\nmoisture for microwaves [22]. There are several\
    \ satellite-\nof being a proxy for overall plant growth [130], and are\nbased\
    \ worldwide spatially and temporally continuous active\nthe most commonlypredictedplantphysiologymeasurements\n\
    microwave imaging satellites used to estimate soil moisture\nfrom satellite imagery\
    \ using deep learning (14/19; see Table\nfrom space [80, 28, 56, 119]. Rabiei\
    \ et al. [88] provide a\nVIII).Canopycoverissimplyameasurementoftheproportion\n\
    summaryofdifferentbene\uFB01tsanddrawbackstousingdifferent\nof light being intercepted\
    \ by the plant, and thus is fairly\nremote sensing techniques. They point out\
    \ that much existing\nstraight forward to measure with remote sensing. LAI is\
    \ half\nwork utilising the active microwave satellites and distributed\nofthegreenleafareaperunitgroundsurfacearea[16],which\n\
    networks of soil monitoring stations are at a much coarser\nhas the capacity to\
    \ measure the extent of vertical/overlapping\nresolution than is useful for a\
    \ single \uFB01eld. In their work,\ncanopy cover. At ground level, LAI is typically\
    \ measured\ntheyusedrelatively\uFB01neresolutionopticalimagery(10m)with\nwith\
    \ a device such as the LAI-2000. This device measures\nCNNs (Type S-i), which\
    \ they found to be superior to other\nthe canopy cover at multiple angles, and\
    \ uses the assumption\nmachine learning methods.\nof uniformly randomly distributed\
    \ leaves to calculate LAI.\nThere were six studies which attempted to measure\
    \ soil Canopy cover and LAI are highly correlated metrics [79], so\nnutrients\
    \ using deep learning on satellite imagery, with all of these are considered together\
    \ for this review.\nthem using MLPs, but only three of them comparedmethods. The\
    \ majority plant physiology studies reviewed used only\nWang et al. [122] and\
    \ Zhang et al. [134] found that RFs MLPsastheirprimarymodelwithoutcomparingagainstother\n\
    worked better than MLPs and Song et al. [105] found that an machinelearningmethods;11/19TypeP-f,3/19TypeS-o(P-f)\n\
    MLPworkedbetterthananRForSVM.Noneofthesestudies and 1/19 Type T-f (see Figure\
    \ 4). The only study that made a\nused CNNs or other modern deep learning architectures.\
    \ comparisonor used anymoderndeep learningwasThorpand\nHighsoilsalinityisagrowingproblemworldwide,andthere\
    \ Drajat [109], who found that LSTMs outperformed MLPs at\nisgrowinginterestinmappingthisenvironmentalhazardusing\
    \ classifying growth stage. There were no examples of modern\nsatellite imagery\
    \ [74]. Despite the dire impacts of high soil deep learning for canopy cover or\
    \ LAI prediction.\nsalinity, there were only 4 studies that investigated predicting\
    \ 1) Radiative Transfer models: A radiative transfer model\nsoil salinity from\
    \ satellite imagery using deep learning. Only (RTM) is a method to estimate the\
    \ re\uFB02ectance from physical\noneusedamoderndeeplearningapproach[3],andtheyfound\
    \ properties of the object being imaged. Most of the studies\nthat it performed\
    \ signi\uFB01cantly better than SVM models using used the PROSAIL model [51],\
    \ to model the plants and the10\nLandsat\nType P-f RF,\nSoil\nSVM, or\nColour\
    \ Feature Stack Moisture\nMLP\nFig.4. Themostcommoninputmethodforsoilhealth,plantphysiologyandcropdamagedetection\
    \ istooperateoneachpixelindependently, andtreatthe\npixelasaunorderedcollection\
    \ offeatures (TypeP-f).Thissimplemethodcaneasilybeappliedtoanypixel-level data,butlacksanycontextual\
    \ information\nandisusedintraditional machinelearning methodslike RFandSVM,aswellassimpleMLPs.\n\
    TABLEVIII\nCOUNTSOFSTUDIESONPLANTPHYSIOLOGY.NISTHETOTALNUMBEROFSTUDIES.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHE\n\
    LABELSCOLUMN:FS=FIELDSURVEY,IS=IMAGESURVEY,MB=MODEL-BASED,MBT/FSE=MODEL-BASEDFORTRAINANDFIELDSURVEYFOR\n\
    EVALUATION.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPESINTHESAMESTUDY.\nn VI Labels\
    \ Model Type\ne\nFS MB MBt/FS Govt. Tree SVM MLP CNN RNN P-f T-f S-i ST-c S-o(P-f)\n\
    CanopyCover/LAI 14 3 6 1 7 0 1 1 14 0 0 10 0 0 0 4\nOther 5 4 1 1 1 2 1 1 4 2\
    \ 1 3 1 2 1 0\nsoil beneath them. It takes as input: the chlorophyll content,\
    \ thescaleoftheplants,whentheybecomewide-spreadenough,\nthe water/dry matter content,\
    \ the Leaf Area Index, average they become visible via remote sensing [132].\n\
    leaf inclination, ratio of diffuse to direct incident radiation,\nMost of the\
    \ found studies posed the damage caused by\nsoil brightness, solar zenith angle,\
    \ sensor zenith angle and\ndisease and natural disasters as a classi\uFB01cation/segmentation\n\
    relative azimuth angle; and outputs re\uFB02ectance. Since the\nproblem (8/10).\
    \ In these cases, the models were segmenting\nphysiologicalpropertiesarethe inputto\
    \ the PROSAIL model,\nbetween \"damage\" and \"no damage\". A notable exception\n\
    the processofdeterminingoneofthe physiologicalproperties\nwas Rodriguez et al.\
    \ [92], who used a modi\uFB01ed ResNet-18\n(e.g. LAI) from the re\uFB02ectance\
    \ is called \u201Cmodel inversion\u201D in\n[44] CNN model to detect damage to\
    \ Coconut crops in the\nthese contexts.\nPhilippines by comparing tree density\
    \ estimates before and\nAlmost half of the studies (8/19) collected ground-level\n\
    after Typhoon Goni, making it the only study to measure the\nphysical properties\
    \ and used an RTM in forward mode to\nextent of the damage per unit area.\ngeneratetraining\
    \ pairsof LAI/re\uFB02ectancefor their MLPs, and\nthen tested them on real data.\
    \ However, Tomicek et al. [112]\nThe threshold for considering an area to be infected\
    \ with a\nfound that the PROSAIL RTM predicted re\uFB02ectances only\ndisease\
    \ varied signi\uFB01cantly between studies, with Yuan et al.\ncorrelated with\
    \ Sentinel-2 images between R2 > 0.6 for red,\n[133] requiring 80% of the plants\
    \ to have visible pustules on\ngreenandbluebandsanduptoR2 >0.9forred-edgeandNIR\n\
    thetopofthecanopytobeconsidered\"infected\"withpowdery\nbands, which implies fundamental\
    \ limits on the accuracy of\nmildew, and Ma et al. [69] requiring more than 10%\
    \ of the\nLAI estimation using this method. Despite the acknowledged\nleafs to\
    \ be infected to be considered \"infected\". Obviously a\nerrors, these studies\
    \ treat the PROSAIL model as inherently\nmore extensive spread of a disease makes\
    \ the disease more\ncorrect, and thus no study compared PROSAIL in reverse\nvisible,\
    \ and hence, predictable. For example, Pignatti et al.\nmode to a machine learning\
    \ model on a held-out test set of\n[85] explicitly tested their MLP model at differenttimes\
    \ after\n\uFB01eld survey data.\ninitial infectionand notedsigni\uFB01cantly improvedaccuracyfor\n\
    later predictions.\nD. Crop Damage\nThesestudieswereallstraight-forwardapplicationsofwell-\n\
    There are only10 worksusing deep learningto detect crop knowndeeplearningalgorithms(mostlyMLPsonsingle-pixel\n\
    damage using satellite data (see Table IX, and of these, only data) mostly using\
    \ \uFB01eld survey data. All of the studies used\ntwo used CNNs (Type S-i) [118,\
    \ 92] and one used a GRU medium resolution images between 1.5m and 30m resolution\n\
    (Type T-s) [7]. Although pests and diseases are features on to match the resolution\
    \ of the \uFB01elds in the \uFB01eld surveys.11\nTABLEIX\nCOUNTSOFSTUDIESONCROPDAMAGE.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHELABELSCOLUMN:FS=FIELDSURVEY,IS=\n\
    IMAGESURVEY.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPESINTHESAMESTUDY.\nn VI Labels\
    \ Model Type\nFS IS Tree SVM MLP CNN RNN P-f S-o(P-f) T-f T-s S-i\nDisease 6 5\
    \ 6 0 2 2 6 0 0 3 2 1 1 0\nOther 4 0 3 2 1 0 2 2 1 1 1 0 0 2\nE. Yield tion observed\
    \ (23/41); this is likely because several govern-\nments publicly provide yield\
    \ measurements aggregated at a\nThe task of yield prediction is to predict the\
    \ average yield\ncounty/state level and thus, the data for such work is readily\n\
    per hectare for a parcel of land. Unlike LULC, which can be\naccessible. This\
    \ provides data for a whole country at once,\nidenti\uFB01edbyahumanexpertfromasatelliteimagemoderately\n\
    but is highly aggregated. It is likely that MODIS imagery is\nreliably[73],yieldis\
    \ generallymeasuredat eitherthe county-\npopularfor this task because the relatively\
    \ large pixels makes\nlevel by governmentbodies,or at the \uFB01eld-levelby individual\n\
    aggregation of re\uFB02ectances and VIs a less computationally\nresearchers.Forthepurposesofthisreview,\"\
    county\"refersto\nintensive task than using Landsat. Conversely,\uFB01eld-level\
    \ data\nanything larger than a \uFB01eld (e.g. \u201Cmunicipality\u201D, \u201C\
    province\u201D,\n(7/41) is generally more dif\uFB01cult to obtain as there are\
    \ no\n\u201Cstate\u201D, etc.) due to their varying meaning across different\n\
    public databases to work from. We note that Landsatimagery\npapers/governments.We\
    \ note that almost universally, county-\nis used at a \uFB01eld-level in much\
    \ the same way as MODIS\nlevel yield uses MODIS imagery with yield measurements\n\
    imageryis usedat a county-level(e.g.[135]),and when\uFB01eld-\npublished by governments;\
    \ while \uFB01eld-level yield uses Sen-\nlevel prediction is formulated in the\
    \ same way as county-\ntinel/Landsat imagery and \uFB01eld surveys, where the\
    \ data was\nlevel, the input is the same shape, and a single model can\ncollected\
    \ speci\uFB01cally for the study (see Table X). However,\noperate seamlessly at\
    \ both granularities [14, 110]. However,\nthe modelling is similar in both cases\
    \ for the vast majority\naggregating over pixels removes all spatial information,\
    \ and\nof studies. Since the yield is measured with respect to large\nthus the\
    \ models cannot learn spatial relationships.\nshapes(counties/\uFB01elds)andnotwithrespecttopixels,theinput\n\
    to the modelsis an aggregatedcolour value from the imagery When averaging over\
    \ counties, it is still possible to use\n(or NDVI) across the county/\uFB01eld,\
    \ effectively removing all a 2D CNN, but not over spatial data. Khaki et al. [57]\
    \ and\nspatial information from the data (Type T-o and ST-o; see Qiaoetal. [87]chosetoaggregatethecounty-leveldatausing\n\
    Figure5).Therearemultiplewaysonecouldaggregateacross a histogram, providing a\
    \ much richer understanding of the\na whole county or \uFB01eld, yet several papers\
    \ did not describe informationwithin a countythanjust takingthe average.This\n\
    their method for doing so. The most commonly mentioned creates a 3D block of data\
    \ (bins, time, bands) which can be\nmethod is to take an average, so it is likely\
    \ that the studies used with a 2D CNN (Type ST-o interpreted as Type T-i). In\n\
    that did not specify the aggregation method simply used an these cases, the 2D\
    \ CNNs performed better than traditional\naverage. machinelearningmethods.However,thismethodof\
    \ using2D\nCNNs doesn\u2019t use spatial data - instead convolving over the\n\
    Aggregatingallpixelsofacountybyaveragingnaivelywill\ntemporal and spectral dimensions.\
    \ Engen et al. [26] collated\nincorporatealotofnon-cropinformationfrombodiesofwater,\n\
    several Norwegian government sources to create a dataset of\nresidential areas,\
    \ and other unfarmed land. Since the process\nfarm-level yields and applied novel\
    \ architectures including\nreduces the data for a whole county to just a few numbers\n\
    both a 2D CNN and GRU. They used the \uFB01eld shape \uFB01les\n(one per colour\
    \ band; often just NDVI), it is important to\nto onlyincludethe pixelsforthe \uFB01\
    eld beingpredicted,setting\nensure that the recorded aggregate is as accurate\
    \ as possible.\nthe other pixels to zero. They compared these to aggregating\n\
    FortheUSandChina,therearenation-wideestimatesofcrop\ndataacrossthewhole\uFB01\
    eldandusinganLSTMandfoundthat\ntypes aligned to Landsat imagery (e.g. CDL). Since\
    \ Landsat\ntheir novel 2DCNN/GRU architecture performed better.\nimagery is at\
    \ a signi\uFB01cantly \uFB01ner resolution than MODIS, it\u2019s\npossible to\
    \ calculate an estimated proportion of each crop While averaging over pixels within\
    \ the \uFB01eld/county was\nwithin each MODIS pixel using these crop maps and\
    \ \uFB01lter the most popular method, two works [42, 99] used com-\nthemforeachcountytoonlyselectthepixelsthatrelatetothe\
    \ bine harvesters equipped with yield measuring technology\ncropofinterest.ForexampleLietal.[62]describe\uFB01\
    lteringout to obtain a yield map across a whole \uFB01eld. This provides\nMODISpixelswithlessthan0.1NDVIorlessthan75%ofthe\
    \ yield at a signi\uFB01cantly \uFB01ner resolution than other methods,\narea\
    \ coveredby the cropof interest, as indicatedbythe CDL. and also provides an obvious\
    \ pathway to include a CNN in\nEven when using such a method, there are still\
    \ signi\uFB01cant the solution as the yield measurements can now be aligned\n\
    sources of error in the NDVI aggregation: the pixels still to the uniform pixel\
    \ grid of the imagery. More speci\uFB01cally,\ncontain non-crop information, the\
    \ \uFB01elds may be mislabelled, Haghverdiet al. [42] collected many densely predicted\
    \ yields\nand\uFB01eldsthataredouble-croppedmayormaynotcontainthe along with combine\
    \ harvester locations, and then averaged\ncrop of interest at the time the image\
    \ is taken. these to match Landsat imagery, and Sagan et al. [99] tasked\nCounty-level\
    \ is the most popular scale of yield predic- commercial satellites to take 30cm\
    \ resolution images of their12\nMODIS\n* * * * * Mask\nFig.5. Themostcommoninputmethodforcounty-level\
    \ yieldpredictionistouseobjectboundaries toselectandaggregatepixelsfromspatiotemporal\
    \ data\n(TypeST-o),andreinterpret thisdataasasimplesequenceofcounty-averaged \u201C\
    pixels\u201D(TypeT-s).TogetherthisisdenotedasTypeST-o(T-s).ThisT-sdata\ncanthenbeusedinmodelslike1DCNNsorLSTMs.ManyworksadditionallymasktheimagedatabycroptypeusingtheUSDA\u2019\
    sCDL[116]orequivalent,\nbut other works indiscriminately aggregate over all pixels\
    \ within the county boundary, including pixels from different crop types and some\
    \ non-farmland.\nSomeworksadditionally \uFB02attenthosecounty-averaged \u201C\
    pixels\u201D toacollection offeatures (TypeST-o(T-f))foruseinRF,SVMandMLPmodels.\n\
    TABLEX\nCOUNTSOFSTUDIESONYIELDPREDICTION.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.CLIM.COUNTSSTUDIESTHATUSEDCLIMATE\n\
    VARIABLESINTHELABELSCOLUMN:FS=FIELDSURVEY,ANDGOVT.=GOVERNMENT.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPES\n\
    INTHESAMESTUDY.ONLYTYPESUSEDINMORETHANONESTUDYARESHOWN.\nm.\nn VI Cli Labels Model\
    \ Type\nFS Govt. Other Tree SVM MLP CNN RNN P-f T-f ST-c S-o(P-f) ST-o(P-f) ST-o(T-f)\
    \ ST-o(T-s) ST-o(T-i) ST-o(T-c)\nCounty-level 23 21 20 1 22 3 16 6 11 7 12 0 0\
    \ 0 0 1 18 14 2 2\nField-level 7 7 2 6 0 1 3 2 5 1 2 0 0 0 2 3 2 2 0 0\nPlot-level\
    \ 2 1 1 2 0 0 1 1 2 1 0 0 1 1 0 1 0 0 0 0\nPixel-level 2 2 1 2 0 1 0 0 1 1 1 1\
    \ 0 0 0 0 0 0 0 0\nOther 7 5 3 5 1 1 1 1 7 1 1 3 2 1 0 0 0 0 0 1\ncropsduringtheirstudyto\
    \ obtainan extremely\uFB01neresolution also notbe applicable.In contrast,thereweretwo\
    \ studiesthat\ndataset to train on. They were then able to train CNNs on used\
    \ CNNs on spatial data [26, 99], and in both cases the\ndense spatiotemporal data\
    \ (Type ST-c) and compare against CNN models performed better than other methods.\n\
    traditionalML methods(trees, SVMs) and found that 2D and Severalof the county-levelstudies\
    \ have over1000counties\n3D CNNs worked better. Although they only used a single\
    \ recordedforover10years.Thisscaleofdataiseasytoobtain\nsite, each pixel is effectively\
    \ another example, meaning they foraresearcher,asitisallpubliclydownloadable.Incontrast,\n\
    had many thousands of examples to train on. with the exception of Zhang et al.\
    \ [135] (11000 data points),\nthe \uFB01eld-levelstudies used small datasets containingless\
    \ than\nThere were several studies which compared performance\n100datapoints;presumablybecausethedatawassoexpensive\n\
    between models, but even for county-level prediction, which\nto obtain.\nhad the\
    \ most homogeneous approach, there was no model\nwhich always performed the best.\
    \ Unlike for the other tasks Interestingly, Watson-Hernandez et al. [127] was\
    \ the only\n- where modern deep learning methods consistently outper- study found\
    \ that attempted to forecast the yield outside the\nformedtraditionalmethods-foryieldpredictionthereisonlya\
    \ current season.\nslightmajorityofLSTMsperformingbetterthantreemethods 1) Climatic\
    \ and soil variables: Nearly all of the county-\n(6/10).Itisnotclearwhythisisthecase;thedatasetsizeswere\
    \ level studies used climatic variables (e.g. ground temperature\napproximately\
    \ the same for studies where LSTMs performed and precipitation) and soil properties\
    \ (e.g. soil particle size,\nbetter. Each of these studies compared different\
    \ times, places soil moisture content) in addition to the re\uFB02ectances/VIs\n\
    and crops types, so comparing RMSE or R2 values would (22/23), and universally\
    \ noted improved performance when13\ncompared to not using these variables [13,\
    \ 126, 129]. How- and not being widely tracked or collated, which has resulted\n\
    ever, there was no consistency in which soil variables were in relatively small-scale\
    \ studies, and less research interest -\nused, nor how the temperature was encoded\
    \ and no works at least as far as deep learning is concerned. There were\ncomparedtheirclimaticdataencodingtootherencodings.For\
    \ 51 studies identi\uFB01ed across soil health, plant physiology and\nexample,\
    \ the temperature was variously classi\uFB01ed/aggregated crop damage tasks, and\
    \ among these only eight of them used\nintoGrowingDegreeDays,KillingDegreeDaysandFreezing\
    \ moderndeeplearningalgorithmsandmostofthosewereafter\nDegree Days before being\
    \ fed into the model (e.g. [135]). It 2020. Of these eight, only four compared\
    \ the modern deep\nwasalsocommontousevariousdifferenttemperaturestatistics learningalgorithmtoatree/forest,SVMorMLP,butinallfour\n\
    (e.g.min/mean/max)andsomestudiesevencombinedmultiple cases the modern deep learning\
    \ algorithm performed better.\nsources of meteorological data (e.g [54]). This\
    \ makes it The vast majority of modern deep learning methods were\ndif\uFB01cult\
    \ to recommend any climatic and soil properties in for LULC tasks, in which there\
    \ was a very noticeable trend\nparticular. of modern deep learning algorithms\
    \ performing better. In\nThese variables can sometimes be dif\uFB01cult to obtain.\
    \ Me- crop segmentation, modern deep learning algorithms were\nteorological stations\
    \ are not uniformly distributed, and don\u2019t compared with trees, SVMs or MLPs\
    \ in 25 studies, and\nnecessarily cover everywhere in the study area, so when\
    \ performed better in all but one case. However, the Vision\noperating at smaller\
    \ than county-level, Engen et al. [26] Transformer [23] model and variants, which\
    \ have performed\nshowedthatthemeteorologicalinformationcanbeinterpolated very\
    \ well in generic computer vision tasks, did not show any\nbetweenmeteorologicalstationsto\
    \ providebetterestimates of particular improvement over CNNs and RNNs. Transformers\n\
    local climatic variables. have been noted to require much more data than CNNs\
    \ to\nachieve state-of-the-artperformance,and it\u2019s possible that the\ntransformersusedinthereviewedstudieshavenotbeentrained\n\
    VII. DISCUSSION\nwith enough data. So, there is room for further investigation\n\
    Inthis review,we haveobservedthatmoderndeeplearning of this phenomenon, perhaps\
    \ utilising unsupervised or semi-\nmethods have become dramatically more popular\
    \ in the last supervised training methods to bridge the gap in data scale.\nfew\
    \ years. This trend is likely to continue, as the research For as many examples\
    \ of straightforward uses of standard-\nappears to be following generic computer\
    \ vision. However, ised forms of modern deep learning algorithms (e.g. UNet\n\
    generic computer vision research has been partially propelled \uFB01ne-tunedon\
    \ type S-idata [83]), therewere also manyexam-\nby large public benchmarkdatasets,\
    \ which are mostly lacking ples of speci\uFB01c ideas being directly transferred\
    \ and adapted\nin the agricultural tasks identi\uFB01ed in this review, especially\
    \ from generic computer vision to the satellite setting (e.g.\nmonitoring soil\
    \ health, plant physiology and crop damage. discriminator loss [63], neural ordinary\
    \ differential equations\nWithout accessible large datasets, methods are not easily\
    \ [75], channel attention maps [107]). However, there was only\ncomparable and\
    \ deep learning in these areas is constrained to one main variation observed that\
    \ explicitly took advantage of\nthose who have the resources to conduct large\
    \ \uFB01eld surveys. the differences between satellite imagery and ground-based\n\
    Crop segmentation is the only identi\uFB01ed task with bench- imagery: several\
    \ works utilised the higher spectral resolution\nmark datasets (see Table V; Section\
    \ VI-A), and this data is and convolvedover the spectral dimension(typesP-s, T-i\
    \ and\nmostly derived from large public data sources. Even within S-c; e.g. [61,\
    \ 20, 101]). There is a gap here; satellite imagery\ncrop segmentation, there\
    \ are very few examples of compar- is not the same as ground-based images or video.\
    \ There is\nisons on these benchmark datasets. And county-level yield temporal\
    \ continuity at every pixel. There are spatial patterns\nprediction - despite\
    \ also being quite popular, and having at hugely varied scales. There is an order\
    \ of magnitude more\npublic data sources - does not have any benchmark datasets.\
    \ data available, and it is all associated with physicallocations.\nMore accessible\
    \ data makes more research easier and enables All of these properties are not\
    \ being taken advantage of in\nreliable comparisons. For example, the recommendation\
    \ to existing work tackling agricultural tasks, and are interesting\nalwaysuseSentinel-1dataalongwithSentinel-2dataisviable\
    \ directions for future research.\nbecauseallSentineldataisalwaysfreelyavailable,andreliable\n\
    because many studies were able to independently \uFB01nd the ACKNOWLEDGEMENTS\n\
    same conclusion. Public benchmark datasets would provide\nThe fundingfor this\
    \ work comes from the SmartSat Coop-\nan accessible collectionof data for manydifferentresearchers\n\
    erative Research Centre.\nto train deep learning models, which would lead to more\n\
    CertaindataincludedhereinarederivedfromClarivateWeb\nreproducibleresults,andallowresearcherstomoreeasilybuild\n\
    of Science. \xA9 Copyright Clarivate 2022. All rights reserved.\noff of each others\
    \ work. Provided, of course, that researchers\nutilise them.\nCrop segmentation\
    \ and county-level yield prediction are REFERENCES\nthe two tasks with the most\
    \ interest, and the only ones with [1] ABARES. Catchment Scale Land Use of Australia\
    \ -\nexistingcountry-widedatasourceswhichcouldbeutilisedfor Update December 2020.\
    \ Australian Bureau of Agricul-\ncreatingbenchmarkdatasetseasily.Thisislikelybecausecrop\
    \ turalandResourceEconomicsandSciences,Canberra,\nsegmentation is relatively easy\
    \ to label, and monitoring yield 2021. doi: 10.25814/aqjw-rq15.\ncountry-wide\
    \ is already well-established in many countries. [2] John B. Adams, Donald E.\
    \ Sabol, Valerie Kapos,\nThe other tasks suffer from being more dif\uFB01cult\
    \ to measure Raimundo Almeida Filho, Dar A. Roberts, Milton O.14\nSmith, and Alan\
    \ R. Gillespie. Classi\uFB01cation of multi- [13] Yaping Cai, Kaiyu Guan, David\
    \ Lobell, Andries B.\nspectralimagesbasedonfractionsofendmembers:Ap- Potgieter,\
    \ Shaowen Wang, Jian Peng, Tianfang Xu,\nplicationtoland-coverchangeintheBrazilianAmazon.\
    \ SentholdAsseng,YongguangZhang,LiangzhiYou,and\nRemote Sensing of Environment,\
    \ 52(2):137\u2013154, May Bin Peng. Integrating satellite and climate data to\n\
    1995. ISSN 0034-4257. doi: 10.1016/0034-4257(94) predictwheatyieldin Australiausingmachinelearning\n\
    00098-8. approaches. AGRICULTURAL AND FOREST METE-\n[3] SeymaAkcaandOguzGungor.\
    \ Semanticsegmentation OROLOGY, 274:144\u2013159, August 2019. ISSN 0168-\nofsoilsalinityusingin-situECmeasurementsanddeep\
    \ 1923. doi: 10.1016/j.agrformet.2019.03.010.\nlearning based U-NET architecture.\
    \ CATENA, 218, [14] Juan Cao, Zhao Zhang, Yuchuan Luo, Liangliang\nNovember 2022.\
    \ ISSN 0341-8162. doi: 10.1016/j. Zhang,JingZhang,ZiyueLi,andFuluTao.Wheatyield\n\
    catena.2022.106529. predictions at a county and \uFB01eld scale with deep learn-\n\
    [4] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. ing, machine learning, and\
    \ google earth engine. EU-\nHinton. Layer Normalization, July 2016. ROPEAN JOURNAL\
    \ OF AGRONOMY, 123, February\n[5] Paola Benedetti, Dino Ienco, Raffaele Gaetano,\
    \ Kenji 2021.ISSN1161-0301.doi:10.1016/j.eja.2020.126204.\nOse, Ruggero G. Pensa,\
    \ and Stephane Dupuy. [15] Mohamed Chelali, Camille Kurtz, Anne Puissant, and\n\
    M(3)Fusion: A Deep Learning Architecture for Multi- Nicole Vincent. Deep-STaR:\
    \ Classi\uFB01cation of image\nscale Multimodal Multitemporal Satellite Data Fusion.\
    \ time series based on spatio-temporal representations.\nIEEEJOURNALOFSELECTEDTOPICSINAPPLIED\
    \ COMPUTER VISION AND IMAGE UNDERSTAND-\nEARTHOBSERVATIONSANDREMOTESENSING,11\
    \ ING, 208, July 2021. ISSN 1077-3142. doi: 10.1016/j.\n(12):4939\u20134949, December\
    \ 2018. ISSN 1939-1404. cviu.2021.103221.\ndoi: 10.1109/JSTARS.2018.2876357. [16]\
    \ J.M.ChenandT.A.Black. De\uFB01ningleafareaindexfor\n[6] Lucas Beyer, Olivier\
    \ J. H\xE9naff, Alexander Kolesnikov, non-\uFB02at leaves. Plant, Cell & Environment,\
    \ 15(4):421\u2013\nXiaohua Zhai, and A\xE4ron van den Oord. Are we done 429,1992.\
    \ ISSN1365-3040.doi:10.1111/j.1365-3040.\nwith ImageNet? arXiv:2006.07159[cs],\
    \ June 2020. 1992.tb00992.x.\n[7] Luning Bi, Guiping Hu, Muhammad Mohsin Raza,\
    \ [17] Liang-Chieh Chen, George Papandreou, Florian\nYuba Kandel, Leonor Leandro,\
    \ and Daren Mueller. A Schroff, and Hartwig Adam. Rethinking Atrous\nGated Recurrent\
    \ Units (GRU)-Based Model for Early Convolution for Semantic Image Segmentation,\n\
    DetectionofSoybeanSuddenDeathSyndromethrough December 2017.\nTime-Series Satellite\
    \ Imagery. REMOTE SENSING, 12 [18] Yun-Jae Choung and Donghwi Jung. Comparison\
    \ of\n(21), November 2020. doi: 10.3390/rs12213621. Machineand DeepLearningMethodsfor\
    \ MappingSea\n[8] ThomasBlaschke and Josef Strobl. What\u2019s wrong with Farms\
    \ Using High-Resolution Satellite Image. Jour-\npixels? Some recent developments\
    \ interfacing remote nal of Coastal Research, 114(sp1):420\u2013423, October\n\
    sensing and GIS. Zeitschrift f\xFCr Geoinformationssys- 2021. ISSN 0749-0208,\
    \ 1551-5036. doi: 10.2112/\nteme, 14:12\u201317, June 2001. JCR-SI114-085.1.\n\
    [9] Thomas Blaschke, Geoffrey J. Hay, Maggi Kelly, Ste- [19] Rapha\xEBl d\u2019\
    Andrimont, Astrid Verhegghen, Michele\nfan Lang, Peter Hofmann, Elisabeth Addink,\
    \ Raul Meroni, Guido Lemoine, Peter Strobl, Beatrice Eiselt,\nQueiroz Feitosa,\
    \ Freek van der Meer, Harald van der MomchilYordanov,LauraMartinez-Sanchez,and\
    \ Mar-\nWerff, Frieke van Coillie, and Dirk Tiede. Geo- ijn van der Velde. LUCAS\
    \ Copernicus 2018: Earth-\ngraphic Object-Based Image Analysis - Towards a new\
    \ observation-relevantin situ data on land cover and use\nparadigm. ISPRS Journal\
    \ of Photogrammetry and Re- throughout the European Union. Earth System Science\n\
    mote Sensing, 87:180\u2013191, January 2014. ISSN 0924- Data,13(3):1119\u2013\
    1133,March2021. ISSN1866-3508.\n2716. doi: 10.1016/j.isprsjprs.2013.09.014. doi:\
    \ 10.5194/essd-13-1119-2021.\n[10] Monica Bocco, Gustavo Ovando, Silvina Sayago,\
    \ En- [20] MisganuDebella-GiloandArntKristianGjertsen.Map-\nrique Willington,\
    \ and Susana Heredia. Estimating soy- ping Seasonal Agricultural Land Use Types\
    \ Using\nbean ground cover from satellite images using neural- Deep Learning on\
    \ Sentinel-2 Image Time Series. RE-\nnetworks models. INTERNATIONAL JOURNAL OF\
    \ MOTE SENSING, 13(2), January 2021. doi: 10.3390/\nREMOTE SENSING, 33(6):1717\u2013\
    1728, 2012. ISSN rs13020289.\n0143-1161. doi: 10.1080/01431161.2011.600347. [21]\
    \ Jia Deng,WeiDong,RichardSocher,Li-Jia Li, KaiLi,\n[11] ClaireBoryan,ZhengweiYang,RickMueller,andMike\
    \ and Li Fei-Fei. ImageNet: A large-scale hierarchical\nCraig. MonitoringUS agriculture:The\
    \ US Department imagedatabase.In2009IEEEConferenceonComputer\nof Agriculture,\
    \ National AgriculturalStatistics Service, Vision and Pattern Recognition, pages\
    \ 248\u2013255, June\nCroplandData LayerProgram. GeocartoInternational, 2009.\
    \ doi: 10.1109/CVPR.2009.5206848.\n26(5):341\u2013358, August 2011. ISSN 1010-6049.\
    \ doi: [22] Myron C. Dobson, Fawwaz T. Ulaby, Martti T. Hal-\n10.1080/10106049.2011.562309.\
    \ likainen, and Mohamed A. El-rayes. Microwave Di-\n[12] Philip G. Brodrick, Andrew\
    \ B. Davies, and Gregory P. electric Behaviorof Wet Soil-PartII:DielectricMixing\n\
    Asner. Uncovering Ecological Patterns with Convo- Models. IEEETransactionsonGeoscienceandRemote\n\
    lutional Neural Networks. Trends in Ecology and Sensing, GE-23(1):35\u201346,\
    \ January 1985. ISSN 1558-\nEvolution, 2019. doi: 10.1016/j.tree.2019.03.006.\
    \ 0644. doi: 10.1109/TGRS.1985.289498.15\n[23] Alexey Dosovitskiy, Lucas Beyer,\
    \ Alexander Gilliams, Sander M\xFCcher, Robert Tetrault, Inian Moor-\nKolesnikov,\
    \ Dirk Weissenborn, Xiaohua Zhai, Thomas thy,andIanMcCallum.Acomparisonofglobalagricul-\n\
    Unterthiner, Mostafa Dehghani, Matthias Minderer, turalmonitoringsystemsandcurrentgaps.\
    \ Agricultural\nGeorg Heigold, Sylvain Gelly, Jakob Uszkoreit, Systems,168:258\u2013\
    272,January2019.ISSN0308-521X.\nand Neil Houlsby. An Image is Worth 16x16 doi:\
    \ 10.1016/j.agsy.2018.05.010.\nWords: Transformers for Image Recognition at Scale.\
    \ [32] J. W Funck, Y Zhong, D. A Butler, C. C Brunner, and\narXiv:2010.11929[cs],\
    \ June 2021. J. B Forrer. Image segmentation algorithms applied\n[24] M. Drusch,\
    \ U. Del Bello, S. Carlier, O. Colin, V. Fer- to wood defect detection. Computers\
    \ and Electronics\nnandez, F. Gascon, B. Hoersch, C. Isola, P. Laberinti, in Agriculture,\
    \ 41(1):157\u2013179, December 2003. ISSN\nP.Martimort,A.Meygret,F.Spoto,O.Sy,F.Marchese,\
    \ 0168-1699. doi: 10.1016/S0168-1699(03)00049-8.\nand P. Bargellini. Sentinel-2:\
    \ ESA\u2019s Optical High- [33] IgnazioGallo, Riccardo La Grassa, Nicola Landro,and\n\
    Resolution Mission for GMES Operational Services. Mirco Boschetti. Sentinel 2\
    \ Time Series Analysis with\nRemoteSensingofEnvironment,120:25\u201336,May2012.\
    \ 3D Feature Pyramid Network and Time Domain Class\nISSN 0034-4257. doi: 10.1016/j.rse.2011.11.026.\
    \ Activation Intervals for Crop Mapping. ISPRS INTER-\n[25] St\xE9phane Dupuyand\
    \ Raffaele Gaetano. Reunion island NATIONAL JOURNAL OF GEO-INFORMATION, 10\n-\
    \ 2019, Land cover map (Spot6/7) - 1.5m, 2020. (7), July 2021. doi: 10.3390/ijgi10070483.\n\
    [26] Martin Engen, Erik Sand\xF8, Benjamin Lucas Oscar Sj\xF8- [34] Vivien Sainte\
    \ Fare Garnot, Loic Landrieu, Sebastien\nlander, Simon Arenberg, Rashmi Gupta,\
    \ and Morten Giordano, and Nesrine Chehata. Satellite Image Time\nGoodwin. Farm-Scale\
    \ Crop Yield Prediction from SeriesClassi\uFB01cationWithPixel-SetEncodersandTem-\n\
    Multi-Temporal Data Using Deep Hybrid Neural Net- poral Self-Attention. In Proceedings\
    \ of the IEEE/CVF\nworks. Agronomy,11(12):2576,December 2021. ISSN Conference\
    \ on Computer Vision and Pattern Recogni-\n2073-4395. doi: 10.3390/agronomy11122576.\
    \ tion, pages 12325\u201312334,2020.\n[27] Dara Entekhabi, Ignacio Rodriguez-Iturbe,\
    \ and Fabio [35] Vivien Sainte Fare Garnot, Loic Landrieu, and Nes-\nCastelli.\
    \ Mutual interaction of soil moisture state and rine Chehata. Multi-modal temporal\
    \ attention models\natmospheric processes. Journal of Hydrology, 184(1): for crop\
    \ mapping from satellite time series. ISPRS\n3\u201317, October 1996. ISSN 0022-1694.\
    \ doi: 10.1016/ JOURNAL OF PHOTOGRAMMETRY AND REMOTE\n0022-1694(95)02965-6. SENSING,\
    \ 187:294\u2013305, May 2022. ISSN 0924-2716.\n[28] Dara Entekhabi, Eni G. Njoku,\
    \ Peggy E. O\u2019Neill, doi: 10.1016/j.isprsjprs.2022.03.012.\nKent H. Kellogg,\
    \ Wade T. Crow, Wendy N. Edelstein, [36] Robin Gebbers and Viacheslav I. Adamchuk.\
    \ Pre-\nJared K. Entin, Shawn D. Goodman, Thomas J. Jack- cision Agriculture and\
    \ Food Security. Science, 327\nson, Joel Johnson, John Kimball, Jeffrey R. Piepmeier,\
    \ (5967):828\u2013831, February 2010. doi: 10.1126/science.\nRandal D. Koster,\
    \ Neil Martin, Kyle C. McDonald, 1183899.\nMahta Moghaddam, Susan Moran, Rolf\
    \ Reichle, J. C. [37] C. Gomez, M. Mangeas, M. Petit, C. Corbane, P. Ha-\nShi,\
    \ Michael W. Spencer, Samuel W. Thurman, Leung mon, S. Hamon, A. De Kochko, D.\
    \ Le Pierres, V. Pon-\nTsang, and Jakob Van Zyl. The Soil Moisture Active cet,\
    \ and M. Despinoy. Use of high-resolution satellite\nPassive (SMAP) Mission. Proceedings\
    \ of the IEEE, imagery in an integrated model to predict the distri-\n98(5):704\u2013\
    716, May 2010. ISSN 1558-2256. doi: bution of shade coffee tree hybrid zones.\
    \ REMOTE\n10.1109/JPROC.2010.2043918. SENSING OF ENVIRONMENT, 114(11):2731\u2013\
    2744,\n[29] Puyu Feng, Bin Wang, De Li Liu, and Qiang Yu. November 2010. ISSN\
    \ 0034-4257. doi: 10.1016/j.rse.\nMachine learning-based integration of remotely-sensed\
    \ 2010.06.007.\ndrought factors can improve the estimation of agricul- [38] Cristina\
    \ G\xF3mez, Joanne C. White, and Michael A.\ntural drought in South-Eastern Australia.\
    \ AGRICUL- Wulder. Optical remotely sensed time series data for\nTURAL SYSTEMS,\
    \ 173:303\u2013316, July 2019. ISSN land cover classi\uFB01cation: A review. ISPRS\
    \ Journal of\n0308-521X. doi: 10.1016/j.agsy.2019.03.015. PhotogrammetryandRemote\
    \ Sensing,116:55\u201372,June\n[30] Matheus Pinheiro Ferreira, Rodolfo Georjute\
    \ Lotte, 2016. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2016.\nFrancisco D\u2019\
    Elia, V, Christos Stamatopoulos, Do- 03.008.\nHyungKim,andAdamR.Benjamin.Accuratemapping\
    \ [39] Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\nof Brazil nut trees\
    \ (Bertholletia excelsa) in Amazo- Deep Learning. MIT Press, 2016.\nnian forests\
    \ using WorldView-3 satellite images and [40] T. W. Grif\uFB01n and J. Lowenberg-DeBoer.\
    \ Worldwide\nconvolutional neural networks. ECOLOGICAL IN- adoption and pro\uFB01\
    tability of precision agriculture Im-\nFORMATICS, 63, July 2021. ISSN 1574-9541.\
    \ doi: plications for Brazil. Revista de Pol\xEDtica Agr\xEDcola, 14\n10.1016/j.ecoinf.2021.101302.\
    \ (4):20\u201337, 2005. ISSN 2317-224X.\n[31] Steffen Fritz, Linda See, Juan Carlos\
    \ Laso Bayas, [41] Vahid Habibi, Hasan Ahmadi, Mohammad Jafari, and\nFran\xE7\
    ois Waldner, Damien Jacques, Inbal Becker- Abolfazl Moeini. Quantitative assessment\
    \ of soil salin-\nReshef, Alyssa Whitcraft, Bettina Baruth, Rogerio ity using\
    \ remote sensing data based on the arti\uFB01cial\nBonifacio, Jim Crutch\uFB01\
    eld, Felix Rembold, Oscar Ro- neural network, case study: Sharif Abad Plain, Central\n\
    jas, Anne Schucknecht, Marijn Van der Velde, James Iran. MODELING EARTH SYSTEMS\
    \ AND ENVIRON-\nVerdin, Bingfang Wu, Nana Yan, Liangzhi You, Sven MENT, 7(2):1373\u2013\
    1383, June 2021. ISSN 2363-6203.16\ndoi: 10.1007/s40808-020-01015-1. tion characterization.\
    \ Remote Sensing of Environment,\n[42] Amir Haghverdi, Robert A. Washington-Allen,\
    \ and 113:S56\u2013S66, September 2009. ISSN 0034-4257. doi:\nBrian G. Leib. Prediction\
    \ of cotton lint yield from 10.1016/j.rse.2008.01.026.\nphenology of crop indices\
    \ using arti\uFB01cial neural net- [52] ShunpingJi,ChiZhang,AnjianXu,YunShi,andYulin\n\
    works. COMPUTERS AND ELECTRONICS IN AGRI- Duan. 3D Convolutional Neural Networks\
    \ for Crop\nCULTURE,152:186\u2013197,September2018.ISSN0168- Classi\uFB01cationwithMulti-TemporalRemoteSensingIm-\n\
    1699. doi: 10.1016/j.compag.2018.07.021. ages. REMOTE SENSING, 10(1), January\
    \ 2018. doi:\n[43] A. M. Hamer, D. M. Simms, and T. W. Waine. Re- 10.3390/rs10010075.\n\
    placing human interpretation of agricultural land in [53] YuJin,JiaweiGuo,HuichunYe,JinlingZhao,Wenjiang\n\
    Afghanistan with a deep convolutionalneural network. Huang, and Bei Cui. Extraction\
    \ of Arecanut Planting\nINTERNATIONAL JOURNAL OF REMOTE SENSING, Distribution\
    \ Based on the Feature Space Optimization\n42(8):3017\u20133038, April 2021. ISSN\
    \ 0143-1161. doi: of PlanetScope Imagery. AGRICULTURE-BASEL, 11\n10.1080/01431161.2020.1864059.\
    \ (4), April 2021. doi: 10.3390/agriculture11040371.\n[44] Kaiming He, Xiangyu\
    \ Zhang, Shaoqing Ren, and Jian [54] Sungha Ju, Hyoungjoon Lim, Jong Won Ma, Soohyun\n\
    Sun. IdentityMappingsin DeepResidualNetworks. In Kim, Kyungdo Lee, Shuhe Zhao,\
    \ and Joon Heo. Op-\nBastianLeibe,JiriMatas,NicuSebe,andMaxWelling, timal county-levelcrop\
    \ yield prediction using MODIS-\neditors, Computer Vision - ECCV 2016, Lecture\
    \ Notes based variables and weather data: A comparative\nin Computer Science,\
    \ pages 630\u2013645, Cham, 2016. study on machine learning models. AGRICUL-\n\
    Springer International Publishing. ISBN 978-3-319- TURALANDFORESTMETEOROLOGY,307,Septem-\n\
    46493-0. doi: 10.1007/978-3-319-46493-0\\_38. ber 2021. ISSN 0168-1923. doi: 10.1016/j.agrformet.\n\
    [45] M. Herold, J. S. Latham, A. Di Gregorio, and C. C. 2021.108530.\nSchmullius.\
    \ Evolving standards in land cover char- [55] Teja Kattenborn, Jens Leitloff,\
    \ Felix Schiefer, and Ste-\nacterization. Journal of Land Use Science, 1(2-4):\
    \ fan Hinz. Review on Convolutional Neural Networks\n157\u2013168, December 2006.\
    \ ISSN 1747-423X. doi: (CNN) in vegetation remote sensing. ISPRS Journal\n10.1080/17474230601079316.\
    \ of Photogrammetry and Remote Sensing, 173:24\u201349,\n[46] GeoffreyE.Hinton,NitishSrivastava,AlexKrizhevsky,\
    \ March2021. ISSN 0924-2716. doi:10.1016/j.isprsjprs.\nIlyaSutskever,andRuslanR.Salakhutdinov.Improving\
    \ 2020.12.010.\nneural networks by preventing co-adaptation of feature [56] Yann\
    \ H. Kerr,Philippe Waldteufel, Philippe Richaume,\ndetectors, July 2012. JeanPierreWigneron,PaoloFerrazzoli,AliMahmoodi,\n\
    [47] Mitchell C. Hunter, Richard G. Smith, Meagan E. Ahmad Al Bitar, Fran\xE7\
    ois Cabot, Claire Gruhier, Sil-\nSchipanski, Lesley W. Atwood, and David A. via\
    \ Enache Juglea, Delphine Leroux, Arnaud Mialon,\nMortensen. Agriculture in 2050:\
    \ Recalibrating Targets andStevenDelwart. TheSMOSSoilMoistureRetrieval\nfor Sustainable\
    \ Intensi\uFB01cation. BioScience, 67(4):386\u2013 Algorithm. IEEE Transactions\
    \ on Geoscience and\n391,April2017. ISSN0006-3568. doi:10.1093/biosci/ Remote\
    \ Sensing, 50(5):1384\u20131403, May 2012. ISSN\nbix010. 1558-0644. doi: 10.1109/TGRS.2012.2184548.\n\
    [48] Jordi Inglada, Marcela Arias, Benjamin Tardy, Olivier [57] Saeed Khaki, Hieu\
    \ Pham, and Lizhi Wang. Simulta-\nHagolle, Silvia Valero, David Morin, G\xE9rard\
    \ Dedieu, neous corn and soybean yield prediction from remote\nGuadalupe Sepulcre,\
    \ Sophie Bontemps, Pierre De- sensing data using deep transferlearning. SCIENTIFIC\n\
    fourny, and Benjamin Koetz. Assessment of an Op- REPORTS, 11(1), May 2021. ISSN\
    \ 2045-2322. doi:\nerational System for Crop Type Map Production Using 10.1038/s41598-021-89779-z.\n\
    High Temporaland Spatial Resolution Satellite Optical [58] Reza Khatami, Giorgos\
    \ Mountrakis, and Stephen V.\nImagery. Remote Sensing, 7(9):12356\u201312379,Septem-\
    \ Stehman. A meta-analysis of remote sensing research\nber 2015. ISSN 2072-4292.\
    \ doi: 10.3390/rs70912356. on supervised pixel-based land-cover image classi\uFB01\
    ca-\n[49] RobertoInterdonato,DinoIenco,RaffaeleGaetano,and tion processes: General\
    \ guidelinesfor practitionersand\nKenji Ose. DuPLO: A DUal view Point deep Learn-\
    \ future research. Remote Sensing of Environment, 177:\ning architecture for time\
    \ series classi\uFB01catiOn. ISPRS 89\u2013100, May 2016. ISSN 0034-4257. doi:\
    \ 10.1016/j.\nJOURNAL OF PHOTOGRAMMETRY AND REMOTE rse.2016.02.028.\nSENSING,\
    \ 149:91\u2013104,March 2019. ISSN 0924-2716. [59] Oz Kira, Anthony L. Nguy-Robertson,\
    \ Timothy J.\ndoi: 10.1016/j.isprsjprs.2019.01.011. Arkebauer, Raphael Linker,\
    \ and Anatoly A. Gitelson.\n[50] Sergey Ioffe and Christian Szegedy. Batch Normaliza-\
    \ Toward Generic Models for Green LAI Estimation in\ntion:AcceleratingDeepNetworkTrainingbyReducing\
    \ Maize and Soybean: Satellite Observations. REMOTE\nInternal Covariate Shift.\
    \ In Proceedings of the 32nd SENSING, 9(4), April 2017. ISSN 2072-4292. doi:\n\
    International Conference on Machine Learning, pages 10.3390/rs9040318.\n448\u2013\
    456. PMLR, June 2015. [60] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-\n\
    [51] St\xE9phane Jacquemoud, Wout Verhoef, Fr\xE9d\xE9ric Baret, ton. ImageNet\
    \ Classi\uFB01cation with Deep Convolutional\nC\xE9dric Bacour, Pablo J. Zarco-Tejada,\
    \ Gregory P. Neural Networks. In Advances in Neural Information\nAsner, Christophe\
    \ Fran\xE7ois, and Susan L. Ustin. ProcessingSystems,volume25,pages1106\u2013\
    1114.Cur-\nPROSPECT+SAILmodels:Areviewofuseforvegeta- ran Associates, Inc., 2012.17\n\
    [61] Nataliia Kussul, MykolaLavreniuk,SergiiSkakun,and earscirev.2021.103858.\n\
    AndriiShelestov. DeepLearningClassi\uFB01cationofLand [71] R. B. MacDonald and\
    \ F. G. Hall. Global Crop Fore-\nCover and Crop Types Using Remote Sensing Data.\
    \ casting. Science, 208(4445):670\u2013679, May 1980. doi:\nIEEE GEOSCIENCE AND\
    \ REMOTE SENSING LET- 10.1126/science.208.4445.670.\nTERS, 14(5):778\u2013782,\
    \ May 2017. ISSN 1545-598X. [72] Khairiya Mudrik Masoud, Claudio Persello, and\
    \ Va-\ndoi: 10.1109/LGRS.2017.2681128. lentyn A. Tolpekin. Delineation of Agricultural\
    \ Field\n[62] Ainong Li, Shunlin Liang, Angsheng Wang, and Jun Boundaries from\
    \ Sentinel-2 Images Using a Novel\nQin. Estimatingcropyieldfrommulti-temporalsatellite\
    \ Super-Resolution Contour Detector Based on Fully\ndata using multivariate regression\
    \ and neural network Convolutional Networks. REMOTE SENSING, 12(1),\ntechniques.\
    \ PHOTOGRAMMETRIC ENGINEERING January 2020. doi: 10.3390/rs12010059.\nAND REMOTE\
    \ SENSING, 73(10):1149\u20131157,October [73] Heather McNairn, Catherine Champagne,\
    \ Jiali Shang,\n2007. ISSN 0099-1112. doi: 10.14358/PERS.73.10. Delmar Holmstrom,\
    \ and Gordon Reichert. Integration\n1149. ofopticalandSyntheticApertureRadar(SAR)imagery\n\
    [63] Jingtao Li, Yonglin Shen, and Chao Yang. An Adver- for delivering operational\
    \ annual crop inventories. IS-\nsarial Generative Network for Crop Classi\uFB01\
    cation from PRS Journal of Photogrammetry and Remote Sensing,\nRemote Sensing\
    \ Timeseries Images. REMOTE SENS- 64(5):434\u2013449,September2009. ISSN0924-2716.doi:\n\
    ING, 13(1), January 2021. doi: 10.3390/rs13010065. 10.1016/j.isprsjprs.2008.07.006.\n\
    [64] Min Li, Zhijie Zhang, Liping Lei, Xiaofan Wang, and [74] G.IMetternichtandJ.AZinck.\
    \ Remotesensingofsoil\nXudong Guo. Agricultural Greenhouses Detection in salinity:\
    \ Potentials and constraints. Remote Sensing of\nHigh-Resolution Satellite Images\
    \ Based on Convolu- Environment,85(1):1\u201320,April2003. ISSN0034-4257.\ntionalNeuralNetworks:Comparisonof\
    \ Faster R-CNN, doi: 10.1016/S0034-4257(02)00188-8.\nYOLO v3 and SSD. SENSORS,\
    \ 20(17), September [75] Nando Metzger, Mehmet Ozgur Turkoglu, Stefano\n2020.\
    \ doi: 10.3390/s20174938. D\u2019Aronco, Jan Dirk Wegner, and Konrad Schindler.\n\
    [65] Weijia Li, Runmin Dong, Haohuan Fu, and Le Yu. Crop Classi\uFB01cation Under\
    \ Varying Cloud Cover With\nLarge-Scale Oil Palm Tree Detection from High- Neural\
    \ Ordinary Differential Equations. IEEE Trans-\nResolution Satellite Images Using\
    \ Two-Stage Convo- actions on Geoscience and Remote Sensing, 60:1\u201312,\nlutional\
    \ Neural Networks. REMOTE SENSING, 11(1), 2022. ISSN 1558-0644. doi: 10.1109/TGRS.2021.\n\
    January 2019. doi: 10.3390/rs11010011. 3101965.\n[66] Chenxi Lin, Zhenong Jin,\
    \ David Mulla, Rahul Ghosh, [76] Monica Y. Moreno-Revelo, Lorena Guachi-Guachi,\n\
    Kaiyu Guan, Vipin Kumar, and Yaping Cai. To- Juan Bernardo Gomez-Mendoza, Javier\
    \ Revelo-\nward Large-Scale Mapping of Tree Crops with High- Fuelagan, and Diego\
    \ H. Peluffo-Ordonez. Enhanced\nResolution Satellite Imagery and Deep Learning\
    \ Al- Convolutional-Neural-Network Architecture for Crop\ngorithms: A Case Study\
    \ of Olive Orchards in Mo- Classi\uFB01cation. APPLIED SCIENCES-BASEL, 11(9),\n\
    rocco. REMOTE SENSING, 13(9), May 2021. doi: May 2021. doi: 10.3390/app11094292.\n\
    10.3390/rs13091740. [77] Aicha Moumni and Abderrahman Lahrouni. Machine\n[67]\
    \ D. Lu and Q. Weng. A survey of image classi\uFB01cation Learning-Based Classi\uFB01\
    cation for Crop-Type Mapping\nmethods and techniques for improving classi\uFB01\
    cation Using the Fusion of High-Resolution Satellite Imagery\nperformance. InternationalJournalof\
    \ Remote Sensing, in a Semiarid Area. SCIENTIFICA, 2021, April 2021.\n28(5):823\u2013\
    870, March 2007. ISSN 0143-1161. doi: ISSN 2090-908X. doi: 10.1155/2021/8810279.\n\
    10.1080/01431160600746456. [78] EmileNdikumana,DinhHoTongMinh,NicolasBagh-\n[68]\
    \ Tingting Lu, Martin Brandt, Xiaoye Tong, Pierre Hi- dadi, Dominique Courault,\
    \ and Laure Hossard. Deep\nernaux, Louise Leroux, Babacar Ndao, and Rasmus Recurrent\
    \ Neural Network for Agricultural Classi\uFB01ca-\nFensholt. Mapping the Abundance\
    \ of Multipurpose tionusingmultitemporalSARSentinel-1forCamargue,\nAgroforestry\
    \ Faidherbia albida Trees in Senegal. RE- France. REMOTE SENSING, 10(8), August\
    \ 2018. doi:\nMOTE SENSING, 14(3), February 2022. doi: 10.3390/ 10.3390/rs10081217.\n\
    rs14030662. [79] David C. Nielsen, Juan J. Miceli-Garcia, and Drew J.\n[69] Huiqin\
    \ Ma, Wenjiang Huang, Yuanshu Jing, Chenghai Lyon.CanopyCoverandLeafAreaIndexRelationships\n\
    Yang, Liangxiu Han, Yingying Dong, Huichun Ye, for Wheat, Triticale, andCorn.\
    \ AgronomyJournal,104\nYue Shi, Qiong Zheng, Linyi Liu, and Chao Ruan. (6):1569\u2013\
    1573, 2012. ISSN 1435-0645. doi: 10.2134/\nIntegrating Growth and Environmental\
    \ Parameters to agronj2012.0107n.\nDiscriminate Powdery Mildew and Aphid of Winter\
    \ [80] E.G. Njoku, T.J. Jackson, V. Lakshmi, T.K. Chan, and\nWheat Using Bi-Temporal\
    \ Landsat-8 Imagery. RE- S.V. Nghiem. Soil moisture retrieval from AMSR-E.\nMOTE\
    \ SENSING, 11(7), April 2019. doi: 10.3390/ IEEETransactionsonGeoscienceandRemoteSensing,\n\
    rs11070846. 41(2):215\u2013229, February 2003. ISSN 1558-0644. doi:\n[70] Zhengjing\
    \ Ma and Gang Mei. Deep learning for 10.1109/TGRS.2002.808243.\ngeologicalhazardsanalysis:Data,models,applications,\
    \ [81] Stella Ofori-Ampofo, Charlotte Pelletier, and Stefan\nand opportunities.\
    \ Earth-ScienceReviews, 223:103858, Lang. Crop Type Mapping from Optical and Radar\n\
    December 2021. ISSN 00128252. doi: 10.1016/j. Time Series Using Attention-Based\
    \ Deep Learning.18\nRemote Sensing, 13(22):4668, January 2021. ISSN poral satellite\
    \ data processing: Classi\uFB01cation of paddy\n2072-4292. doi: 10.3390/rs13224668.\
    \ transplanted\uFB01elds. ECOLOGICALINFORMATICS,61,\n[82] Subir Paul, Mamta Kumari,\
    \ C. S. Murthy, and March 2021. ISSN 1574-9541. doi: 10.1016/j.ecoinf.\nD. Nagesh\
    \ Kumar. Generating pre-harvest crop maps 2021.101214.\nby applying convolutional\
    \ neural network on multi- [92] Andres C. Rodriguez, Rodrigo Caye Daudt, Stefano\n\
    temporalSentinel-1data. INTERNATIONALJOURNAL D\u2019Aronco, Konrad Schindler,\
    \ and Jan D. Wegner. Ro-\nOF REMOTE SENSING, February 2022. ISSN 0143- bust Damage\
    \ Estimation of Typhoon Goni on Coconut\n1161. doi: 10.1080/01431161.2022.2030072.\
    \ Crops with Sentinel-2 Imagery. REMOTE SENSING,\n[83] Oscar D. Pedrayes, Dario\
    \ G. Lema, Daniel F. Garcia, 13(21), November 2021. doi: 10.3390/rs13214302.\n\
    Ruben Usamentiaga, and Angela Alonso. Evaluation [93] Olaf Ronneberger, Philipp\
    \ Fischer, and Thomas Brox.\nof Semantic Segmentation Methods for Land Use with\
    \ U-Net: Convolutional Networks for Biomedical Image\nSpectralImagingUsingSentinel-2andPNOAImagery.\
    \ Segmentation. In Nassir Navab, Joachim Hornegger,\nREMOTE SENSING, 13(12), June\
    \ 2021. doi: 10.3390/ William M. Wells, and Alejandro F. Frangi, editors,\nrs13122292.\
    \ Medical Image Computing and Computer-Assisted In-\n[84] C. Persello, V. A. Tolpekin,\
    \ J. R. Bergado, and R. A. tervention - MICCAI 2015, Lecture Notes in Computer\n\
    de By. Delineation of agricultural\uFB01elds in smallholder Science, pages 234\u2013\
    241, Cham, 2015. Springer Inter-\nfarms from satellite images using fully convolutional\
    \ national Publishing. ISBN 978-3-319-24574-4. doi:\nnetworksandcombinatorialgrouping.\
    \ REMOTESENS- 10.1007/978-3-319-24574-4\\_28.\nING OF ENVIRONMENT, 231,September2019.\
    \ ISSN [94] J.Roughgarden,S.W.Running,andP.A.Matson.What\n0034-4257. doi: 10.1016/j.rse.2019.111253.\
    \ Does Remote Sensing Do For Ecology? Ecology, 72\n[85] Stefano Pignatti, Raffaele\
    \ Casa, Giovanni Laneve, (6):1918\u20131922, 1991. ISSN 1939-9170. doi: 10.2307/\n\
    Zhenhai Li, Linyi Liu, Pablo Marzialetti, Nada Mzid, 1941546.\nSimone Pascucci,\
    \ Paolo Cosmo Silvestro, Massimo [95] D. P. Roy, M. A. Wulder, T. R. Loveland,\
    \ Woodcock\nTolomio, Deepak Upreti, Hao Yang, Guijun Yang, and C.e., R. G. Allen,\
    \ M. C. Anderson, D. Helder, J. R.\nWenjiang Huang. Sino-EU Earth Observation\
    \ Data to Irons, D. M. Johnson, R. Kennedy, T. A. Scambos,\nSupport the Monitoring\
    \ and Management of Agricul- C. B. Schaaf, J. R. Schott, Y. Sheng, E. F. Vermote,\n\
    tural Resources. REMOTE SENSING, 13(15), August A. S. Belward, R. Bindschadler,\
    \ W. B. Cohen, F. Gao,\n2021. doi: 10.3390/rs13152889. J. D. Hipple, P. Hostert,\
    \ J. Huntington, C. O. Justice,\n[86] GuanghuiQi,GengxingZhao,andXueXi.SoilSalinity\
    \ A. Kilic, V. Kovalskyy, Z. P. Lee, L. Lymburner, J. G.\nInversion of Winter\
    \ Wheat Areas Based on Satellite- Masek,J.McCorkel,Y.Shuai,R.Trezza,J.Vogelmann,\n\
    Unmanned Aerial Vehicle-Ground Collaborative Sys- R. H. Wynne, and Z. Zhu. Landsat-8:\
    \ Science and\ntem in Coastal of the Yellow River Delta. SENSORS, product vision\
    \ for terrestrial global change research.\n20(22), November 2020. doi: 10.3390/s20226521.\
    \ Remote Sensing of Environment, 145:154\u2013172, April\n[87] MengjiaQiao,XiaohuiHe,XijieCheng,PanleLi,Hao-\
    \ 2014. ISSN0034-4257.doi:10.1016/j.rse.2014.02.001.\ntian Luo, Zhihui Tian, and\
    \ Hengliang Guo. Exploiting [96] Marc Ru\xDFwurm and Marco Koerner. Self-attention\
    \ for\nHierarchical Features for Crop Yield Prediction Based raw optical Satellite\
    \ Time Series Classi\uFB01cation. ISPRS\non3-DConvolutionalNeuralNetworksandMultikernel\
    \ JOURNAL OF PHOTOGRAMMETRY AND REMOTE\nGaussian Process. IEEE JOURNAL OF SELECTED\
    \ SENSING, 169:421\u2013435,November 2020. ISSN 0924-\nTOPICS IN APPLIED EARTH\
    \ OBSERVATIONS AND 2716. doi: 10.1016/j.isprsjprs.2020.06.006.\nREMOTE SENSING,14:4476\u2013\
    4489,2021. ISSN 1939- [97] Marc Ru\xDFwurm and Marco K\xF6rner. Multi-Temporal\n\
    1404. doi: 10.1109/JSTARS.2021.3073149. Land Cover Classi\uFB01cation with Sequential\
    \ Recurrent\n[88] Saman Rabiei, Ehsan Jalilvand, and Massoud Tajr- Encoders. ISPRS\
    \ International Journal of Geo-\nishy. A Method to Estimate Surface Soil Moisture\
    \ and Information, 7(4):129, April 2018. ISSN 2220-9964.\nMap the Irrigated Cropland\
    \ Area Using Sentinel-1 and doi: 10.3390/ijgi7040129.\nSentinel-2 Data. Sustainability,\
    \ 13(20):11355, January [98] Marc Ru\xDFwurm, Charlotte Pelletier, Maximilian\
    \ Zoll-\n2021. ISSN 2071-1050. doi: 10.3390/su132011355. ner,S\xE9bastienLef\xE8\
    vre,andMarcoK\xF6rner.BreizhCrops:\n[89] Fatemeh Rahimi-Ajdadi and Mahdi Khani.\
    \ Remote A time series dataset for crop type mapping. In-\nsensing-based detection\
    \ of tea land losses: The case of ternational Archives of the Photogrammetry,\
    \ Re-\nLahijan, Iran. REMOTE SENSING APPLICATIONS- mote Sensing and Spatial Information\
    \ Sciences IS-\nSOCIETY AND ENVIRONMENT, 23, August 2021. PRS (2020), pages 1545\u2013\
    1551, 2020. doi: 10.5194/\nISSN 2352-9385. doi: 10.1016/j.rsase.2021.100568. isprs-archives-XLIII-B2-2020-1545-2020.\n\
    [90] Muhammad Moshiur Rahman, Andrew Robson, and [99] VasitSagan,MaitiniyaziMaimaitijiang,SouravBhadra,\n\
    Mila Bristow. Exploring the Potential of High Res- Matthew Maimaitiyiming, Davis\
    \ R. Brown, Pahed-\nolution WorldView-3 Imagery for Estimating Yield of ing Sidike,\
    \ and Felix B. Fritschi. Field-scale crop\nMango. REMOTE SENSING, 10(12), December\
    \ 2018. yieldpredictionusingmulti-temporalWorldView-3and\ndoi: 10.3390/rs10121866.\
    \ PlanetScope satellite data and deep learning. ISPRS\n[91] Anuvi Rawat, Anil\
    \ Kumar, Priyadarshi Upadhyay, and JOURNAL OF PHOTOGRAMMETRY AND REMOTE\nShashi\
    \ Kumar. Deep learning-based models for tem- SENSING, 174:265\u2013281,April2021.\
    \ ISSN 0924-2716.19\ndoi: 10.1016/j.isprsjprs.2021.02.008. JOURNALOFAPPLIEDEARTHOBSERVATIONAND\n\
    [100] Ieda Del\u2019Arco Sanches, Raul Queiroz Feitosa, Pe- GEOINFORMATION, 102,\
    \ October 2021. ISSN 1569-\ndro Marco Achanccaray Diaz, Marinalva Dias Soares,\
    \ 8432. doi: 10.1016/j.jag.2021.102375.\nAlfredo Jose Barreto Luiz, Bruno Schultz,\
    \ and Luis [111] M. C. Tirado, R. Clarke, L. A. Jaykus, A. McQuatters-\nEduardo\
    \ Pinheiro Maurano. Campo Verde Database, Gollop, and J. M. Frank. Climate change\
    \ and food\nOctober 2017. safety: A review. Food Research International, 43(7):\n\
    [101] EkremSaraliogluandOguzGungor. Semanticsegmen- 1745\u20131765, August 2010.\
    \ ISSN 0963-9969. doi: 10.\ntation of land cover from high resolution multispec-\
    \ 1016/j.foodres.2010.07.003.\ntral satellite images by spectral-spatial convolutional\
    \ [112] Jiri Tomicek, Jan Misurec, and Petr Lukes. Proto-\nneural network. GEOCARTO\
    \ INTERNATIONAL, 37 typing a Generic Algorithm for Crop Parameter Re-\n(2):657\u2013\
    677, January 2022. ISSN 1010-6049. doi: trieval across the Season Using Radiative\
    \ Transfer\n10.1080/10106049.2020.1734871. Model Inversion and Sentinel-2 Satellite\
    \ Observations.\n[102] SERCO. Copernicus Sentinel Data Access Annual Re- REMOTE\
    \ SENSING, 13(18), September 2021. doi:\nport2021. https://sentinels.copernicus.eu/web/sentinel/-\
    \ 10.3390/rs13183659.\n/copernicus-sentinel-data-access-annual-report- [113] Ramon\
    \ Torres, Paul Snoeij, Dirk Geudtner, David\n2021/1.2, 2021. Bibby, Malcolm Davidson,\
    \ Evert Attema, Pierre\n[103] Andrii Shelestov, Mykola Lavreniuk, Nataliia Kussul,\
    \ Potin, Bj\xF6rn Rommen, Nicolas Floury, Mike Brown,\nAlexei Novikov, and Sergii\
    \ Skakun. Exploring Google Ignacio Navas Traver, Patrick Deghaye, Berthyl\nEarth\
    \ Engine Platform for Big Data Processing: Clas- Duesmann, Betlem Rosich, Nuno\
    \ Miranda, Claudio\nsi\uFB01cation of Multi-TemporalSatellite Imageryfor Crop\
    \ Bruno, Michelangelo L\u2019Abbate, Renato Croci, Andrea\nMapping. FRONTIERS\
    \ IN EARTH SCIENCE, 5:1\u201310, Pietropaolo, Markus Huchler, and Friedhelm Rostan.\n\
    February 2017. doi: 10.3389/feart.2017.00017. GMES Sentinel-1 mission. Remote\
    \ Sensing of Envi-\n[104] Karen Simonyan and Andrew Zisserman. Very Deep ronment,\
    \ 120:9\u201324, May 2012. ISSN 0034-4257. doi:\nConvolutionalNetworks for Large-Scale\
    \ Image Recog- 10.1016/j.rse.2011.05.028.\nnition, April 2015. [114] Mehmet Ozgur\
    \ Turkoglu, Stefano D\u2019Aronco, Gre-\n[105] Ying-Qiang Song, Xin Zhao, Hui-Yue\
    \ Su, Bo Li, Yue- gor Perich, Frank Liebisch, Constantin Streit, Konrad\nMing\
    \ Hu, and Xue-Sen Cui. Predicting Spatial Vari- Schindler, and Jan Dirk Wegner.\
    \ Crop mapping from\nations in Soil Nutrients with Hyperspectral Remote image\
    \ time series: Deep learningwith multi-scale label\nSensingatRegionalScale. SENSORS,18(9),September\
    \ hierarchies. REMOTE SENSING OF ENVIRONMENT,\n2018. doi: 10.3390/s18093086. 264,\
    \ October 2021. ISSN 0034-4257. doi: 10.1016/j.\n[106] Dimitrios Sykas, Maria\
    \ Sdraka, Dimitrios Zografakis, rse.2021.112603.\nand Ioannis Papoutsis. A sentinel-2\
    \ multiyear, multi- [115] UnitedNations.WorldPopulationProspectsHighlights,\n\
    country benchmark dataset for crop classi\uFB01cation and 2019 Revision Highlights.\
    \ 2019. ISBN 978-92-1-\nsegmentation with deep learning. IEEE JOURNAL OF 148316-1.\n\
    SELECTED TOPICS IN APPLIED EARTH OBSERVA- [116] USDA. National Agricultural Statistics\n\
    TIONSANDREMOTESENSING,15:3323\u20133339,2022. Service Cropland Data Layer. Published\
    \ crop-\nISSN 1939-1404. doi:10.1109/JSTARS.2022.3164771. speci\uFB01c data layer\
    \ [Online]. Available at:\n[107] Pengfei Tang, Peijun Du, Junshi Xia, Peng Zhang,\
    \ https://nassgeodata.gmu.edu/CropScape/. USDA-\nand Wei Zhang. Channel Attention-Based\
    \ Temporal NASS, Washington, DC, 2022.\nConvolutionalNetwork for Satellite Image\
    \ Time Series [117] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nClassi\uFB01\
    cation. IEEE Geoscience and Remote Sens- Uszkoreit,LlionJones,AidanNGomez,LukaszKaiser,\n\
    ing Letters, 19:1\u20135, 2022. ISSN 1558-0571. doi: and Illia Polosukhin. Attention\
    \ is All you Need. In\n10.1109/LGRS.2021.3095505. Advances in Neural Information\
    \ Processing Systems,\n[108] Nima Teimouri, Mads Dyrmann, and Rasmus Nyholm volume\
    \ 30, pages 5998\u20136008. Curran Associates, Inc.,\nJorgensen. A Novel Spatio-TemporalFCN-LSTM\
    \ Net- 2017.\nworkforRecognizingVariousCropTypesUsingMulti- [118] Shyamal S. Virnodkar,\
    \ Vinod K. Pachghare, Virupak-\nTemporal Radar Images. REMOTE SENSING, 11(8),\
    \ shagouda C. Patil, and Sunil Kumar Jha. DenseRe-\nApril 2019. doi: 10.3390/rs11080990.\
    \ sUNet: An Architecture to Assess Water-Stressed\n[109] K. R. Thorp and D. Drajat.\
    \ Deep machine learning Sugarcane Crops from Sentinel-2 Satellite Imagery.\nwithSentinelsatellitedatatomappaddyriceproduction\
    \ TRAITEMENT DU SIGNAL, 38(4):1131\u20131139,August\nstagesacrossWestJava,Indonesia.REMOTESENSING\
    \ 2021. ISSN 0765-0019. doi: 10.18280/ts.380424.\nOF ENVIRONMENT, 265, November\
    \ 2021. ISSN [119] Wolfgang Wagner, Sebastian Hahn, Richard Kidd,\n0034-4257.\
    \ doi: 10.1016/j.rse.2021.112679. ThomasMelzer,ZoltanBartalis,StefanHasenauer,Julia\n\
    [110] Huiren Tian, Pengxin Wang, Kevin Tansey, Dong Han, Figa-Salda\xF1a, Patricia\
    \ de Rosnay, Alexander Jann, Ste-\nJingqi Zhang, Shuyu Zhang, and Hongmei Li.\
    \ A fan Schneider, J\xFCrgen Komma, Gerhard Kubu, Katha-\ndeeplearningframeworkunderattentionmechanismfor\
    \ rina Brugger, Christoph Aubrecht, Johann Z\xFCger, Ute\nwheat yield estimation\
    \ using remotely sensed indices Gangkofner, Stefan Kienberger, Luca Brocca, Yong\n\
    in the Guanzhong Plain, PR China. INTERNATIONAL Wang, G\xFCnter Bl\xF6schl, Josef\
    \ Eitzinger, and Kla Stein-20\nnocher. The ASCAT Soil Moisture Product: A Review\
    \ [129] Aleksandra Wolanin, Gonzalo Mateo-Garcia, Gustau\nof its Speci\uFB01cations,\
    \ Validation Results, and Emerging Camps-Valls, Luis Gomez-Chova, Michele Meroni,\n\
    Applications. Meteorologische Zeitschrift, pages 5\u201333, GregoryDuveiller,YouLiangzhi,andLuisGuanter.Es-\n\
    February 2013. ISSN ,. doi: 10.1127/0941-2948/2013/ timatingandunderstandingcropyieldswithexplainable\n\
    0399. deep learning in the Indian Wheat Belt. ENVIRON-\n[120] Fran\xE7ois Waldner\
    \ and Foivos I. Diakogiannis. Deep MENTALRESEARCHLETTERS,15(2),February2020.\n\
    learning on edge: Extracting \uFB01eld boundaries from ISSN 1748-9326. doi: 10.1088/1748-9326/ab68ac.\n\
    satellite images with a convolutional neural network. [130] Qiong Wu, Yunxiang\
    \ Jin, Yuhai Bao, Quansheng\nRemote Sensing of Environment, 2019. doi: 10.1016/j.\
    \ Hai, Ruirui Yan, Baorui Chen, Hongbin Zhang, Bao-\nrse.2020.111741. hui Zhang,\
    \ Zhenwang Li, Xiaoyu Li, and Xiaoping\n[121] Francois Waldner, Foivos I. Diakogiannis,\
    \ Kathryn Xin. Comparison of two inversion methods for leaf\nBatchelor, Michael\
    \ Ciccotosto-Camp, Elizabeth area index using HJ-1 satellite data in a temperate\n\
    Cooper-Williams, Chris Herrmann, Gonzalo Mata, meadow steppe. INTERNATIONAL JOURNAL\
    \ OF\nand Andrew Toovey. Detect, Consolidate, Delineate: REMOTESENSING,36(19-20,SI):5192\u2013\
    5207,October\nScalable Mapping of Field Boundaries Using Satellite 2015. ISSN\
    \ 0143-1161. doi: 10.1080/01431161.2015.\nImages. REMOTE SENSING, 13(11), June\
    \ 2021. doi: 1040135.\n10.3390/rs13112197. [131] Jinfan Xu, Yue Zhu, Renhai Zhong,\
    \ Zhixian Lin, Jialu\n[122] Li Wang, Yong Zhou, Jingyi Liu, Yujie Liu, Qian Zuo,\
    \ Xu, Hao Jiang, Jingfeng Huang, Haifeng Li, and Tao\nand Qing Li. Exploring the\
    \ potential of multispectral Lin. DeepCropMapping: A multi-temporal deep learn-\n\
    satellite imagesforestimatingthe contentsofcadmium ing approach with improved\
    \ spatial generalizability\nand lead in cropland: The effect of the dimidiate\
    \ pixel for dynamic corn and soybean mapping. REMOTE\nmodel and random forest.\
    \ JOURNAL OF CLEANER SENSING OF ENVIRONMENT, 247, September 2020.\nPRODUCTION,\
    \ 367, September 2022. ISSN 0959- ISSN 0034-4257. doi: 10.1016/j.rse.2020.111946.\n\
    6526. doi: 10.1016/j.jclepro.2022.132922. [132] Sijing Ye, Shuhan Lu, Xuesong\
    \ Bai, and Jinfeng Gu.\n[123] Sherrie Wang, William Chen, Sang Michael Xie, ResNet-Locust-BN\
    \ Network-Based Automatic Identi-\nSangMichaelXie,GeorgeAzzari,andDavidB.Lobell.\
    \ \uFB01cation of East Asian Migratory Locust Species and\nWeakly SupervisedDeep\
    \ Learningfor Segmentationof Instars from RGB Images. INSECTS, 11(8), August\n\
    Remote Sensing Imagery. Remote Sensing, 2020. doi: 2020. doi: 10.3390/insects11080458.\n\
    10.3390/rs12020207. [133] Lin Yuan, Jingcheng Zhang, Yeyin Shi, Chenwei Nie,\n\
    [124] Sherrie Wang, Stefania Di Tommaso, Joey Faulkner, Liguang Wei, and Jihua\
    \ Wang. Damage Mapping\nThomas Friedel, Alexander Kennepohl, Rob Strey, and of\
    \ Powdery Mildew in Winter Wheat with High-\nDavid B. Lobell. Mapping Crop Types\
    \ in Southeast Resolution Satellite Image. REMOTE SENSING, 6(5):\nIndiawithSmartphoneCrowdsourcingandDeepLearn-\
    \ 3611\u20133623, May 2014. doi: 10.3390/rs6053611.\ning. REMOTESENSING,12(18),September2020.\
    \ doi: [134] Bo Zhang, Bin Guo, Bin Zou, Wei Wei, Yongzhi Lei,\n10.3390/rs12182957.\
    \ and Tianqi Li. Retrieving soil heavy metals concentra-\n[125] Xiaoping Wang,\
    \ Fei Zhang, Jianli Ding, Hsiang-te tions based on GaoFen-5 hyperspectral satellite\
    \ image\nKung, Aamir Latif, and Verner C. Johnson. Estimation at an opencast coal\
    \ mine, Inner Mongolia, China. EN-\nof soil salt content (SSC) in the Ebinur Lake\
    \ Wetland VIRONMENTAL POLLUTION, 300, May 2022. ISSN\nNationalNatureReserve(ELWNNR),NorthwestChina,\
    \ 0269-7491. doi: 10.1016/j.envpol.2022.118981.\nbased on a Bootstrap-BP neural\
    \ network model and [135] Liangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan\noptimal\
    \ spectral indices. SCIENCE OF THE TOTAL Cao, Ruizhi Xie, and Shaokun Li. Integratingsatellite-\n\
    ENVIRONMENT, 615:918\u2013930, February 2018. ISSN derivedclimaticandvegetationindicestopredictsmall-\n\
    0048-9697. doi: 10.1016/j.scitotenv.2017.10.025. holder maize yield using deep\
    \ learning. AGRICUL-\n[126] YumiaoWang, ZhouZhang,LuweiFeng, QingyunDu, TURALAND\
    \ FORESTMETEOROLOGY, 311,Decem-\nand Troy Runge. Combining Multi-Source Data and\
    \ ber 2021. ISSN 0168-1923. doi: 10.1016/j.agrformet.\nMachineLearningApproachestoPredictWinterWheat\
    \ 2021.108666.\nYield in the Conterminous United States. REMOTE [136] Ya\u2019\
    nan Zhou, Jiancheng Luo, Li Feng, Yingpin Yang,\nSENSING,12(8),April2020. doi:10.3390/rs12081232.\
    \ YuehongChen,andWeiWu. Long-short-term-memory-\n[127] FernandoWatson-Hernandez,NataliaGomez-Calderon,\
    \ based crop classi\uFB01cation using high-resolution optical\nandRouversonPereiradaSilva.\
    \ Oilpalmyieldestima- images and multi-temporal SAR data. GISCIENCE\ntionbasedonvegetationandhumidityindicesgenerated\
    \ & REMOTE SENSING, 56(8):1170\u20131191, November\nfrom satellite images and\
    \ machine learning techniques. 2019. ISSN 1548-1603. doi: 10.1080/15481603.2019.\n\
    AGRIENGINEERING, 4(1):279\u2013291,March 2022. doi: 1628412.\n10.3390/agriengineering4010019.\
    \ [137] Zhe Zhu, Michael A. Wulder, David P. Roy, Curtis E.\n[128] M. Weiss, F.\
    \ Jacob, and G. Duveiller. Remote sensing Woodcock, Matthew C. Hansen, Volker\
    \ C. Radeloff,\nfor agricultural applications: A meta-review. Remote Sean P. Healey,\
    \ Crystal Schaaf, Patrick Hostert, Pe-\nSensing of Environment, 236:111402, January\
    \ 2020. ter Strobl, Jean-Francois Pekel, Leo Lymburner, Nima\nISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2019.111402. Pahlevan, and Ted A. Scambos. Bene\uFB01ts of\
    \ the free21\nand open Landsat data policy. Remote Sensing of\nEnvironment, 224:382\u2013\
    385, April 2019. ISSN 0034-\n4257. doi: 10.1016/j.rse.2019.02.016.1 Supplementary\n\
    1.1 Search terms\nThe full list of crop names searchedfor: Wheat, Corn, Maize,\
    \ Orchard,Co\uFB00ee, Vineyard, Soy, Rice, Cotton, Sorghum,\nPeanut*, Tobacco,\
    \ Barley, Grain, Rye, Oat, Millet, Speltz, Canola, Flaxseed, Mustard, Alfalfa,\
    \ Camelina, Beans,\nPotato*,Sugar*,Vegetable*,Fruit,Onion*,Cucumber*,Peas,Lentils,Tomato*,Hops,Herbs,Peach*,Apple*,Grape*,\n\
    Citrus, Pecan*, Almond*, Walnut*, Pear*, Aquaculture, Perrenial, Pistachio*, Triticale,\
    \ Carrot*, Asparagus, Garlic,\nCantaloupes,Prune*,Orange*,Olive*,Broccoli,Avocado*,Pepper*,Pomegranate*,Nectarine*,Plum*,Squash,Apri-\n\
    cot*, Vetch, Lettuce, Pumpkin, Cabbage, Celery, Radish*, Turnip*, Eggplant*, Gourd*\n\
    1.2 Dataset links\nTable 1: Identi\uFB01ed crop segmentation satellite benchmark\
    \ datasets and data sources,along with links to download the\ndataset.\nName Link\n\
    3 LUCAS [d\u2019Andrimont et al., 2021] https://data.jrc.ec.europa.eu/dataset/cfe66a0c-bdee-4074-96e1-a2f7030b9515\n\
    2 Munich dataset https://github.com/MarcCoru/MTLCC\n0\n[Ru\xDFwurm and K\xA8orner,\
    \ 2018]\n2\nBreizhCrops [Ru\xDFwurm et al., 2020] https://github.com/dl4sits/BreizhCrops\n\
    \ \nc ZueriCrop [Turkoglu et al., 2021] https://polybox.ethz.ch/index.php/s/uXfdr2AcXE3QNB6\n\
    e\nReunionIsland[Dupuyand Gaetano, https://dataverse.cirad.fr/dataset.xhtml?persistentId=doi:10.18167/DVN1/YZJQ7Q\n\
    D\n2020]\n5  Campo Verde[Sanches et al., 2017] https://ieee-dataport.org/documents/campo-verde-database\n\
    1 UOS2[Pedrayes et al., 2021] https://zenodo.org/record/4648002\n  PASTIS-R[Garnot\
    \ et al., 2022] https://zenodo.org/record/5735646\n \n] Sen4AgriNet [Sykaset al.,\
    \ 2022] https://github.com/Orion-AI-Lab/S4A\nV\nFrench Land Parcel Identi\uFB01\
    cation https://www.data.gouv.fr/fr/datasets/registre-parcellaire-graphique-rpg-contours-des-\n\
    C\nSystem parcelles-et-ilots-culturaux-et-leur-groupe-de-cultures-majoritaire/\n\
    . Cropland Data LayerUSDA[2022] https://nassgeodata.gmu.edu/CropScape/\ns\nc Corine\
    \ Land Cover https://land.copernicus.eu/pan-european/corine-land-cover\n[ CLUM\
    \ https://www.awe.gov.au/abares/aclump/catchment-scale-land-use-of-australia-\n\
    \ \n  update-december-2020\n2\nv\n2\nEach dataset from the LULC section can be\
    \ downloaded from the links in Table 1.\n7\n2\n1 1.3 Tagged database\n0\n. All\
    \ references for this review are made available as a Zotero rdf \uFB01le. It includes\
    \ notes and tags on all studies.\n0\n1\n2\n2\n:\nv\ni\nX\nr\na\n11.4 All Crop\
    \ Segmentation studies\nHere, we list all of the crop segmentation studies.\n\
    Studies on crop segmentation (up to 2020). N is the number of classes that the\
    \ study distinguished between\n(number of agricultural classes in brackets). VI\
    \ stands for vegetative indices, and indicates whether VIs were used\n(possibly\
    \ in combination with other features). GSD = Ground Spatial Distance/resolution.\
    \ In the labels column, a \u2020\nindicates that the labels are from a dataset\
    \ (see Table 1). The best performing model type in each study is\nunderlined.\
    \ Where no model is underlined, no one model performed best. Where two model types\
    \ are underlined, it\nmeans the model had components of both types. In the Tree\
    \ column: RF = Random Forest, and a tick means any\nother kind of tree. In the\
    \ CNN column: nD = nDCNN, including non-spatial CNNs. In the RNN column: L =\n\
    LSTM, G = GRU, and nD = nD ConvRNN (ConvGRU or ConvLSTM). In the Attn column:\
    \ T = Transformer,P =\nPSE-TAE Garnot et al. [2020] and a tick indicates any other\
    \ transformer-like attention.\nModel\ne M P N N n\nStudy N Images VI GSD Labels\
    \ Tre SV ML CN RN Att Type\nBan [2003] 8 (8) ERS-1, 30m Field Survey X ST-o\n\
    Landsat (T-f)\nKarkee et al. [2009] 2 (1) MODIS X 1km Model-based X P-f\nPena\
    \ et al. [2014] 9 (9) ASTER X 15m Priv. govt. X X X S-o\n(P-f)\nKumar et al. [2015]\
    \ 13 (7) LISS IV 5.8m Field Survey X X P-f\nLoew et al. [2015] 10 (7) RapidEye\
    \ X 6.5m Field Survey RF X X ?-f\nX\nKussul et al. [2017] 11 (7) Sentinel-1, 30m\
    \ Field Survey RF X 1D P-f\nLandsat-8 2D P-s\nST-i\nShelestov et al. 13 (8) Landsat-8\
    \ 30m Field Survey RF X X S-o\n[2017] (P-f)\nBenedettiet al. 13 (4) Sentinel-2,\
    \ X 20m, Reunion RF 2D G ST-f\n[2018] SPOT6/7 2m Island\u2020 ST-c\nJi et al.\
    \ [2018] 9 (4) GaoFen-1/2 X 15m, Image Survey X 2D S-i\n4m 3D ST-c\nKussul et\
    \ al. [2018] 13 (8) Sentinel-1, 10m, Field Survey X P-f\nLandsat-8 30m\nNdikumanaet\
    \ al. 11 (8) Sentinel-1 20m Image Survey RF X L ST-o\n[2018] G (T-f\nT-s)\nInterdonatoet\
    \ al. 13 (4) Sentinel-1/2 X 10m Reunion RF 2D L T-f\n[2019] Island\u2020, G T-s\n\
    Koumia\u2020 2D ST-c\nSidike et al. [2019] 19 WV-3 0.3m Field Survey RF X 1D P-f\n\
    (11) P-s\nTeimouri et al. 16 Sentinel-1 10m Model-based 2D 2D ST-c\n[2019] (13)\n\
    Xie et al. [2019] 15 GaoFen-1 2m Image Survey RF 2D S-i\n(12)\nZhao et al. [2019]\
    \ 5 (5) Sentinel-1 10m Field Survey RF 1D L T-f\nG T-s\nZhou et al. [2019] 7 (7)\
    \ Sentinel-1 10m, Image Survey RF X L ST-o\n5.1m (T-f\nT-s)\nMazzia et al. [2020]\
    \ 3 (3) Sentinel-2 X 10m LUCAS RF X 2D L T-f\nX T-i\nNguyenet al. 2 (1) Sentinel-2,\
    \ 30m, Field Survey 2D L ST-c\n[2020] Landsat-8 10m\nRu\xDFwurm and Koerner 23\
    \ Sentinel-2 10m Pub. govt. RF 1D L T ST-o\n[2020] (18) 2D G (T-f\nT-s)\nWanget\
    \ al. [2020a] 10 Sentinel-1/2 X 10m Field Survey RF 1D T-f\n(10) 3D T-s\nST-c\n\
    Xu et al. [2020] 3 (2) Landsat-8 30m CDL RF X L T T-f\nT-s\n2Studies on crop segmentation\
    \ (year 2021).\nModel\ne M P N N n\nStudy N Images VI GSD Labels Tre SV ML CN\
    \ RN Att Type\nChelali et al. 4 (4) Sentinel-2 10m Pub. govt. 1D L ST-o\n[2021]\
    \ 2D 2D (ST-i)\nChoung and Jung 3(2) KOMPSAT- 0.7m Image Survey X X S-i\n[2021]\
    \ 3\nDebella-Gilo and Gjer3ts(e1n) Sentinel-2 20m Pub. govt. X 1D T-f T-s\n[2021]\
    \ 2D T-i\nFernandez-Sellers et al.111 Sentinel-2 10m Pub. govt. X T-f\n[2021]\
    \ (?)\nFu et al. [2021] 4 (2) GaoFen-1 16m Field/Image 2D S-i\nSurvey\nGallo et\
    \ al. [2021] 17 Sentinel-2 X 10m Munich 3D ST-c\n(17)\nHamer et al. 2 (1) DMC\
    \ 32m Image Survey, RF 2D P-f\n[2021] Model-based S-i\nJin et al. [2021] 2(1)\
    \ PlanetScope X 3m Field Survey RF X X P-f\nLaban et al. 8 (6) Sentinel-2 10m\
    \ Field Survey 2D P-f (S-i)\n[2021]\nLei et al. [2021] 2(2) Zhuhai-1, 10m Field/Image\
    \ 2D S-i\nSentinel- Survey\n1/2\nLi et al. [2021] 3 (2) Landsat-8 30m CDL X 2D\
    \ L ST-c\nLozano-Tello et al. 2(1) Sentinel-2 10m Priv. govt. X P-f\n[2021]\n\
    Martini et al. 9 (7) Sentinel-2 10m BreizhCrops\u2020 T ST-o\n[2021] (T-s)\nMeng\
    \ et al. [2021] 6(2) Zhuhai-1, X 10m Field/Image 1D P-s\nSentinel-2 Survey 2D\
    \ S-i\n3D S-c\nMoreno-Revelo et al. 11 Sentinel-1, 30m Campo Verde\u2020 2D L\
    \ S-iS-s\n[2021] (6) Landsat-8\nMoumni and Lahroun6i (4) Sentinel- X 10m Field/Image\
    \ RF X X T-f\n[2021] 1/2 Survey\nMukharamovaet al. 12 MODIS X 250m Pub. govt.\
    \ RF X L T-s\n[2021] (8)\nOfori-Ampofo et al. 12 Sentinel- 10m Pub. govt. P ST-c\n\
    [2021] (8) 1/2\nPedrayes et al. 11 Sentinel-2 10m UOS2\u2020 RF X 2D P-f\n[2021]\
    \ (4) S-i\nQuinton and Landrieu 20 Sentinel-2 10m Pub. govt. P ST-c\n[2021] (18)\n\
    Rahimi-Ajdadiand K4ha(n2i) Landsat- 30m Field/Image X P-f\n[2021] 5/7/8 Survey,\n\
    Model-based\nRawat et al. 5(4) Sentinel-2, 10m Field Survey 1D 1D T-s\n[2021]\
    \ Landsat-8\nThorp and Drajat 6 (3) Sentinel- X 10m Priv. govt. RF X X 2D L P-f\
    \ S-i\n[2021] 1/2 G T-s ST-c\n2D\nTurkoglu et al. 48 Sentinel-2 10m ZueriCrop\u2020\
    \ RF 2D L T ?-f S-i\n[2021] (41) 2D T-s ST-c\nWu et al. [2021] 2 (1) Sentinel-1\
    \ 10m Model-based 2D S-i\nXie and Huang 2(1) MODIS X 250m Image Survey RF 1D L\
    \ T-f\n[2021] T-s\nZhang et al. 3 (2) Sentinel-2, X 10m, Pub. govt., X T-f\n[2021a]\
    \ Landsat-8 30m Field Survey\nZhao et al. [2021] 7(6) Sentinel-2 10m Field/Image\
    \ 1D L T-s\nSurvey G\n1D\n3Studies on crop segmentation (year 2022).\nModel\n\
    e M P N N n\nStudy N Images VI GSD Labels Tre SV ML CN RN Att Type\nAsminget al.\
    \ 9 (2) Landsat-8, 30m, Image Survey X P-f\n[2022] Sentinel-2 10m\nDesloires et\
    \ al. 2 (1) Sentinel-2 10m Pub. govt. G T-s\n[2022]\nFontanelli et al. 10 (9)\
    \ COSMO- 15m Field Survey 1D T-s\n[2022] SkyMed 3D ST-c\nGarnot et al. 30 Sentinel-1/2\
    \ 10m Pub. govt. 2D P ST-c\n[2022] (27) ST-o\n(T-s)\nJiang et al. 10 (3) Sentinel-2\
    \ 10m CDL RF X X P-f\n[2022] X\nLei et al. [2022] 2 (1) SPOT, X 6m, Pub. govt.\
    \ X X ST-f\nSentinel-1 10m\nLi et al. [2022a] 3 (2) RadarSat-2 X 8m Field Survey\
    \ 1D P-f\nLi et al. [2022c] 15 (3) Jilin-1, 1m, Image Survey 2D X S-i\nGaoFen-2\
    \ 4m\nMetzger et al. 48 Sentinel-2 10m ZeuriCrops\u2020 L T ST-s\n[2022] (41)\
    \ G\nNyborget al. 11 Sentinel-2 X 10m Pub. govt. P ST-o\n[2022] (10) (T-s)\nPaul\
    \ et al. [2022] 6 (5) Sentinel-1 10m Field Survey X X 2D ?-f\nST-i\nPavlovic et\
    \ al. 10 (2) Sentinel-2 10m Image Survey 2D S-i\n[2022]\nRauf et al. [2022] 3\
    \ (2) Sentinel-2 X 10m Field Survey, 2D T-i\nModel-based\nRawat et al. 2 (1) Sentinel-2\
    \ X 10m Field Survey 1D T-s\n[2022]\nSaralioglu and Gungor7 (2) [Commercial] 0.5m\
    \ Image Survey RF X 2D P-f\n[2022] 3D S-i\nS-c\nSharma [2022] 101 Sentinel-2 X\
    \ 10m Pub. govt. 1D T-s\n(4)\nSykaset al. 11 Sentinel-2 X 10m Dataset: 1D 2D T\
    \ ST-c\n[2022] (11) Sen4AgriNet 2D L ST-o\n(T-s)\nTang et al. 13 (8) Sentinel-2\
    \ 10m Breizhcrops\u2020 RF 1D L X T-f\n[2022] T-s\nST-c\nTeimouri et al. 7 (7)\
    \ Sentinel-1/2 10m Pub. govt. X X 2D P-f\n[2022] 3D S-i\nST-c\nWanget al. 4 (3)\
    \ Sentinel-2 10m Pub. govt. 2D T S-i\n[2022a]\nWanget al. 10 (5) Sentinel-2 X\
    \ 10m Field Survey 2D S-i\n[2022c]\nWanget al. 5 (5) MODIS X 1km Model-based RF\
    \ X 1D L T-f\n[2022d] T-s\nYanget al. 4 (3) Sentinel-2 10m Model-based 1D T-s\n\
    [2022] 3D ST-c\n4Studies on speci\uFB01c land cover tasks other than segmentation.\
    \ The best performing model in each study is\nunderlined.\nModel\ne\ne M P N N\
    \ n p\nStudy Task/N Images VI GSD Labels Tre SV ML CN RN Att Ty\nField Boundary\
    \ Detection\nPersello et al. - WV-2/3 0.3m Image Survey 2D S-i\n[2019]\nWaldnerand\
    \ Diakogiannis - Sentinel-2 10m Image Survey 2D S-i\n[2019]\nMasoud et al. - Sentinel-2\
    \ 10m Pub. govt. 2D S-i\n[2020]\nWaldneret al. - Sentinel-2 10m Image Survey 2D\
    \ X S-i\n[2021]\nJong et al. [2022] - MODIS, 10m Pub. govt., 2D S-i\nLandsat,\
    \ Image Survey\nSentinel\nLong et al. - GF-1/2 4m Image Survey 2D S-i\n[2022]\n\
    Shari\uFB01 et al. - Sentinel-2 10m Image Survey 2D S-i\n[2022]\nMei et al. [2022]\
    \ - WV-3 0.5m Image Survey 2D S-i\nDam Detection\nCarvajal et al. - Quickbird\
    \ 1m ??? X P-f\n[2016]\nMalerba et al. - [Maps] - Image Survey 2D S-i\n[2021]\n\
    Ma et al. [2022] - GF1, GF2 15m, Image Survey 2D S-i\n4m\nMalerba et al. - [Maps]\
    \ - Image Survey 2D S-i\n[2022]\nCenter Pivot Irrigation Detection\nZhanget al.\
    \ Classify Landsat-8 30m Image Survey 2D S-i\n[2018]\ndeAlbuquerqueet al.Segment\
    \ Landsat-8 30m Pub. govt. 2D S-i\n[2020]\nSaraiva et al. Segment PlanetScope\
    \ 3m Image Survey 2D S-i\n[2020]\nLi et al. [2022b] Classify Landsat 30m Image\
    \ Survey 2D S-i\nIrrigation Detection\nColligan et al. Segment Landsat 30m Field/Image\
    \ 2D S-i\n[2022] Survey\nGreenhouse Detection\nLi et al. [2020] Detection GF1,\
    \ GF2 2m, Image Survey 2D S-i\n1m\nZhanget al. Segment GF2 0.8m Image Survey 2D\
    \ S-i\n[2021c] Boundary\nHedgerow Detection\nAhlswedeet al. Segment IKONOS 1m\
    \ Field/Image 2D S-i\n[2021] Survey\nTree Crown Delineation\nGomez et al. Segment\
    \ QuickBird 0.6m ??? X P-f\n[2010]\nLi et al. [2019] Classify QuickBird 0.6m Image\
    \ Survey 2D S-i\nFerreira et al. Segment WV-3 0.3m Field/Image 2D S-i\n[2021]\
    \ Survey\nLin et al. [2021] Classify WV-3, 0.3m, Image Survey 2D L S-i\nPlanetScope\
    \ 3m\nAbozeid et al. Segment Satellites.pro ? Image Survey T S-i\n[2022]\nLu et\
    \ al. [2022] Segment Sentinel X 10m Field Survey X P-f\n51.5 All Soil Monitoring\
    \ studies\nStudies on soil health; mostly soil moisture and soil salinity studies.\
    \ VI stands for vegetative indices, and indicates\nwhether VIs were used (possibly\
    \ in combination with other features). GSD = Ground Spatial Distance/resolution.\n\
    The best performing model type in each study is underlined. In the Tree column:\
    \ RF = Random Forest, and a tick\nmeans any other kind of tree. In the CNN column:\
    \ 2D = 2DCNN.\nModel\ne M P N N\nStudy Task Images VI GSD Labels Tre SV ML CN\
    \ RN Type\nSoil Moisture\nDel Frateet al. SM ERS-2 30m Model-based X P-f\n[2004]\
    \ (train), Field\nsurvey (eval)\nSantiet al. SM ASAR 30m Model-based X P-f\n[2013]\
    \ (train), Field\nsurvey (eval)\nBaghdadi et al. SM RADARSAT- 12m, Field Survey\
    \ X S-o\n[2016] 2, Landsat-7/8 30m (P-\nf)\nKolassa et al. SM [Many] 3km, Model-based\
    \ X P-f\n[2018] 16km, (train), Field\n36km survey (eval)\nvan derSchalie et al.Agreement\
    \ AMSR-E, 25km, Self-labelled X P-f\n[2018] MIRAS, 35km,\nASCAT 25km\nEroglu et\
    \ al. SM CYGNSS X 9km Government X P-f\n[2019]\nKumaret al. SM Sentinel-1 20m\
    \ Field Survey RF X X P-f\n[2019]\nZhanget al. SM Landsat, X 30m, Model-based\
    \ X P-f\n[2020b] Terra-SAR 3m (train), Field\nsurvey (eval)\nRabiei et al. SM\
    \ Sentinel-1, 10m Field Survey X 2D P-f\n[2021] Sentinel-2 S-i\nSenanayakeet al.\
    \ SM MODIS X 1km Field Survey X X P-f\n[2021]\nGhasemloo et al. SM Landsat, X\
    \ 30m, Field Survey X P-f\n[2022] Sentinel-1 10m\nTripathi et al. SM, Sentinel-1/2\
    \ X 10m Field Survey RF X X P-f\n[2022] salinity, X\netc.\nXu et al. [2022] SM\
    \ SMAP, X 36km, Model-based X P-f\nMODIS 1km (train),\nGovernment (eval)\nZeynoddin\
    \ and BonaSkMdari SMAP 36km Self-labelled L T-s\n[2022]\nSoil Nutrients/Minerals\n\
    Gautam et al. Nitrate Landsat 30m Field Survey X S-o\n[2011] (P-\nf)\nSong et\
    \ al. [2018] Nitrogen HJ-1 100m Field Survey RF X X ?-f\nZhanget al. Potassium\
    \ Landsat 30m Field Survey X P-f\n[2020a]\nPeng et al.[2022] Fertility Sentinel-2\
    \ X 10m Field Survey X X P-f\nWanget al. Pb, Cd Sentinel-2 X 10m Field Survey\
    \ RF X P-f\n[2022b]\nZhanget al. Zn, Ni, GaoFen-5 30m Field Survey RF X X P-f\n\
    [2022] Cu\nSoil Salinity\nWanget al. Regress Landsat, HJ-1 X 30m, Field Survey\
    \ X P-f\n[2018] 100m\nQi et al. [2020] Regress Sentinel-2 X 10m Field Survey/\
    \ RF X X P-f\nModel-based\nHabibiet al. Regress Landsat 30m Field Survey X P-f\n\
    [2021]\nAkcaand Gungor Classify RapidEye X 6.5m Field Survey X 2D S-i\n[2022]\n\
    61.6 All Plant Physiology studies\nStudies on plant physiology; mostly canopy\
    \ cover/LAI estimates. VI stands for vegetative indices, and indicates\nwhether\
    \ VIs were used (possibly in combination with other features). GSD = Ground Spatial\
    \ Distance/resolution.\nThe best performing model type in each study is underlined.\
    \ LAI = Leaf Area Index, LCC = Leaf Chlorophyl\nContent, LWC = Leaf Water Content,\
    \ GPP = Gross Primary Production, SIF = Solar-Induced Fluorescence. In the\nRNN\
    \ column: L = LSTM, G = GRU, and 2D = 2D ConvRNN (ConvGRU or ConvLSTM).\nModel\n\
    e M P N N\nStudy Task Images VI GSD Labels Tre SV ML CN RN Type\nCanopy Cover/LAI\n\
    Del Frateet al. Regress LAI ERS-2 30m Model-based X P-f\n[2004] (train), Field\n\
    survey(eval)\nGascon et al. Regress LAI POLDER 60m Model-based X P-f\n[2007] (train),\
    \ Field\nsurvey(eval)\nBsaibes et al. Regress LAI FORMOSAT- 8m Field Survey X\
    \ S-o\n[2009] 2 (P-\nf)\nRichteret al. Regress LAI CASI 10m Model-based X P-f\n\
    [2009] (train), Field\nsurvey(eval)\nVergeret al. Regress LAI PROBA-1 34m Model-based\
    \ X P-f\n[2011] / Canopy (train), Field\nCover survey(eval)\nBocco et al. Regress\
    \ MODIS, X 500m, Field Survey X S-o\n[2012] Canopy Landsat 30m (P-\nCover f)\n\
    Wuet al. Regress LAI HJ-1 X 30m Field Survey X P-f\n[2015]\nBaghdadi et al. Regress\
    \ LAI RADARSAT- 12m, Field Survey X S-o\n[2016] 2, 30m (P-\nLandsat-7/8 f)\nKira\
    \ et al. Regress LAI MODIS, 500m, Field Survey X X S-o\n[2017] Landsat, 30m, (P-\n\
    MERIS 250m f)\nDelloye et al. Regress LAI Sentinel-2 10m Model-based X P-f\n[2018]\
    \ (train), Field\nsurvey(eval)\nSunet al. Regress LAI MODIS 500m Model-based X\
    \ P-f\n[2021] (train), Field\nsurvey(eval)\nTomicek et al. Regress LAI, Sentinel-2\
    \ 10m Model-based X P-f\n[2021] LCC, LWC (train), Field\nsurvey(eval)\nElmetwalli\
    \ et al. Regress LAI, QuickBird X 0.6m Field Survey RF X P-f\n[2022] height, AGB,\n\
    SPAD\nIgderet al. Regress LAI Sentinel-2 10m Model-based X P-f\n[2022]\nOther\n\
    Wagle et al. RegressLight MODIS X 500m Government X T-f\n[2016] / Water Use\n\
    E\uFB03ciency\nWolanin et al. Regress GPP Sentinel-2 X 10m Model-based X P-f\n\
    [2019] (train), Field\nsurvey(eval)\nKira and Sun Regress SIF MODIS 500m Government\
    \ X P-f\n[2020]\nThorp and DrajatClassify Sentinel-1, X 10m Government RF X X\
    \ 2D L P-f\n[2021] Growth Sentinel-2 G S-i\nStage 2D T-s\nST-c\nZhao et al. Classify\
    \ Sentinel-1/2 X 10m Field survey, 2D S-i\n[2022] Growth Model-based\nStage\n\
    71.7 All Crop Damage studies\nStudies on crop damage. VI stands for vegetative\
    \ indices, and indicates whether VIs were used (possibly in\ncombination with\
    \ other features). GSD = Ground Spatial Distance/resolution. In the Tree column:\
    \ RF = Random\nForest, and a tick means any other kind of tree. In the RNN column:\
    \ G = GRU. The best performing model type in\neach study is underlined.\nModel\n\
    e M P N N\nStudy Task Images VI GSD Labels Tre SV ML CN RN Type\nDisease\nYuanet\
    \ al. Segment powdery Spot-6 X 1.5m Field Sur- X S-o\n[2014] mildew vey (P-\n\
    f)\nMa et al. [2019] Segment powdery Landsat X 30m Field Sur- X X P-f\nmildew\
    \ and vey\naphids\nBi et al. [2020] Segment SDS in PlanetScope 3m Field Sur- X\
    \ X G T-f\nsoybeans vey T-s\nPignatti et al. Segment P. Sentinel-2, X 10m, Field\
    \ Sur- X S-o\n[2021] syringae and RapidEye-1, 6.5m, vey (P-\nYellow Rust PRISMA\
    \ 30m f)\nRuanet al. Segment wheat Sentinel-2 X 10m Field Sur- X X P-f\n[2021]\
    \ stripe rust vey\nGuo et al. [2022] Segment Yellow PlanetScope X 3.1m Field Sur-\
    \ RF X P-f\nLeaf Disease vey\nGeneric Damage\nMuradyan et al. Regress heavy SPOT-7\
    \ 1.5m Field Sur- X S-o\n[2020] metal conc. vey (P-\nf)\nRodriguez et al. Regress\
    \ coconut Sentinel-2 10m Image Sur- 2D S-i\n[2021] tree density vey\nVirnodkaret\
    \ al. Segment water Sentinel-2 10m Field Sur- 2D S-i\n[2021] stress vey\nBoroughani\
    \ et al. Segment dusty MODIS 250m Field/Image X X P-f\n[2022] day Survey\n81.8\
    \ All Yield Estimation studies\nThe majority of the yield estimation studies were\
    \ county-level.\nVI stands for vegetative indices, and indicates whether VIs were\
    \ used (possibly in combination with other\nfeatures). GSD = Ground Spatial Distance/resolution.\
    \ \u201CClim.?\u201D indicates whether additional climate data was used\ninthe\
    \ prediction. The bestperformingmodeltype ineachstudy isunderlined. Where twomodeltypes\
    \ areunderlined,\nit means the model had components of both types. In the Tree\
    \ column: RF = Random Forest, and a tick means any\nother kind oftree. In the\
    \ CNN column: nD = nDCNN, including non-spatialCNNs. Inthe RNN column: L = LSTM\n\
    9Model\n?\nm. e M P N N\nStudy Crop Images VI GSD Cli Labels Tre SV ML CN RN Type\n\
    County-level yield\nLi et al. [2007] Maize, MODIS, X 1km Pub. govt. X ST-o\nSoy\
    \ AVHRR (T-f)\nCai et al. [2019] Wheat MODIS X 5.5km X Pub. govt. RF X X ST-o\n\
    (T-s)\nFeng et al. [2019] Wheat MODIS X 1km X Pub. govt. RF X X ST-o\n(P-f)\n\
    Kanget al. Maize MODIS, X 500m X Pub. govt. RF X 2D L ST-o\n[2020] [Many] X (T-f\n\
    T-s\nT-i)\nPotopova et al. Maize, MODIS X 5km X Pub. govt. X ST-o\n[2020] Sun-\
    \ (T-f)\n\uFB02ower,\nGrapes\nSchwalbert et al. Soy MODIS X 250m X Pub. govt.\
    \ RF L ST-o\n[2020] (T-f\nT-s)\nWanget al. Wheat MODIS X 500m X Pub. govt. RF\
    \ X X ST-o\n[2020b] X (T-f)\nWolanin et al. Wheat MODIS X 500m X Pub. govt. RF\
    \ 1D ST-o\n[2020] (T-f\nT-s)\nZhanget al. Maize MODIS X 1km X Pub. govt. RF L\
    \ ST-o\n[2020c] X (T-f\nT-s)\nCao et al. Rice MODIS X 1km X Pub. govt. RF L ST-o\n\
    [2021b] (T-f\nT-s)\nCao et al. Wheat MODIS X 1km X Pub. govt. RF X 1D L ST-o\n\
    [2021a] (T-f\nT-s)\nFeng et al. [2021] Wheat MODIS X 500m X Pub. govt. X ST-o\n\
    (T-f)\nJu et al. [2021] Maize, MODIS X 250m, X Pub. govt. RF X X 2D L ST-o\nSoy,Rice\
    \ 1km (T-f\nT-s)\nKhakiet al. Maize, MODIS 1km Pub. govt. RF X 2D ST-o\n[2021]\
    \ Soy 3D (T-f\nT-i\nT-c)\nMa et al. [2021] Maize MODIS X 500m X Pub. govt. X ST-o\n\
    (T-f)\nTian et al. [2021] Wheat MODIS X 1km X Pub. govt., L ST-o\nField Survey\
    \ (T-s)\nQiao et al. [2021] Wheat MODIS 500m Pub. govt. 3D ST-o\n(T-c)\nXie and\
    \ Huang Wheat MODIS X 250m X Model-based, RF 1D L ST-o\n[2021] Pub. govt. (T-f\n\
    T-s)\nJi et al. [2022] Maize MODIS X 1km X Pub. govt. RF L ST-o\n(T-f\nT-s)\n\
    Liu et al. [2022] Wheat MODIS X 1km X Pub. govt. RF X L ST-o\nX (T-f\nT-s)\nLuo\
    \ et al. [2022] Wheat AVHRR, X 1km X Pub. govt. RF L ST-o\nMODIS X (T-f\nT-s)\n\
    Watson-HernandezePtaallm. Oil Landsat- X 15m, X Business RF X ST-o\n[2022] 5/6/7/8\
    \ 30m X (T-f)\nXie [2022] Wheat Sentinel-2 X 10m X Model-based, L ST-o\nPub. govt.\
    \ (T-s)\n10There were a few studies attempting to predict yield at di\uFB00erent\
    \ scales, too, but not many.\nModel\n?\nm. e M P N N\nStudy Crop Images VI GSD\
    \ Cli Labels Tre SV ML CN RN Type\nField-level yield\nKhan et al. Mentha Landsat\
    \ X 30m Field X S-o\n[2020] Survey (P-\nf)\nArab et al. Grapes Landsat X 30m Field\
    \ X S-o\n[2021] Survey (P-\nf)\nEvans and Shen Wheat Landsat X 30m X Field RF\
    \ X X ST-o\n[2021] Survey (P-\nf)\nGbodjo et al. Millet Sentinel, X 10m, Field\
    \ RF X 2D L ST-o\n[2021] Planetscope 3.1m Survey (T-f\nT-s\n?-i)\nZhanget al.\
    \ Maize Landsat X 30m X Priv. govt. X L ST-o\n[2021b] (T-f\nT-s)\nAbebeet al.\
    \ Sugarcane Sentinel-2, X 30m Field X X ST-o\n[2022] Landsat Survey (P-\nf)\n\
    Krupavathiet al. Sugarcane Landsat X 30m Field X ST-o\n[2022] Survey (P-\nf)\n\
    Farm-level yield\nEngen et al. Any Sentinel-2 X 10m X Pub. govt. X 2D L ST-c\n\
    [2021] G\nPlot-level yield\nHaghverdiet al. Cotton Landsat X 30m X Field X T-f\n\
    [2018] Survey\nSagan et al. Maize, WorldView- 0.3m, Field RF X X 2D ST-o\n[2021]\
    \ Soy 3, 3.1m Survey 3D (P-\nPlanetScope f)\nST-c\nTree-level yield\nRahman et\
    \ al. Mango Worldview- X 0.3m Field X S-i\n[2018] 3 Survey\nPixel-level yield\n\
    Jeong et al. Rice MODIS X 1km X Model- 1D L T-s\n[2022] based\nTripathi et al.\
    \ Wheat Sentinel-1/2 X 10m Priv. govt. X P-f\n[2022]\nGrassland Biomass\nLi et\
    \ al. [2016] Grass Landsat 30m Field X P-f\nSurvey\nAli et al. [2017] Grass MODIS\
    \ X 500m Field X P-f\nSurvey\nBarnetson et al. Grass PlanetScope X 3m Field X\
    \ T-f\n[2021] Survey\nNickmilderet al. Grass Sentinel-1/2 X Field RF X X T-f\n\
    [2021] Survey\nCounty-level cumulative NDVI\nZambrano et al. All MODIS X 500m,\
    \ X Images X P-f\n[2018] 18km\n11References\nGebeyehu Abebe, Tsegaye Tadesse,\
    \ and Berhan Gessesse. Combined Use of Landsat 8 and Sentinel 2A Imagery\nfor\
    \ Improved Sugarcane Yield Estimation in Wonji-Shoa, Ethiopia. JOURNAL OF THE\
    \ INDIAN SOCIETY OF\nREMOTE SENSING, 50(1):143\u2013157,January 2022. ISSN 0255-660X.\
    \ doi: 10.1007/s12524-021-01466-8.\nAmrAbozeid,RayanAlanazi,AhmedElhadad,AhmedI.Taloba,andRashaM.AbdEl-Aziz.\
    \ Alarge-scaledatasetand\ndeeplearningmodelfordetectingandcountingolivetreesinsatelliteimagery.COMPUTATIONALINTELLIGENCE\n\
    AND NEUROSCIENCE, 2022, January 2022. ISSN 1687-5265. doi: 10.1155/2022/1549842.\n\
    Steve Ahlswede, Sarah Asam, and Achim Roeder. Hedgerow object detection in very\
    \ high-resolution satellite images\nusing convolutional neural networks. JOURNAL\
    \ OF APPLIED REMOTE SENSING, 15(1), January 2021. doi:\n10.1117/1.JRS.15.018501.\n\
    SeymaAkcaandOguzGungor. Semanticsegmentationofsoilsalinityusingin-situECmeasurementsanddeeplearning\n\
    based U-NET architecture. CATENA, 218, November 2022. ISSN 0341-8162. doi: 10.1016/j.catena.2022.106529.\n\
    Iftikhar Ali, Fiona Cawkwell, Edward Dwyer, and Stuart Green. Modeling Managed\
    \ Grassland Biomass Estimation\nby Using Multitemporal Remote Sensing Data-A Machine\
    \ Learning Approach. IEEE JOURNAL OF SELECTED\nTOPICS IN APPLIED EARTH OBSERVATIONS\
    \ AND REMOTE SENSING, 10(7):3254\u20133264, July 2017. ISSN\n1939-1404. doi: 10.1109/JSTARS.2016.2561618.\n\
    Sara Tokhi Arab, Ryozo Noguchi, Shusuke Matsushita, and Tofael Ahamed. Prediction\
    \ of grape yields from time-\nseries vegetation indices using satellite remote\
    \ sensing and a machine-learning approach. REMOTE SENSING\nAPPLICATIONS: SOCIETY\
    \ AND ENVIRONMENT, 22, April 2021. ISSN 2352-9385. doi: 10.1016/j.rsase.2021.\n\
    100485.\nMuhammad Anwar Azizan Asming, Azhar Mohd Ibrahim, and Intiaz Mohammad\
    \ Abir. Processing and classi\uFB01cation\nof landsat and sentinel images for\
    \ oil palm plantation detection. REMOTE SENSING APPLICATIONS: SOCIETY\nAND ENVIRONMENT,\
    \ 26, April 2022. ISSN 2352-9385. doi: 10.1016/j.rsase.2022.100747.\nNicolasN.Baghdadi,MohamadElHajj,MehrezZribi,andIbrahimFayad.\
    \ CouplingSARC-BandandOpticalDatafor\nSoilMoistureandLeafAreaIndex RetrievalOverIrrigatedGrasslands.\
    \ IEEE JOURNAL OF SELECTED TOPICS\nIN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,\
    \ 9(3, SI):1229\u20131243, March 2016. ISSN 1939-\n1404. doi: 10.1109/JSTARS.2015.2464698.\n\
    YF Ban. Synergy of multitemporal ERS-1 SAR and Landsat TM data for classi\uFB01\
    cation of agricultural crops. CANA-\nDIAN JOURNAL OF REMOTE SENSING, 29(4):518\u2013\
    526,August 2003. ISSN 0703-8992. doi: 10.5589/m03-014.\nJason Barnetson, Stuart\
    \ Phinn, and Peter Scarth. Climate-Resilient Grazing in the Pastures of Queensland:\
    \ An\nIntegrated Remotely Piloted Aircraft System and Satellite-Based Deep-Learning\
    \ Method for Estimating Pasture\nYield. AGRIENGINEERING, 3(3):681\u2013702,September\
    \ 2021. doi: 10.3390/agriengineering3030044.\nPaola Benedetti, Dino Ienco, Ra\uFB00\
    aele Gaetano, Kenji Ose, Ruggero G. Pensa, and Stephane Dupuy. M(3)Fusion:\nA\
    \ Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite\
    \ Data Fusion. IEEE JOURNAL\nOF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS\
    \ AND REMOTE SENSING, 11(12):4939\u20134949,\nDecember 2018. ISSN 1939-1404. doi:\
    \ 10.1109/JSTARS.2018.2876357.\nLuning Bi, Guiping Hu, Muhammad Mohsin Raza, Yuba\
    \ Kandel, Leonor Leandro, and Daren Mueller. A Gated\nRecurrent Units (GRU)-Based\
    \ Model for Early Detection of Soybean Sudden Death Syndrome through Time-Series\n\
    Satellite Imagery. REMOTE SENSING, 12(21), November 2020. doi: 10.3390/rs12213621.\n\
    Monica Bocco,GustavoOvando, Silvina Sayago,EnriqueWillington, andSusana Heredia.\
    \ Estimating soybeanground\ncoverfromsatellite imagesusingneural-networksmodels.\
    \ INTERNATIONAL JOURNALOF REMOTE SENSING,\n33(6):1717\u20131728,2012. ISSN 0143-1161.\
    \ doi: 10.1080/01431161.2011.600347.\nMahdi Boroughani, Maziar Mohammadi, Fahimeh\
    \ Mirchooli, and Stephanie Fiedler. Assessment of the impact of\ndust aerosols\
    \ on crop and water loss in the Great Salt Desert in Iran. COMPUTERS AND ELECTRONICS\
    \ IN\nAGRICULTURE, 192, January 2022. ISSN 0168-1699. doi: 10.1016/j.compag.2021.106605.\n\
    Aline Bsaibes, Dorninique Courault, Frederic Baret, Marie Weiss, Albert Olioso,\
    \ Frederic Jacob, Olivier Hagolle,\nOlivier Marloie, Nadine Bertrand, Veronique\
    \ Desfond, and Farzaneh Kzemipour. Albedo and LAI estimates from\nFORMOSAT-2 data\
    \ for crop monitoring. REMOTE SENSING OF ENVIRONMENT, 113(4):716\u2013729, April\
    \ 2009.\nISSN 0034-4257. doi: 10.1016/j.rse.2008.11.014.\nYaping Cai, Kaiyu Guan,\
    \ David Lobell, Andries B. Potgieter, Shaowen Wang, Jian Peng, Tianfang Xu, Senthold\n\
    Asseng,YongguangZhang,LiangzhiYou,andBinPeng. Integratingsatelliteandclimatedatatopredictwheatyield\n\
    inAustraliausingmachinelearningapproaches. AGRICULTURALAND FORESTMETEOROLOGY,274:144\u2013\
    159,\nAugust 2019. ISSN 0168-1923. doi: 10.1016/j.agrformet.2019.03.010.\n12JuanCao,\
    \ Zhao Zhang,Yuchuan Luo,Liangliang Zhang,Jing Zhang, Ziyue Li, andFulu Tao. Wheat\
    \ yield predictions\nat a county and \uFB01eld scale with deep learning, machine\
    \ learning, and google earth engine. EUROPEAN JOURNAL\nOF AGRONOMY, 123, February\
    \ 2021a. ISSN 1161-0301. doi: 10.1016/j.eja.2020.126204.\nJuan Cao, Zhao Zhang,\
    \ Fulu Tao, Liangliang Zhang, Yuchuan Luo, Jing Zhang, Jichong Han, and Jun Xie.\
    \ In-\ntegrating Multi-Source Data for Rice Yield Prediction across China using\
    \ Machine Learning and Deep Learning\nApproaches. AGRICULTURAL AND FOREST METEOROLOGY,\
    \ 297, February 2021b. ISSN 0168-1923. doi:\n10.1016/j.agrformet.2020.108275.\n\
    F. Carvajal, F. Aguera, and J. Sanchez-Hermosilla. Estimating the Evaporation\
    \ from Irrigation Reservoirs of Green-\nhouses Using Satellite Imagery. ENVIRONMENTAL\
    \ PROGRESS & SUSTAINABLE ENERGY, 35(6):1750\u20131757,\nNovember 2016. ISSN 1944-7442.\
    \ doi: 10.1002/ep.12419.\nMohamed Chelali, Camille Kurtz, Anne Puissant, and Nicole\
    \ Vincent. Deep-STaR: Classi\uFB01cation of image time series\nbasedonspatio-temporalrepresentations.\
    \ COMPUTER VISIONANDIMAGEUNDERSTANDING,208,July2021.\nISSN 1077-3142. doi: 10.1016/j.cviu.2021.103221.\n\
    Yun-Jae Choung and Donghwi Jung. Comparison of Machine and Deep Learning Methods\
    \ for Mapping Sea Farms\nUsing High-Resolution Satellite Image. Journal of Coastal\
    \ Research, 114(sp1):420\u2013423, October 2021. ISSN 0749-\n0208, 1551-5036.\
    \ doi: 10.2112/JCR-SI114-085.1.\nThomas Colligan, David Ketchum, Douglas Brinkerho\uFB00\
    , and Marco Maneta. A deep learning approach to mapping\nirrigationusinglandsat:\
    \ IrrMapperU-net. IEEE TRANSACTIONSON GEOSCIENCE AND REMOTE SENSING,\n60, 2022.\
    \ ISSN 0196-2892. doi: 10.1109/TGRS.2022.3175635.\nRapha\xA8el d\u2019Andrimont,\
    \ Astrid Verhegghen, Michele Meroni, Guido Lemoine, Peter Strobl, Beatrice Eiselt,\
    \ Momchil\nYordanov,LauraMartinez-Sanchez,andMarijnvanderVelde. LUCASCopernicus2018:\
    \ Earth-observation-relevant\nin situ data on land cover and use throughout the\
    \ European Union. Earth System Science Data, 13(3):1119\u20131133,\nMarch 2021.\
    \ ISSN 1866-3508. doi: 10.5194/essd-13-1119-2021.\nAnesmar Olino de Albuquerque,\
    \ Osmar Abilio de Carvalho Junior, Osmar Luiz Ferreira de Carvalho, Pablo Pozzobon\n\
    de Bem, Pedro Henrique Guimaraes Ferreira, Rebeca dos Santos de Moura, Cristiano\
    \ Rosa Silva, Roberto Arnaldo\nTrancoso Gomes, and Renato Fontes Guimaraes. Deep\
    \ Semantic Segmentation of Center Pivot Irrigation Systems\nfrom Remotely Sensed\
    \ Data. REMOTE SENSING, 12(13), July 2020. doi: 10.3390/rs12132159.\nMisganuDebella-GiloandArntKristianGjertsen.MappingSeasonalAgriculturalLandUseTypesUsingDeepLearning\n\
    on Sentinel-2 Image Time Series. REMOTE SENSING, 13(2), January 2021. doi: 10.3390/rs13020289.\n\
    FDelFrate,PFerrazzoli,LGuerriero,TStrozzi,UWegmuller,GCookmartin,andSQuegan. Wheatcyclemonitoring\n\
    using radar data and a neural network trained by a model. IEEE TRANSACTIONS ON\
    \ GEOSCIENCE AND\nREMOTE SENSING, 42(1):35\u201344,January 2004. ISSN 0196-2892.\
    \ doi: 10.1109/TGRS.2003.817200.\nCindy Delloye, Marie Weiss, and Pierre Defourny.\
    \ Retrieval of the canopy chlorophyllcontent from Sentinel-2 spectral\nbandstoestimatenitrogenuptakeinintensivewinterwheatcroppingsystems.\
    \ REMOTE SENSINGOF ENVIRON-\nMENT, 216:245\u2013261,October 2018. ISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2018.06.037.\nJohannDesloires,DinoIenco,AntoineBotrel,andNicolasRanc.\
    \ PositiveUnlabelledLearningforSatelliteImages\u2019Time\nSeries Analysis: An\
    \ Application to Cereal and Forest Mapping. REMOTE SENSING, 14(1), January 2022.\
    \ doi:\n10.3390/rs14010140.\nSt\xB4ephane Dupuy and Ra\uFB00aele Gaetano. Reunion\
    \ island - 2019, Land cover map (Spot6/7) - 1.5m, 2020.\nAdel H. Elmetwalli, Yasser\
    \ S. A. Mazrou, Andrew N. Tyler, Peter D. Hunter, Osama Elsherbiny, Zaher Mundher\n\
    Yaseen, and Salah Elsayed. Assessing the e\uFB03ciency of remote sensing and machine\
    \ learning algorithms to quantify\nwheat characteristics in the nile delta region\
    \ of egypt. AGRICULTURE-BASEL, 12(3), March 2022. doi: 10.3390/\nagriculture12030332.\n\
    Martin Engen, Erik Sand\xF8, Benjamin Lucas Oscar Sj\xF8lander, Simon Arenberg,\
    \ Rashmi Gupta, and Morten Goodwin.\nFarm-Scale Crop Yield Prediction from Multi-Temporal\
    \ Data Using Deep Hybrid Neural Networks. Agronomy, 11\n(12):2576, December 2021.\
    \ ISSN 2073-4395. doi: 10.3390/agronomy11122576.\nOrhan Eroglu, Mehmet Kurum,\
    \ Dylan Boyd, and Ali Cafer Gurbuz. High Spatio-Temporal Resolution CYGNSS Soil\n\
    Moisture Estimates Using Arti\uFB01cial Neural Networks. REMOTE SENSING, 11(19),\
    \ October 2019. doi: 10.3390/\nrs11192272.\nFiona H. Evans and Jianxiu Shen. Long-Term\
    \ Hindcasts of Wheat Yield in Fields Using Remotely Sensed Phenology,\nClimate\
    \ Data and Machine Learning. REMOTE SENSING, 13(13), July 2021. doi: 10.3390/rs13132435.\n\
    13LuweiFeng,YumiaoWang,ZhouZhang,andQingyunDu. Geographicallyandtemporallyweightedneuralnetworkfor\n\
    winter wheat yield prediction. REMOTE SENSING OF ENVIRONMENT, 262, September 2021.\
    \ ISSN 0034-4257.\ndoi: 10.1016/j.rse.2021.112514.\nPuyuFeng,BinWang,DeLiLiu,andQiangYu.\
    \ Machinelearning-basedintegrationofremotely-senseddroughtfactors\ncan improve\
    \ the estimation of agricultural drought in South-Eastern Australia. AGRICULTURAL\
    \ SYSTEMS, 173:\n303\u2013316,July 2019. ISSN 0308-521X. doi: 10.1016/j.agsy.2019.03.015.\n\
    Marcos Fernandez-Sellers, Guillermo Siesto, Adolfo Lozano-Tello, and Pedro J.\
    \ Clemente. Finding a suitable sensing\ntimeperiodforcropidenti\uFB01cationusingheuristictechniqueswithmulti-temporalsatelliteimages.INTERNATIONAL\n\
    JOURNAL OF REMOTE SENSING, September 2021. ISSN 0143-1161. doi: 10.1080/01431161.2021.1975846.\n\
    Matheus Pinheiro Ferreira, Rodolfo Georjute Lotte, Francisco D\u2019Elia, V, Christos\
    \ Stamatopoulos, Do-Hyung Kim,\nand Adam R. Benjamin. Accurate mapping of Brazil\
    \ nut trees (Bertholletia excelsa) in Amazonian forests using\nWorldView-3 satellite\
    \ images and convolutional neural networks. ECOLOGICAL INFORMATICS, 63, July 2021.\n\
    ISSN 1574-9541. doi: 10.1016/j.ecoinf.2021.101302.\nGiacomoFontanelli,AlessandroLapini,LeonardoSanturri,SimonePettinato,EmanueleSanti,GiulianoRamat,Simone\n\
    Pilia, Fabrizio Baroni, Deodato Tapete, Francesca Cigna, and Simonetta Paloscia.\
    \ Early-season crop mapping on\nan agricultural area in italy using X-band dual-polarization\
    \ SAR satellite data and convolutional neural networks.\nIEEE JOURNAL OF SELECTED\
    \ TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,\n15:6789\u20136803,2022.\
    \ ISSN 1939-1404. doi: 10.1109/JSTARS.2022.3198475.\nYongyong Fu, Jinsong Deng,\
    \ Hongquan Wang, Alexis Comber, Wu Yang, Wenqiang Wu, Shixue You, Yi Lin, and\n\
    Ke Wang. A new satellite-deriveddatasetfor marine aquaculture areasin China\u2019\
    s coastalregion. EARTH SYSTEM\nSCIENCE DATA, 13(4):1829\u20131842,May 2021. ISSN\
    \ 1866-3508. doi: 10.5194/essd-13-1829-2021.\nIgnazio Gallo, Riccardo La Grassa,\
    \ Nicola Landro, and Mirco Boschetti. Sentinel 2 Time Series Analysis with 3D\n\
    FeaturePyramidNetworkandTimeDomainClassActivationIntervalsforCropMapping.ISPRSINTERNATIONAL\n\
    JOURNAL OF GEO-INFORMATION, 10(7), July 2021. doi: 10.3390/ijgi10070483.\nVivien\
    \ Sainte Fare Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata.\
    \ Satellite Image Time Series\nClassi\uFB01cation With Pixel-Set Encoders and\
    \ Temporal Self-Attention. In Proceedings of the IEEE/CVF Conference\non Computer\
    \ Vision and Pattern Recognition, pages 12325\u201312334,2020.\nVivien Sainte\
    \ Fare Garnot, Loic Landrieu, and Nesrine Chehata. Multi-modal temporal attention\
    \ models for crop\nmapping from satellite time series. ISPRS JOURNAL OF PHOTOGRAMMETRY\
    \ AND REMOTE SENSING, 187:\n294\u2013305,May 2022. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2022.03.012.\n\
    F. Gascon, J. P. Gastellu-Etchegorry, and M. Leroy. Using multi-directional high-resolution\
    \ imagery from POLDER\nsensortoretrieveleafareaindex.INTERNATIONALJOURNALOFREMOTESENSING,28(1-2):167\u2013\
    181,January\n2007. ISSN 0143-1161. doi: 10.1080/01431160600647217.\nRamesh Gautam,\
    \ Suranjan Panigrahi, David Franzen, and Albert Sims. Residual soil nitrate prediction\
    \ from im-\nagery and non-imagery information using neural network technique.\
    \ BIOSYSTEMS ENGINEERING, 110(1):20\u201328,\nSeptember 2011. ISSN 1537-5110.\
    \ doi: 10.1016/j.biosystemseng.2011.06.002.\nYawogan Jean Eudes Gbodjo, Dino Ienco,\
    \ and Louise Leroux. Benchmarking statistical modelling approaches with\nmulti-sourceremotesensingdataformilletyieldmonitoring:\
    \ Acasestudyofthe groundnutbasinincentralSenegal.\nINTERNATIONAL JOURNAL OF REMOTE\
    \ SENSING, 42(24):9277\u20139300,December 2021. ISSN 0143-1161. doi:\n10.1080/01431161.2021.1993465.\n\
    Nima Ghasemloo, Ali Akbar Matkan, Abbas Alimohammadi, Hossein Aghighi, and Babak\
    \ Mirbagheri. Estimating\nthe agricultural farm soil moisture using spectral indices\
    \ of landsat 8, and sentinel-1, and arti\uFB01cial neural networks.\nJOURNAL OF\
    \ GEOVISUALIZATION AND SPATIAL ANALYSIS, 6(2), December 2022. ISSN 2509-8810.\
    \ doi:\n10.1007/s41651-022-00110-4.\nC. Gomez, M. Mangeas, M. Petit, C. Corbane,\
    \ P. Hamon, S. Hamon, A. De Kochko, D. Le Pierres, V. Poncet, and\nM.Despinoy.\
    \ Useofhigh-resolutionsatelliteimageryinanintegratedmodeltopredictthedistributionofshadeco\uFB00\
    ee\ntreehybridzones. REMOTE SENSINGOF ENVIRONMENT,114(11):2731\u20132744,November2010.\
    \ ISSN0034-4257.\ndoi: 10.1016/j.rse.2010.06.007.\nJiaweiGuo, Yu Jin, Huichun\
    \ Ye, Wenjiang Huang, Jinling Zhao, Bei Cui, Fucheng Liu, and Jiajian Deng. Recognition\n\
    of Areca Leaf Yellow Disease Based on PlanetScope Satellite Imagery. AGRONOMY-BASEL,\
    \ 12(1), January 2022.\ndoi: 10.3390/agronomy12010014.\nVahid Habibi, Hasan Ahmadi,\
    \ Mohammad Jafari, and Abolfazl Moeini. Quantitative assessment of soil salinity\n\
    using remote sensing data based on the arti\uFB01cial neural network, case study:\
    \ Sharif Abad Plain, Central Iran.\nMODELING EARTH SYSTEMS AND ENVIRONMENT, 7(2):1373\u2013\
    1383, June 2021. ISSN 2363-6203. doi:\n10.1007/s40808-020-01015-1.\n14Amir Haghverdi,\
    \ Robert A. Washington-Allen, and Brian G. Leib. Prediction of cotton lint yield\
    \ from phenology\nof crop indices using arti\uFB01cial neural networks. COMPUTERS\
    \ AND ELECTRONICS IN AGRICULTURE, 152:\n186\u2013197,September 2018. ISSN 0168-1699.\
    \ doi: 10.1016/j.compag.2018.07.021.\nA.M.Hamer,D.M.Simms,andT.W.Waine. ReplacinghumaninterpretationofagriculturallandinAfghanistanwith\n\
    a deep convolutional neural network. INTERNATIONAL JOURNAL OF REMOTE SENSING,\
    \ 42(8):3017\u20133038,\nApril 2021. ISSN 0143-1161. doi: 10.1080/01431161.2020.1864059.\n\
    Omid Mohammadi Igder, Hosein Alizadeh, Barat Mojaradi, and Mehrad Bayat. Multivariate\
    \ assimilation of satellite-\nbased leaf area index and ground-based river stream\uFB02\
    ow for hydrological modelling of irrigated watersheds using\nSWAT. JOURNAL OF\
    \ HYDROLOGY,610, July 2022. ISSN 0022-1694. doi: 10.1016/j.jhydrol.2022.128012.\n\
    Roberto Interdonato, Dino Ienco, Ra\uFB00aele Gaetano, and Kenji Ose. DuPLO: A\
    \ DUal view Point deep Learning\narchitecturefortimeseriesclassi\uFB01catiOn.ISPRSJOURNALOFPHOTOGRAMMETRYANDREMOTESENSING,\n\
    149:91\u2013104,March 2019. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2019.01.011.\n\
    SeungtaekJeong,JonghanKo,andJong-MinYeom.Predictingriceyieldatpixelscalethroughsyntheticuseofcropand\n\
    deep learningmodels with satellite data in South andNorth Korea. SCIENCE OF THE\
    \ TOTAL ENVIRONMENT,\n802, January 2022. ISSN 0048-9697. doi: 10.1016/j.scitotenv.2021.149726.\n\
    ShunpingJi,ChiZhang,AnjianXu,YunShi,andYulinDuan.3DConvolutionalNeuralNetworksforCropClassi\uFB01\
    cation\nwith Multi-Temporal Remote Sensing Images. REMOTE SENSING, 10(1), January\
    \ 2018. doi: 10.3390/rs10010075.\nZhonglinJi, YaozhongPan,Xiufang Zhu, Dujuan\
    \ Zhang,and JiajiaDai. Predictionofcornyieldin the USA cornbelt\nusingsatellitedataandmachinelearning:\
    \ Fromanevapotranspirationperspective. AGRICULTURE-BASEL,12(8),\nAugust 2022.\
    \ doi: 10.3390/agriculture12081263.\nDeyang Jiang, Shengbo Chen, Juliana Useya,\
    \ Lisai Cao, and Tianqi Lu. Crop mapping using the historical crop\ndata layer\
    \ and deep neural networks: A case study in jilin province, china. SENSORS, 22(15),\
    \ August 2022. doi:\n10.3390/s22155853.\nYu Jin, Jiawei Guo, Huichun Ye, Jinling\
    \ Zhao, Wenjiang Huang, and Bei Cui. Extraction of Arecanut Planting\nDistribution\
    \ Based on the Feature Space Optimization of PlanetScope Imagery. AGRICULTURE-BASEL,\
    \ 11(4),\nApril 2021. doi: 10.3390/agriculture11040371.\nMaxwell Jong, Kaiyu Guan,\
    \ Sibo Wang, Yizhi Huang, and Bin Peng. Improving \uFB01eld boundary delineation\
    \ in Re-\nsUNetsviaadversarialdeeplearning. INTERNATIONALJOURNALOFAPPLIED EARTH\
    \ OBSERVATIONAND\nGEOINFORMATION, 112, August 2022. ISSN 1569-8432. doi: 10.1016/j.jag.2022.102877.\n\
    Sungha Ju, Hyoungjoon Lim, Jong Won Ma, Soohyun Kim, Kyungdo Lee, Shuhe Zhao,\
    \ and Joon Heo. Optimal\ncounty-levelcropyield prediction using MODIS-based variables\
    \ and weather data: A comparativestudy on machine\nlearning models. AGRICULTURAL\
    \ AND FOREST METEOROLOGY, 307,September 2021. ISSN 0168-1923. doi:\n10.1016/j.agrformet.2021.108530.\n\
    Yanghui Kang, Mutlu Ozdogan, Xiaojin Zhu, Zhiwei Ye, Christopher Hain, and Martha\
    \ Anderson. Comparative\nassessmentofenvironmentalvariablesandmachinelearningalgorithmsformaizeyieldpredictionintheUSMidwest.\n\
    ENVIRONMENTAL RESEARCH LETTERS, 15(6), June 2020. ISSN 1748-9326. doi: 10.1088/1748-9326/ab7df9.\n\
    ManojKarkee,BrianL.Steward,LieTang,andSarnsuzanaA.Aziz. Quantifyingsub-pixelsignatureofpaddyrice\uFB01\
    eld\nusing anarti\uFB01cialneuralnetwork. COMPUTERS AND ELECTRONICS IN AGRICULTURE,65(1):65\u2013\
    76,January\n2009. ISSN 0168-1699. doi: 10.1016/j.compag.2008.07.009.\nSaeed Khaki,\
    \ Hieu Pham, and Lizhi Wang. Simultaneous corn and soybean yield prediction from\
    \ remote sensing\ndata using deep transfer learning. SCIENTIFIC REPORTS, 11(1),\
    \ May 2021. ISSN 2045-2322. doi: 10.1038/\ns41598-021-89779-z.\nMohammad Saleem\
    \ Khan, Manoj Semwal, Ashok Sharma, and Rajesh Kumar Verma. An arti\uFB01cial\
    \ neural network\nmodel for estimating Mentha crop biomass yield using Landsat\
    \ 8 OLI. PRECISION AGRICULTURE, 21(1):18\u201333,\nFebruary 2020. ISSN 1385-2256.\
    \ doi: 10.1007/s11119-019-09655-9.\nOz Kira and Ying Sun. Extraction of sub-pixel\
    \ C3/C4 emissions of solar-induced chlorophyll \uFB02uorescence (SIF) using\n\
    arti\uFB01cial neural network. ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,\
    \ 161:135\u2013146,\nMarch 2020. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2020.01.017.\n\
    Oz Kira, Anthony L. Nguy-Robertson, Timothy J. Arkebauer, Raphael Linker, and\
    \ Anatoly A. Gitelson. Toward\nGeneric Models for Green LAI Estimation in Maize\
    \ and Soybean: Satellite Observations. REMOTE SENSING, 9\n(4), April 2017. ISSN\
    \ 2072-4292. doi: 10.3390/rs9040318.\n15J.Kolassa,R.H.Reichle,Q.Liu,S.H.Alemohammad,P.Gentine,K.Aida,J.Asanuma,S.Bircher,T.Caldwell,A.Col-\n\
    liander,M. Cosh,C.Holi\uFB01eldCollins, T.J.Jackson,J.Martinez-Fernandez,H.McNairn,\
    \ A.Pacheco,M.Thibeault,\nand J.P. Walker. Estimating surface soilmoisture from\
    \ SMAP observations using a Neural Networktechnique. RE-\nMOTE SENSING OF ENVIRONMENT,\
    \ 204:43\u201359,January 2018. ISSN 0034-4257. doi: 10.1016/j.rse.2017.10.045.\n\
    K.Krupavathi,M.Raghubabu,A.Mani,P.R.K.Parasad,andL.Edukondalu. Field-ScaleEstimationandComparison\n\
    of the Sugarcane Yield from Remote Sensing Data: A Machine Learning Approach.\
    \ JOURNAL OF THE INDIAN\nSOCIETY OF REMOTE SENSING, February 2022. ISSN 0255-660X.\
    \ doi: 10.1007/s12524-021-01448-w.\nP. Kumar, R. Prasad, A. Choudhary, D. K. Gupta,\
    \ V. N. Mishra, A. K. Vishwakarma, A. K. Singh, and P. K.\nSrivastava. Comprehensiveevaluationofsoilmoistureretrievalmodels\
    \ underdi\uFB00erentcropcovertypesusingC-band\nsynthetic aperture radar data.\
    \ GEOCARTO INTERNATIONAL,34(9):1022\u20131041,July 2019. ISSN 1010-6049. doi:\n\
    10.1080/10106049.2018.1464601.\nPradeep Kumar, Dileep Kumar Gupta, Varun Narayan\
    \ Mishra, and Rajendra Prasad. Comparison of support vector\nmachine, arti\uFB01\
    cial neural network, and spectral angle mapper algorithms for crop classi\uFB01\
    cation using LISS IV data.\nINTERNATIONAL JOURNAL OF REMOTE SENSING, 36(6):1604\u2013\
    1617, 2015. ISSN 0143-1161. doi: 10.1080/\n2150704X.2015.1019015.\nNataliia Kussul,\
    \ Mykola Lavreniuk, Sergii Skakun, and Andrii Shelestov. Deep Learning Classi\uFB01\
    cation of Land Cover\nand Crop Types Using Remote Sensing Data. IEEE GEOSCIENCE\
    \ AND REMOTE SENSING LETTERS, 14(5):\n778\u2013782,May 2017. ISSN 1545-598X. doi:\
    \ 10.1109/LGRS.2017.2681128.\nNataliia Kussul, Lavreniuk Mykola, Andrii Shelestov,\
    \ and Sergii Skakun. Crop inventory at regional scale in Ukraine:\nDeveloping\
    \ in season and end of season crop maps with multi-temporal optical and SAR satellite\
    \ imagery. EURO-\nPEAN JOURNAL OF REMOTE SENSING, 51(1):627\u2013636,2018. doi:\
    \ 10.1080/22797254.2018.1454265.\nNoureldin Laban, Bassam Abdellatif, Hala M.\
    \ Ebeid, Howida A. Shedeed, and Mohamed F. Tolba. Sparse Pixel\nTraining of Convolutional\
    \ Neural Networks for Land Cover Classi\uFB01cation. IEEE ACCESS, 9:52067\u2013\
    52078, 2021.\nISSN 2169-3536. doi: 10.1109/ACCESS.2021.3069882.\nLeiLei,XinyuWang,YanfeiZhong,HengweiZhao,Xin\
    \ Hu, andChangLuo. DOCC:Deepone-classcropclassi\uFB01cation\nviapositiveandunlabeledlearningformulti-modalsatellite\
    \ imagery. INTERNATIONALJOURNALOF APPLIED\nEARTH OBSERVATION AND GEOINFORMATION,\
    \ 105, December 2021. ISSN 1569-8432. doi: 10.1016/j.jag.\n2021.102598.\nTsu Chiang\
    \ Lei, Shiuan Wan, You Cheng Wu, Hsin-Ping Wang, and Chia-Wen Hsieh. Multi-temporal\
    \ data fusion in\nMSandSARimagesusingthedynamictimewarpingmethodforpaddyriceclassi\uFB01\
    cation. AGRICULTURE-BASEL,\n12(1), January 2022. doi: 10.3390/agriculture12010077.\n\
    AinongLi,ShunlinLiang,AngshengWang,andJunQin. Estimatingcropyieldfrommulti-temporalsatellitedatausing\n\
    multivariate regression and neural network techniques. PHOTOGRAMMETRIC ENGINEERING\
    \ AND REMOTE\nSENSING, 73(10):1149\u20131157,October 2007. ISSN 0099-1112. doi:\
    \ 10.14358/PERS.73.10.1149.\nFei Li, Jiajia Zheng, Hao Wang, Juhua Luo, Ying Zhao,\
    \ and Ruibin Zhao. Mapping grazing intensity using remote\nsensing in the Xilingol\
    \ steppe region, Inner Mongolia, China. REMOTE SENSING LETTERS, 7(4):328\u2013\
    337,2016.\nISSN 2150-704X. doi: 10.1080/2150704X.2015.1137987.\nHepingLi,JingLu,GuixiangTian,HuijinYang,JianhuiZhao,andNingLi.\
    \ Cropclassi\uFB01cationbasedonGDSSM-CNN\nusing multi-temporal RADARSAT-2 SAR\
    \ with limited labeled data. REMOTE SENSING, 14(16), August 2022a.\ndoi: 10.3390/rs14163889.\n\
    Jingtao Li, Yonglin Shen, and Chao Yang. An Adversarial Generative Network for\
    \ Crop Classi\uFB01cation from Remote\nSensing Timeseries Images. REMOTE SENSING,\
    \ 13(1), January 2021. doi: 10.3390/rs13010065.\nMin Li, Zhijie Zhang, Liping\
    \ Lei, Xiaofan Wang, and Xudong Guo. Agricultural Greenhouses Detection in High-\n\
    Resolution Satellite Images Based on ConvolutionalNeural Networks: Comparisonof\
    \ Faster R-CNN, YOLO v3 and\nSSD. SENSORS, 20(17), September 2020. doi: 10.3390/s20174938.\n\
    Ting Li, Kasper Johansen, and Matthew F. McCabe. A machine learning approach for\
    \ identifying and delineating\nagricultural \uFB01elds and their multi-temporal\
    \ dynamics using three decades of Landsat data. ISPRS JOURNAL OF\nPHOTOGRAMMETRY\
    \ AND REMOTE SENSING, 186:83\u2013101, April 2022b. ISSN 0924-2716. doi: 10.1016/j.\n\
    isprsjprs.2022.02.002.\nWeijia Li,Runmin Dong,HaohuanFu, andLe Yu. Large-ScaleOilPalmTreeDetectionfromHigh-ResolutionSatellite\n\
    Images Using Two-Stage Convolutional Neural Networks. REMOTE SENSING, 11(1), January\
    \ 2019. doi: 10.3390/\nrs11010011.\n16Zhuqiang Li, Shengbo Chen, Xiangyu Meng,\
    \ Ruifei Zhu, Junyan Lu, Lisai Cao, and Peng Lu. Full convolution neural\nnetworkcombinedwithcontextualfeaturerepresentationforcroplandextractionfromhigh-resolutionremotesensing\n\
    images. REMOTE SENSING, 14(9), May 2022c. doi: 10.3390/rs14092157.\nChenxiLin,ZhenongJin,DavidMulla,RahulGhosh,KaiyuGuan,VipinKumar,andYapingCai.\
    \ TowardLarge-Scale\nMapping of Tree Crops with High-Resolution Satellite Imagery\
    \ and Deep Learning Algorithms: A Case Study of\nOlive Orchards in Morocco. REMOTE\
    \ SENSING, 13(9), May 2021. doi: 10.3390/rs13091740.\nYuanyuanLiu,ShaoqiangWang,XiaoboWang,BinChen,JinghuaChen,JunbangWang,MeiHuang,ZhaoshengWang,\n\
    Li Ma, Pengyuan Wang, Muhammad Amir, and Kai Zhu. Exploring the superiority of\
    \ solar-induced chlorophyll\n\uFB02uorescence data in predicting wheat yield using\
    \ machine learning and deep learning methods. COMPUTERS AND\nELECTRONICS IN AGRICULTURE,\
    \ 192, January 2022. ISSN 0168-1699. doi: 10.1016/j.compag.2021.106612.\nFabian\
    \ Loew, Christopher Conrad, and Ulrich Michel. Decision fusion and non-parametric\
    \ classi\uFB01ers for land use\nmapping using multi-temporal RapidEye data. ISPRS\
    \ JOURNAL OF PHOTOGRAMMETRY AND REMOTE\nSENSING, 108:191\u2013204,October 2015.\
    \ ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2015.07.001.\nJiang Long, Mengmeng\
    \ Li, Xiaoqin Wang, and Alfred Stein. Delineation of agricultural \uFB01elds using\
    \ multi-task BsiNet\nfromhigh-resolutionsatelliteimages. INTERNATIONALJOURNALOF\
    \ APPLIED EARTH OBSERVATIONAND\nGEOINFORMATION, 112, August 2022. ISSN 1569-8432.\
    \ doi: 10.1016/j.jag.2022.102871.\nAdolfoLozano-Tello,MarcosFernandez-Sellers,EliaQuiros,LauraFragoso-Campon,AbelardoGarcia-Martin,JoseAn-\n\
    tonio Gutierrez Gallego, Carmen Mateos, Ruben Trenado, and Pedro Munoz. Crop identi\uFB01\
    cation by massive pro-\ncessingofmultiannualsatellite imageryforEUcommonagriculturepolicysubsidy\
    \ control. EUROPEAN JOURNAL\nOF REMOTE SENSING, 54(1):1\u201312,January 2021.\
    \ doi: 10.1080/22797254.2020.1858723.\nTingting Lu, Martin Brandt, Xiaoye Tong,\
    \ Pierre Hiernaux, Louise Leroux, Babacar Ndao, and Rasmus Fensholt.\nMapping\
    \ the Abundance of Multipurpose AgroforestryFaidherbia albida Trees in Senegal.\
    \ REMOTE SENSING, 14\n(3), February 2022. doi: 10.3390/rs14030662.\nYuchuan Luo,\
    \ Zhao Zhang, Juan Cao, Liangliang Zhang, Jing Zhang, Jichong Han, Huimin Zhuang,\
    \ Fei Cheng, and\nFulu Tao. Accurately mapping globalwheat production system using\
    \ deep learning algorithms. INTERNATIONAL\nJOURNAL OF APPLIED EARTH OBSERVATION\
    \ AND GEOINFORMATION, 110, June 2022. ISSN 1569-8432.\ndoi: 10.1016/j.jag.2022.102823.\n\
    HuiqinMa,WenjiangHuang,YuanshuJing,ChenghaiYang,LiangxiuHan,YingyingDong,HuichunYe,YueShi,Qiong\n\
    Zheng, Linyi Liu, and Chao Ruan. Integrating Growth and Environmental Parameters\
    \ to Discriminate Powdery\nMildewandAphidofWinterWheatUsingBi-TemporalLandsat-8Imagery.\
    \ REMOTE SENSING,11(7),April2019.\ndoi: 10.3390/rs11070846.\nYintao Ma, Zheng\
    \ Zhou, Xiaoxiong She, Longyu Zhou, Tao Ren, Shishi Liu, and Jianwei Lu. Identifying\
    \ Dike-Pond\nSystem Using an Improved Cascade R-CNN Model and High-Resolution\
    \ Satellite Images. REMOTE SENSING, 14\n(3), February 2022. doi: 10.3390/rs14030717.\n\
    Yuchi Ma, Zhou Zhang, Yanghui Kang, and Mutlu Ozdogan. Corn yield prediction and\
    \ uncertainty analysis based on\nremotely sensed variables using a Bayesian neural\
    \ network approach. REMOTE SENSING OF ENVIRONMENT,\n259, June 2021. ISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2021.112408.\nMartino E. Malerba, Nicholas Wright, and Peter\
    \ I. Macreadie. A Continental-Scale Assessment of Density, Size,\nDistribution\
    \ and Historical Trends of Farm Dams Using Deep Learning Convolutional Neural\
    \ Networks. REMOTE\nSENSING, 13(2), January 2021. doi: 10.3390/rs13020319.\nMartino\
    \ E. Malerba, Nicholas Wright, and Peter I. Macreadie. Australian farm dams are\
    \ becoming less reliable water\nsourcesunder climate change. SCIENCE OF THE TOTAL\
    \ ENVIRONMENT,829,July 2022. ISSN 0048-9697. doi:\n10.1016/j.scitotenv.2022.154360.\n\
    Mauro Martini, Vittorio Mazzia, Aleem Khaliq, and Marcello Chiaberge. Domain-Adversarial\
    \ Training of Self-\nAttention-Based Networks for Land Cover Classi\uFB01cation\
    \ Using Multi-Temporal Sentinel-2 Satellite Imagery. RE-\nMOTE SENSING, 13(13),\
    \ July 2021. doi: 10.3390/rs13132564.\nKhairiya Mudrik Masoud, Claudio Persello,\
    \ and Valentyn A. Tolpekin. Delineation of Agricultural Field Boundaries\nfrom\
    \ Sentinel-2 Images Using a Novel Super-Resolution Contour Detector Based on Fully\
    \ Convolutional Networks.\nREMOTE SENSING, 12(1), January 2020. doi: 10.3390/rs12010059.\n\
    Vittorio Mazzia, Aleem Khaliq, and Marcello Chiaberge. Improvement in Land Cover\
    \ and Crop Classi\uFB01cation based\non Temporal Features Learning from Sentinel-2\
    \ Data Using Recurrent-Convolutional Neural Network (R-CNN).\nAPPLIED SCIENCES-BASEL,\
    \ 10(1), January 2020. doi: 10.3390/app10010238.\n17Weiye Mei, HaoyuWang, DavidFouhey,\
    \ Weiqi Zhou,Isabella Hinks, JoshM.Gray,Derek Van Berkel,andMeha Jain.\nUsing\
    \ deep learning andvery-high-resolutionimageryto mapsmallholder \uFB01eldboundaries.\
    \ REMOTE SENSING,14\n(13), July 2022. doi: 10.3390/rs14133046.\nShiyao Meng, Xinyu\
    \ Wang, Xin Hu, Chang Luo, and Yanfei Zhong. Deep learning-based crop mapping\
    \ in the cloudy\nseason using one-shot hyperspectral satellite imagery. COMPUTERS\
    \ AND ELECTRONICS IN AGRICULTURE,\n186, July 2021. ISSN 0168-1699. doi: 10.1016/j.compag.2021.106188.\n\
    Nando Metzger, Mehmet Ozgur Turkoglu, Stefano D\u2019Aronco, Jan Dirk Wegner,\
    \ and Konrad Schindler. Crop Classi\uFB01-\ncation Under Varying Cloud CoverWith\
    \ Neural OrdinaryDi\uFB00erential Equations. IEEE Transactions on Geoscience\n\
    and Remote Sensing, 60:1\u201312,2022. ISSN 1558-0644. doi: 10.1109/TGRS.2021.3101965.\n\
    Monica Y. Moreno-Revelo, Lorena Guachi-Guachi, Juan Bernardo Gomez-Mendoza, Javier\
    \ Revelo-Fuelagan, and\nDiegoH. Pelu\uFB00o-Ordonez. EnhancedConvolutional-Neural-NetworkArchitecture\
    \ forCropClassi\uFB01cation. APPLIED\nSCIENCES-BASEL, 11(9), May 2021. doi: 10.3390/app11094292.\n\
    Aicha Moumni andAbderrahmanLahrouni. Machine Learning-BasedClassi\uFB01cationfor\
    \ Crop-TypeMapping Using the\nFusion ofHigh-ResolutionSatellite Imageryin a SemiaridArea.\
    \ SCIENTIFICA, 2021,April 2021. ISSN 2090-908X.\ndoi: 10.1155/2021/8810279.\n\
    Svetlana Mukharamova, Anatoly Saveliev, Maxim Ivanov, Artur Gafurov, and Oleg\
    \ Yermolaev. Estimating the Soil\nErosion Cover-Management Factor at the European\
    \ Part of Russia. ISPRS INTERNATIONAL JOURNAL OF\nGEO-INFORMATION, 10(10), October\
    \ 2021. doi: 10.3390/ijgi10100645.\nVahagn Muradyan, Garegin Tepanosyan, Shushanik\
    \ Asmaryan, Nairuhi Maghakyan, Lilit Sahakyan, and Armen\nSaghatelyan. Estimating\
    \ Mo, Cu, Ni, Cd Contents in the Crop Leaves Growing on Small Land Plots Using\
    \ Satellite\nData. COMMUNICATIONS IN SOIL SCIENCE AND PLANT ANALYSIS, 51(11):1457\u2013\
    1468, June 2020. ISSN\n0010-3624. doi: 10.1080/00103624.2020.1784922.\nEmile Ndikumana,\
    \ Dinh Ho Tong Minh, Nicolas Baghdadi, Dominique Courault, and Laure Hossard.\
    \ Deep Recurrent\nNeuralNetworkforAgriculturalClassi\uFB01cationusingmultitemporalSARSentinel-1forCamargue,France.\
    \ REMOTE\nSENSING, 10(8), August 2018. doi: 10.3390/rs10081217.\nThanhTamNguyen,ThanhDatHoang,MinhTamPham,TuyetTrinhVu,ThanhHungNguyen,Quyet-ThangHuynh,\n\
    and Jun Jo. Monitoring agriculture areas with satellite images and deep learning.\
    \ APPLIED SOFT COMPUTING,\n95, October 2020. ISSN 1568-4946. doi: 10.1016/j.asoc.2020.106565.\n\
    Charles Nickmilder, Anthony Tedde, Isabelle Dufrasne, Francoise Lessire, Bernard\
    \ Tychon, Yannick Curnel, Jerome\nBindelle, and Helene Soyeurt. Development of\
    \ Machine Learning Models to Predict Compressed Sward Height in\nWalloon Pastures\
    \ Based on Sentinel-1, Sentinel-2 and Meteorological Data Using Multiple Data\
    \ Transformations.\nREMOTE SENSING, 13(3), February 2021. doi: 10.3390/rs13030408.\n\
    Joachim Nyborg, Charlotte Pelletier, Sebastien Lefevre, and Ira Assent. TimeMatch:\
    \ Unsupervised cross-regionadap-\ntationbytemporalshiftestimation. ISPRSJOURNALOFPHOTOGRAMMETRY\
    \ ANDREMOTESENSING,188:\n301\u2013313,June 2022. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2022.04.018.\n\
    Stella Ofori-Ampofo, Charlotte Pelletier, and Stefan Lang. Crop Type Mapping from\
    \ Optical and Radar Time Series\nUsing Attention-Based Deep Learning. Remote Sensing,\
    \ 13(22):4668,January 2021. ISSN 2072-4292. doi: 10.3390/\nrs13224668.\nSubir\
    \ Paul, Mamta Kumari, C. S. Murthy, and D. Nagesh Kumar. Generating pre-harvest\
    \ crop maps by applying\nconvolutional neural network on multi-temporal Sentinel-1\
    \ data. INTERNATIONAL JOURNAL OF REMOTE\nSENSING, February 2022. ISSN 0143-1161.\
    \ doi: 10.1080/01431161.2022.2030072.\nMarko Pavlovic, Slobodan Ilic, Nenad Antonic,\
    \ and Dubravko Culibrk. Monitoring the impact of large transport\ninfrastructure\
    \ on land use and environment using deep learning and satellite imagery. REMOTE\
    \ SENSING, 14(10),\nMay 2022. doi: 10.3390/rs14102494.\nOscar D. Pedrayes, Dario\
    \ G. Lema, Daniel F. Garcia, Ruben Usamentiaga, and Angela Alonso. Evaluation\
    \ of Seman-\ntic Segmentation Methods for Land Use with Spectral Imaging Using\
    \ Sentinel-2 and PNOA Imagery. REMOTE\nSENSING, 13(12), June 2021. doi: 10.3390/rs13122292.\n\
    JoseM.Pena,PedroA.Gutierrez,CesarHervas-Martinez,JohanSix,RichardE.Plant,andFranciscaLopez-Granados.\n\
    Object-Based Image Classi\uFB01cation of Summer Crops with Machine Learning Methods.\
    \ REMOTE SENSING, 6(6):\n5019\u20135041,June 2014. doi: 10.3390/rs6065019.\nYiping\
    \ Peng, Zhenhua Liu, Chenjie Lin, Yueming Hu, Li Zhao, Runyan Zou, Ya Wen, and\
    \ Xiaoyun Mao. A new\nmethodforestimatingsoilfertilityusingextremegradientboostingandabackpropagationneuralnetwork.\
    \ REMOTE\nSENSING, 14(14), July 2022. doi: 10.3390/rs14143311.\n18C. Persello,\
    \ V. A. Tolpekin, J. R. Bergado, and R. A. de By. Delineation of agricultural\
    \ \uFB01elds in smallholder farms\nfrom satellite images using fully convolutional\
    \ networks and combinatorial grouping. REMOTE SENSING OF\nENVIRONMENT, 231, September\
    \ 2019. ISSN 0034-4257. doi: 10.1016/j.rse.2019.111253.\nStefano Pignatti, Ra\uFB00\
    aele Casa, Giovanni Laneve, Zhenhai Li, Linyi Liu, Pablo Marzialetti, Nada Mzid,\
    \ Simone Pas-\ncucci, Paolo Cosmo Silvestro, Massimo Tolomio, Deepak Upreti, Hao\
    \ Yang, Guijun Yang, and Wenjiang Huang.\nSino-EUEarthObservationData to Supportthe\
    \ Monitoring andManagementofAgriculturalResources. REMOTE\nSENSING, 13(15), August\
    \ 2021. doi: 10.3390/rs13152889.\nVera Potopova, Miroslav Trnka, Pavel Hamouz,\
    \ Josef Soukup, and Tudor Castravet. Statistical modelling of drought-\nrelatedyieldlossesusingsoilmoisture-vegetationremotesensingandmultiscalarindicesinthesouth-easternEurope.\n\
    AGRICULTURAL WATER MANAGEMENT, 236, June 2020. ISSN 0378-3774. doi: 10.1016/j.agwat.2020.106168.\n\
    GuanghuiQi,GengxingZhao,andXueXi. SoilSalinityInversionofWinterWheatAreasBasedonSatellite-Unmanned\n\
    AerialVehicle-GroundCollaborativeSysteminCoastaloftheYellowRiverDelta. SENSORS,20(22),November2020.\n\
    doi: 10.3390/s20226521.\nMengjiaQiao,XiaohuiHe,XijieCheng,PanleLi,HaotianLuo,ZhihuiTian,andHengliangGuo.ExploitingHierarchical\n\
    Features for CropYield PredictionBased on3-D ConvolutionalNeuralNetworks and MultikernelGaussianProcess.\n\
    IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,\n\
    14:4476\u20134489,2021. ISSN 1939-1404. doi: 10.1109/JSTARS.2021.3073149.\nF\xB4\
    elixQuintonandLoicLandrieu. CropRotationModelingforDeepLearning-BasedParcelClassi\uFB01\
    cationfromSatellite\nTime Series. Remote Sensing, 13(22):4599,January 2021. ISSN\
    \ 2072-4292. doi: 10.3390/rs13224599.\nSaman Rabiei, Ehsan Jalilvand, and Massoud\
    \ Tajrishy. A Method to Estimate Surface Soil Moisture and Map the\nIrrigated\
    \ Cropland Area Using Sentinel-1 and Sentinel-2 Data. Sustainability, 13(20):11355,\
    \ January 2021. ISSN\n2071-1050. doi: 10.3390/su132011355.\nFatemeh Rahimi-Ajdadi\
    \ and Mahdi Khani. Remote sensing-based detection of tea land losses: The case\
    \ of Lahijan,\nIran. REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT,23,August2021.\
    \ ISSN 2352-9385.\ndoi: 10.1016/j.rsase.2021.100568.\nMuhammad Moshiur Rahman,\
    \ Andrew Robson, and Mila Bristow. Exploring the Potential of High Resolution\n\
    WorldView-3 Imagery for Estimating Yield of Mango. REMOTE SENSING, 10(12), December\
    \ 2018. doi:\n10.3390/rs10121866.\nUsman Rauf, Waqar S. Qureshi, Hamid Jabbar,\
    \ Ayesha Zeb, Alina Mirza, Eisa Alanazi, Umar S. Khan, and Nasir\nRashid. A new\
    \ method for pixel classi\uFB01cation for rice variety identi\uFB01cation using\
    \ spectral and time series data from\nSentinel-2 satellite imagery. COMPUTERS\
    \ AND ELECTRONICS IN AGRICULTURE, 193, February 2022. ISSN\n0168-1699. doi: 10.1016/j.compag.2022.106731.\n\
    AnuviRawat,AnilKumar,PriyadarshiUpadhyay,andShashiKumar.Deeplearning-basedmodelsfortemporalsatellite\n\
    dataprocessing: Classi\uFB01cationofpaddytransplanted\uFB01elds. ECOLOGICAL INFORMATICS,61,March2021.\
    \ ISSN\n1574-9541. doi: 10.1016/j.ecoinf.2021.101214.\nAnuvi Rawat, Anil Kumar,\
    \ Priyadarshi Upadhyay, and Shashi Kumar. A Comparative Study of 1D-Convolutional\n\
    Neural Networks with Modi\uFB01ed Possibilistic c-Mean Algorithm for Mapping Transplanted\
    \ Paddy Fields Using Tem-\nporal Data. JOURNAL OF THE INDIAN SOCIETY OF REMOTE\
    \ SENSING, 2022. ISSN 0255-660X. doi:\n10.1007/s12524-020-01303-4.\nK. Richter,\
    \ C. Atzberger, F. Vuolo, P. Weihs, and G. D\u2019Urso. Experimental assessment\
    \ of the Sentinel-2 band setting\nfor RTM-based LAI retrieval of sugar beet and\
    \ maize. CANADIAN JOURNAL OF REMOTE SENSING, 35(3):\n230\u2013247,June 2009. ISSN\
    \ 0703-8992. doi: 10.5589/m09-010.\nAndresC.Rodriguez,RodrigoCayeDaudt,Stefano\
    \ D\u2019Aronco,KonradSchindler,andJanD.Wegner. RobustDamage\nEstimation of Typhoon\
    \ Goni on Coconut Crops with Sentinel-2 Imagery. REMOTE SENSING, 13(21), November\n\
    2021. doi: 10.3390/rs13214302.\nChao Ruan, Yingying Dong, Wenjiang Huang, Linsheng\
    \ Huang, Huichun Ye, Huiqin Ma, Anting Guo, and Yu Ren.\nPrediction of Wheat Stripe\
    \ Rust Occurrence with Time Series Sentinel-2 Images. AGRICULTURE-BASEL, 11(11),\n\
    November 2021. doi: 10.3390/agriculture11111079.\nMarc Ru\xDFwurm and Marco Koerner.\
    \ Self-attention for raw optical Satellite Time Series Classi\uFB01cation. ISPRS\
    \ JOUR-\nNAL OF PHOTOGRAMMETRY AND REMOTE SENSING, 169:421\u2013435, November\
    \ 2020. ISSN 0924-2716. doi:\n10.1016/j.isprsjprs.2020.06.006.\nMarc Ru\xDFwurm\
    \ and Marco K\xA8orner. Multi-Temporal Land Cover Classi\uFB01cation with Sequential\
    \ Recurrent Encoders.\nISPRS International Journal of Geo-Information, 7(4):129,\
    \ April 2018. ISSN 2220-9964. doi: 10.3390/ijgi7040129.\n19Marc Ru\xDFwurm, Charlotte\
    \ Pelletier, Maximilian Zollner, S\xB4ebastien Lef`evre, and Marco K\xA8orner.\
    \ BreizhCrops: A time\nseries dataset for crop type mapping. International Archives\
    \ of the Photogrammetry, Remote Sensing and Spatial\nInformation Sciences ISPRS\
    \ (2020), pages 1545\u20131551,2020. doi: 10.5194/isprs-archives-XLIII-B2-2020-1545-2020.\n\
    Vasit Sagan, Maitiniyazi Maimaitijiang, Sourav Bhadra, Matthew Maimaitiyiming,\
    \ Davis R. Brown, Paheding Sidike,\nand Felix B. Fritschi. Field-scale crop yield\
    \ prediction using multi-temporal WorldView-3 and PlanetScope satellite\ndata\
    \ and deep learning. ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING, 174:265\u2013\
    281,\nApril 2021. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2021.02.008.\nIedaDel\u2019\
    ArcoSanches,RaulQueirozFeitosa,PedroMarcoAchanccarayDiaz,MarinalvaDiasSoares,AlfredoJoseBar-\n\
    reto Luiz, Bruno Schultz, and Luis Eduardo Pinheiro Maurano. Campo Verde Database,\
    \ October 2017.\nEmanuele Santi, Simonetta Paloscia, Simone Pettinato, Claudia\
    \ Notarnicola, Luca Pasolli, and Alberto Pistocchi.\nComparison between SAR Soil\
    \ Moisture Estimates and Hydrological Model Simulations over the Scrivia Test\
    \ Site.\nREMOTE SENSING, 5(10):4961\u20134976,October 2013. doi: 10.3390/rs5104961.\n\
    Marciano Saraiva, Eglen Protas, Moises Salgado, and Carlos Souza Jr. Automatic\
    \ Mapping of Center Pivot Irrigation\nSystems from Satellite Images Using Deep\
    \ Learning. REMOTE SENSING, 12(3), February 2020. doi: 10.3390/\nrs12030558.\n\
    Ekrem Saralioglu and Oguz Gungor. Semantic segmentation of land cover from high\
    \ resolution multispectral satellite\nimages by spectral-spatial convolutional\
    \ neural network. GEOCARTO INTERNATIONAL, 37(2):657\u2013677,January\n2022. ISSN\
    \ 1010-6049. doi: 10.1080/10106049.2020.1734871.\nRai A. Schwalbert, Telmo Amado,\
    \ Geomar Corassa, Luan Pierre Pott, P. V. Vara Prasad, and Ignacio A. Ciampitti.\n\
    Satellite-based soybean yield forecast: Integrating machine learning and weather\
    \ data for improving crop yield\nprediction in southern Brazil. AGRICULTURAL AND\
    \ FOREST METEOROLOGY, 284, April 2020. ISSN 0168-\n1923. doi: 10.1016/j.agrformet.2019.107886.\n\
    I. P. Senanayake, I. Y. Yeo, J. P. Walker, and G. R. Willgoose. Estimating catchment\
    \ scale soil moisture at a high\nspatialresolution: Integratingremotesensingandmachinelearning.\
    \ SCIENCE OF THE TOTAL ENVIRONMENT,\n776, July 2021. ISSN 0048-9697. doi: 10.1016/j.scitotenv.2021.145924.\n\
    Alireza Shari\uFB01, Hadi Mahdipour, Elahe Moradi, and Aqil Tariq. Agricultural\
    \ Field Extraction with Deep Learning\nAlgorithm and Satellite Imagery. JOURNAL\
    \ OF THE INDIAN SOCIETY OF REMOTE SENSING, 2022. ISSN\n0255-660X. doi: 10.1007/s12524-021-01475-7.\n\
    RamC.Sharma. Countrywidemappingofplantecologicalcommunitieswith101legendsincludinglandcovertypesfor\n\
    the \uFB01rst time at 10 m resolution through convolutional learning of satellite\
    \ images. APPLIED SCIENCES-BASEL,\n12(14), July 2022. doi: 10.3390/app12147125.\n\
    Andrii Shelestov, Mykola Lavreniuk, Nataliia Kussul, Alexei Novikov, and Sergii\
    \ Skakun. Exploring Google Earth\nEngine Platform for Big Data Processing: Classi\uFB01\
    cation of Multi-Temporal Satellite Imagery for Crop Mapping.\nFRONTIERS IN EARTH\
    \ SCIENCE, 5:1\u201310,February 2017. doi: 10.3389/feart.2017.00017.\nPahedingSidike,VasitSagan,MaitiniyaziMaimaitijiang,MatthewMaimaitiyiming,NadiaShakoor,JoelBurken,Todd\n\
    Mockler,andFelixB.Fritschi. dPEN:DeepProgressivelyExpandedNetworkformappingheterogeneousagricultural\n\
    landscape using WorldView-3 satellite imagery. REMOTE SENSING OF ENVIRONMENT,\
    \ 221:756\u2013772,February\n2019. ISSN 0034-4257. doi: 10.1016/j.rse.2018.11.031.\n\
    Ying-Qiang Song, Xin Zhao, Hui-Yue Su, Bo Li, Yue-Ming Hu, and Xue-Sen Cui. Predicting\
    \ Spatial Variations in\nSoil Nutrients with Hyperspectral Remote Sensing at Regional\
    \ Scale. SENSORS, 18(9), September 2018. doi:\n10.3390/s18093086.\nLin Sun, Weiyan\
    \ Wang, Chen Jia, and Xirong Liu. Leaf area index remote sensing based on Deep\
    \ Belief Network\nsupportedbysimulationdata. INTERNATIONALJOURNALOF REMOTE SENSING,42(20):7637\u2013\
    7661,October\n2021. ISSN 0143-1161. doi: 10.1080/01431161.2021.1942584.\nDimitrios\
    \ Sykas, Maria Sdraka, Dimitrios Zografakis, and Ioannis Papoutsis. A sentinel-2\
    \ multiyear, multicountry\nbenchmark dataset for crop classi\uFB01cation and segmentation\
    \ with deep learning. IEEE JOURNAL OF SELECTED\nTOPICS IN APPLIED EARTH OBSERVATIONSANDREMOTE\
    \ SENSING,15:3323\u20133339,2022. ISSN1939-1404.\ndoi: 10.1109/JSTARS.2022.3164771.\n\
    Pengfei Tang, Peijun Du, Junshi Xia, Peng Zhang, and Wei Zhang. Channel Attention-Based\
    \ TemporalConvolutional\nNetwork for Satellite Image Time Series Classi\uFB01\
    cation. IEEE Geoscience and Remote Sensing Letters, 19:1\u20135,2022.\nISSN 1558-0571.\
    \ doi: 10.1109/LGRS.2021.3095505.\nMaryam Teimouri, Mehdi Mokhtarzade, Nicolas\
    \ Baghdadi, and Christian Heipke. Fusion of time-series optical and\nSAR images\
    \ using 3D convolutionalneural networksfor cropclassi\uFB01cation. GEOCARTO INTERNATIONAL,2022.\n\
    ISSN 1010-6049. doi: 10.1080/10106049.2022.2095446.\n20Nima Teimouri, Mads Dyrmann,\
    \ and Rasmus Nyholm Jorgensen. A Novel Spatio-Temporal FCN-LSTM Network for\n\
    RecognizingVariousCropTypesUsing Multi-TemporalRadarImages. REMOTE SENSING,11(8),April2019.\
    \ doi:\n10.3390/rs11080990.\nK. R. Thorp and D. Drajat. Deep machine learning\
    \ with Sentinel satellite data to map paddy rice production stages\nacrossWestJava,Indonesia.\
    \ REMOTE SENSINGOF ENVIRONMENT,265,November2021. ISSN0034-4257. doi:\n10.1016/j.rse.2021.112679.\n\
    Huiren Tian, PengxinWang, Kevin Tansey, Dong Han, Jingqi Zhang, Shuyu Zhang, and\
    \ Hongmei Li. A deep learning\nframework under attention mechanism for wheat yield\
    \ estimation using remotely sensed indices in the Guanzhong\nPlain, PR China.\
    \ INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMA-\nTION, 102,\
    \ October 2021. ISSN 1569-8432. doi: 10.1016/j.jag.2021.102375.\nJiri Tomicek,\
    \ Jan Misurec, and Petr Lukes. Prototyping a Generic Algorithm for Crop Parameter\
    \ Retrieval across the\nSeason Using Radiative Transfer Model Inversion and Sentinel-2\
    \ Satellite Observations. REMOTE SENSING, 13\n(18), September 2021. doi: 10.3390/rs13183659.\n\
    Akshar Tripathi, Reet Kamal Tiwari, and Surya Prakash Tiwari. A deep learning\
    \ multi-layer perceptron and remote\nsensingapproachforsoilhealthbasedcropyieldestimation.\
    \ INTERNATIONALJOURNALOF APPLIED EARTH\nOBSERVATIONANDGEOINFORMATION,113,September2022.\
    \ ISSN1569-8432.doi: 10.1016/j.jag.2022.102959.\nMehmet Ozgur Turkoglu, Stefano\
    \ D\u2019Aronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler,\
    \ and\nJanDirkWegner. Cropmappingfromimagetime series: Deeplearningwithmulti-scalelabelhierarchies.\
    \ REMOTE\nSENSING OF ENVIRONMENT, 264, October 2021. ISSN 0034-4257. doi: 10.1016/j.rse.2021.112603.\n\
    USDA. National Agricultural Statistics Service Cropland Data Layer. Published\
    \ crop-speci\uFB01c data layer [Online].\nAvailable at: https://nassgeodata.gmu.edu/CropScape/.USDA-NASS,\
    \ Washington, DC, 2022.\nRobin van der Schalie, Richard de Jeu, Nemesio Rodriguez-Fernandez,\
    \ Amen Al-Yaari, Yann Kerr, Jean-Pierre\nWigneron, Robert Parinussa, and Matthias\
    \ Drusch. The E\uFB00ect of Three Di\uFB00erent Data Fusion Approaches on the\n\
    Quality of Soil Moisture Retrievals from Multiple Passive Microwave Sensors. REMOTE\
    \ SENSING, 10(1), January\n2018. ISSN 2072-4292. doi: 10.3390/rs10010107.\nAleixandre\
    \ Verger, Frederic Baret, and Fernando Camacho. Optimal modalities for radiative\
    \ transfer-neural net-\nwork estimation of canopy biophysical characteristics:\
    \ Evaluation over an agricultural area with CHRIS/PROBA\nobservations. REMOTE\
    \ SENSING OF ENVIRONMENT, 115(2):415\u2013426, February 2011. ISSN 0034-4257.\
    \ doi:\n10.1016/j.rse.2010.09.012.\nShyamal S. Virnodkar, Vinod K. Pachghare,\
    \ Virupakshagouda C. Patil, and Sunil Kumar Jha. DenseResUNet: An\nArchitecture\
    \ to Assess Water-Stressed Sugarcane Crops from Sentinel-2 Satellite Imagery.\
    \ TRAITEMENT DU\nSIGNAL, 38(4):1131\u20131139,August 2021. ISSN 0765-0019. doi:\
    \ 10.18280/ts.380424.\nPradeep Wagle, Prasanna H. Gowda, Xiangming Xiao, and K.\
    \ C. Anup. Parameterizing ecosystem light use\ne\uFB03ciency and water use e\uFB03\
    ciency to estimate maize gross primary production and evapotranspiration using\n\
    MODIS EVI. AGRICULTURAL AND FOREST METEOROLOGY, 222:87\u201397, May 2016. ISSN\
    \ 0168-1923. doi:\n10.1016/j.agrformet.2016.03.009.\nFran\xB8cois Waldner and\
    \ Foivos I. Diakogiannis. Deep learning onedge: Extracting \uFB01eld boundaries\
    \ from satellite images\nwith a convolutional neural network. Remote Sensing of\
    \ Environment, 2019. doi: 10.1016/j.rse.2020.111741.\nFrancois Waldner, Foivos\
    \ I. Diakogiannis, Kathryn Batchelor, Michael Ciccotosto-Camp, Elizabeth Cooper-Williams,\n\
    Chris Herrmann, Gonzalo Mata, and Andrew Toovey. Detect, Consolidate, Delineate:\
    \ Scalable Mapping of Field\nBoundaries Using Satellite Images. REMOTE SENSING,\
    \ 13(11), June 2021. doi: 10.3390/rs13112197.\nHong Wang, Xianzhong Chen, Tianxiang\
    \ Zhang, Zhiyong Xu, and Jiangyun Li. CCTNet: Coupled CNN and trans-\nformer network\
    \ for crop segmentation of remote sensing images. REMOTE SENSING, 14(9), May 2022a.\
    \ doi:\n10.3390/rs14091956.\nLi Wang, Yong Zhou, Jingyi Liu, Yujie Liu, Qian Zuo,\
    \ and Qing Li. Exploring the potential of multispectral satellite\nimages for\
    \ estimating the contents of cadmium and lead in cropland: The e\uFB00ect of the\
    \ dimidiate pixel model and\nrandom forest. JOURNAL OF CLEANER PRODUCTION, 367,\
    \ September 2022b. ISSN 0959-6526. doi: 10.1016/\nj.jclepro.2022.132922.\nLijun\
    \ Wang, Jiayao Wang, Xiwang Zhang, Laigang Wang, and Fen Qin. Deep segmentation\
    \ and classi\uFB01cation of\ncomplex crops using multi-feature satellite imagery.\
    \ COMPUTERS AND ELECTRONICS IN AGRICULTURE,\n200, September 2022c. ISSN 0168-1699.\
    \ doi: 10.1016/j.compag.2022.107249.\nSherrie Wang, Stefania Di Tommaso, Joey\
    \ Faulkner, Thomas Friedel, Alexander Kennepohl, Rob Strey, and David B.\nLobell.\
    \ Mapping Crop Types in Southeast India with Smartphone Crowdsourcing and Deep\
    \ Learning. REMOTE\nSENSING, 12(18), September 2020a. doi: 10.3390/rs12182957.\n\
    21Xiaoping Wang, Fei Zhang, Jianli Ding, Hsiang-te Kung, Aamir Latif, and Verner\
    \ C. Johnson. Estimation of soil\nsalt content (SSC) in the Ebinur Lake Wetland\
    \ National Nature Reserve (ELWNNR), Northwest China, based on a\nBootstrap-BP\
    \ neural network model and optimal spectral indices. SCIENCE OF THE TOTAL ENVIRONMENT,\n\
    615:918\u2013930,February 2018. ISSN 0048-9697. doi: 10.1016/j.scitotenv.2017.10.025.\n\
    Xue Wang, Jiahua Zhang, Lan Xun, Jingwen Wang, Zhenjiang Wu, Malak Henchiri, Shichao\
    \ Zhang, Sha Zhang, Yun\nBai,ShanshanYang,ShuaishuaiLi,andXiangYu. Evaluatingthee\uFB00\
    ectivenessofmachinelearninganddeeplearning\nmodels combined time-series satellite\
    \ data for multiple crop types classi\uFB01cation over a large-scale region. REMOTE\n\
    SENSING, 14(10), May 2022d. doi: 10.3390/rs14102341.\nYumiao Wang, Zhou Zhang,\
    \ Luwei Feng, Qingyun Du, and Troy Runge. Combining Multi-Source Data and Machine\n\
    Learning Approaches to Predict Winter Wheat Yield in the Conterminous United States.\
    \ REMOTE SENSING, 12\n(8), April 2020b. doi: 10.3390/rs12081232.\nFernandoWatson-Hernandez,NataliaGomez-Calderon,andRouversonPereiradaSilva.Oilpalmyieldestimationbased\n\
    on vegetation and humidity indices generated from satellite images and machine\
    \ learning techniques. AGRIENGI-\nNEERING, 4(1):279\u2013291,March 2022. doi:\
    \ 10.3390/agriengineering4010019.\nAleksandra Wolanin, Gustau Camps-Valls, Luis\
    \ Gomez-Chova, Gonzalo Mateo-Garcia, Christiaan van der Tol, Yong-\nguangZhang,andLuisGuanter.\
    \ EstimatingcropprimaryproductivitywithSentinel-2andLandsat8usingmachine\nlearning\
    \ methods trained with radiative transfer simulations. REMOTE SENSING OF ENVIRONMENT,\
    \ 225:441\u2013\n457, May 2019. ISSN 0034-4257. doi: 10.1016/j.rse.2019.03.002.\n\
    Aleksandra Wolanin, Gonzalo Mateo-Garcia, Gustau Camps-Valls, Luis Gomez-Chova,\
    \ Michele Meroni, Gregory Du-\nveiller,YouLiangzhi,andLuisGuanter. Estimatingandunderstandingcropyields\
    \ withexplainabledeeplearningin\nthe Indian Wheat Belt. ENVIRONMENTAL RESEARCH\
    \ LETTERS, 15(2), February 2020. ISSN 1748-9326. doi:\n10.1088/1748-9326/ab68ac.\n\
    Lin Wu, Wenwen Qi, Zhengwei Guo, Jianhui Zhao, Huijin Yang, and Ning Li. Winter\
    \ wheat planting area extraction\nusing SARchangedetection. REMOTE SENSING LETTERS,\
    \ 12(10):951\u2013960,October2021. ISSN 2150-704X. doi:\n10.1080/2150704X.2021.1951873.\n\
    Qiong Wu, Yunxiang Jin, Yuhai Bao, Quansheng Hai, Ruirui Yan, Baorui Chen, Hongbin\
    \ Zhang, Baohui Zhang,\nZhenwang Li, Xiaoyu Li, and Xiaoping Xin. Comparison of\
    \ two inversion methods for leaf area index using HJ-1\nsatellite data in a temperate\
    \ meadow steppe. INTERNATIONAL JOURNAL OF REMOTE SENSING, 36(19-20,\nSI):5192\u2013\
    5207,October 2015. ISSN 0143-1161. doi: 10.1080/01431161.2015.1040135.\nBin Xie,\
    \ Hankui K. Zhang, and Jie Xue. Deep Convolutional Neural Network for Mapping\
    \ Smallholder Agriculture\nUsing High Spatial Resolution Satellite Image. SENSORS,\
    \ 19(10), May 2019. doi: 10.3390/s19102398.\nYiXie. CombiningCERES-Wheatmodel,Sentinel-2data,anddeeplearningmethodforwinterwheatyieldestimation.\n\
    International Journal of Remote Sensing, 43(2):630\u2013648, January 2022. ISSN\
    \ 0143-1161. doi: 10.1080/01431161.\n2022.2026521.\nYiXie andJianxiHuang. IntegrationofaCropGrowthModelandDeepLearningMethodsto\
    \ ImproveSatellite-Based\nYield Estimation of Winter Wheat in Henan Province,\
    \ China. REMOTE SENSING, 13(21), November 2021. doi:\n10.3390/rs13214372.\nJinfan\
    \ Xu, Yue Zhu, Renhai Zhong, Zhixian Lin, Jialu Xu, Hao Jiang, Jingfeng Huang,\
    \ Haifeng Li, and Tao Lin.\nDeepCropMapping: A multi-temporal deep learning approach\
    \ with improved spatial generalizability for dynamic\ncornandsoybeanmapping. REMOTE\
    \ SENSING OF ENVIRONMENT,247,September2020. ISSN0034-4257. doi:\n10.1016/j.rse.2020.111946.\n\
    Mengyuan Xu, Ning Yao, Haoxuan Yang, Jia Xu, Annan Hu, Luis Gustavo Goncalves\
    \ de Goncalves, and Gang Liu.\nDownscalingSMAPsoilmoistureusingawide&deeplearningmethodovertheContinentalUnitedStates.JOURNAL\n\
    OF HYDROLOGY,609, June 2022. ISSN 0022-1694. doi: 10.1016/j.jhydrol.2022.127784.\n\
    Shuting Yang, Lingjia Gu, Xiaofeng Li, Fang Gao, and Tao Jiang. Fully Automated\
    \ Classi\uFB01cation Method for Crops\nBasedonSpatiotemporalDeep-LearningFusionTechnology.\
    \ IEEE Transactions on Geoscience and Remote Sensing,\n60:1\u201316,2022. ISSN\
    \ 1558-0644. doi: 10.1109/TGRS.2021.3113014.\nLin Yuan, Jingcheng Zhang, Yeyin\
    \ Shi, Chenwei Nie, Liguang Wei, and Jihua Wang. Damage Mapping of Powdery\nMildew\
    \ in Winter Wheat with High-Resolution Satellite Image. REMOTE SENSING, 6(5):3611\u2013\
    3623, May 2014.\ndoi: 10.3390/rs6053611.\nFrancisco Zambrano, Anton Vrieling,\
    \ Andy Nelson, Michele Meroni, and Tsegaye Tadesse. Prediction of drought-\ninducedreductionofagriculturalproductivityinChilefromMODIS,rainfallestimates,andclimateoscillationindices.\n\
    REMOTE SENSING OF ENVIRONMENT, 219:15\u201330, December 2018. ISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2018.\n10.006.\n22Mohammad Zeynoddin and Hossein Bonakdari.\
    \ Structural-optimized sequential deep learning methods for surface\nsoil moisture\
    \ forecasting, case study Quebec, Canada. NEURAL COMPUTING & APPLICATIONS, 2022.\
    \ ISSN\n0941-0643. doi: 10.1007/s00521-022-07529-2.\nBo Zhang, Bin Guo, Bin Zou,\
    \ Wei Wei, Yongzhi Lei, and Tianqi Li. Retrieving soil heavy metals concentrations\
    \ based\non GaoFen-5 hyperspectral satellite image at an opencast coal mine, Inner\
    \ Mongolia, China. ENVIRONMENTAL\nPOLLUTION, 300, May 2022. ISSN 0269-7491. doi:\
    \ 10.1016/j.envpol.2022.118981.\nChenZhang,LipingDi,PengyuHao,ZhengweiYang,LiLin,HaotengZhao,andLiyingGuo.\
    \ Rapidin-seasonmapping\nofcornandsoybeansusingmachine-learnedtrustedpixelsfromCroplandDataLayer.INTERNATIONALJOURNAL\n\
    OF APPLIED EARTH OBSERVATION AND GEOINFORMATION, 102, October 2021a. ISSN 1569-8432.\
    \ doi:\n10.1016/j.jag.2021.102374.\nChenxiao Zhang, Peng Yue, Liping Di, and ZhaoyanWu.\
    \ Automatic Identi\uFB01cation of Center Pivot Irrigation Systems\nfrom Landsat\
    \ Images Using Convolutional Neural Networks. AGRICULTURE-BASEL, 8(10), October\
    \ 2018. doi:\n10.3390/agriculture8100147.\nJing Zhang, Dongli Ji, Dong Du, Jinjie\
    \ Miao, Hongwei Liu, and Yaonan Bai. Temporal paradox in soil potassium\nestimations\
    \ using spaceborne multispectral imagery. CATENA, 194, November 2020a. ISSN 0341-8162.\
    \ doi: 10.\n1016/j.catena.2020.104771.\nLi Zhang, Xiaolei Lv, Qi Chen, Guangcai\
    \ Sun, and Jingchuan Yao. Estimation of Surface Soil Moisture during Corn\nGrowthStage\
    \ fromSAR and OpticalData Using a Combined Scattering Model. REMOTE SENSING, 12(11),June\n\
    2020b. doi: 10.3390/rs12111844.\nLiangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan\
    \ Cao, and Fulu Tao. Combining Optical, Fluorescence, Thermal\nSatellite,andEnvironmentalDatatoPredictCounty-LevelMaizeYieldinChinaUsingMachineLearningApproaches.\n\
    REMOTE SENSING, 12(1), January 2020c. doi: 10.3390/rs12010021.\nLiangliang Zhang,\
    \ Zhao Zhang, Yuchuan Luo, Juan Cao, Ruizhi Xie, and Shaokun Li. Integrating satellite-derived\n\
    climatic and vegetation indices to predict smallholder maize yield using deep\
    \ learning. AGRICULTURAL AND\nFOREST METEOROLOGY, 311, December 2021b. ISSN 0168-1923.\
    \ doi: 10.1016/j.agrformet.2021.108666.\nXiaopingZhang,BoCheng,JinfenChen,andChenbinLiang.\
    \ High-ResolutionBoundaryRe\uFB01nedConvolutionalNeural\nNetwork for Automatic\
    \ Agricultural Greenhouses Extraction from GaoFen-2 Satellite Imageries. REMOTE\
    \ SENS-\nING, 13(21), November 2021c. doi: 10.3390/rs13214237.\nHongwei Zhao,\
    \ Zhongxin Chen, Hao Jiang, Wenlong Jing, Liang Sun, and Min Feng. Evaluation\
    \ of Three Deep\nLearning Models for Early Crop Classi\uFB01cation Using Sentinel-1A\
    \ Imagery Time Series-A Case Study in Zhanjiang,\nChina. REMOTE SENSING, 11(22),\
    \ November 2019. doi: 10.3390/rs11222673.\nHongwei Zhao, Sibo Duan, Jia Liu, Liang\
    \ Sun, and Louis Reymondin. Evaluation of Five Deep Learning Models for\nCrop\
    \ Type Mapping Using Sentinel-2 Time Series Images with Missing Information. REMOTE\
    \ SENSING, 13(14),\nJuly 2021. doi: 10.3390/rs13142790.\nWenzhi Zhao, Yang Qu,\
    \ Liqiang Zhang, and Kaiyuan Li. Spatial-aware SAR-optical time-series deep integration\n\
    for crop phenology tracking. REMOTE SENSING OF ENVIRONMENT, 276, July 2022. ISSN\
    \ 0034-4257. doi:\n10.1016/j.rse.2022.113046.\nYa\u2019nan Zhou, Jiancheng Luo,\
    \ Li Feng, Yingpin Yang, Yuehong Chen, and Wei Wu. Long-short-term-memory-based\n\
    crop classi\uFB01cation using high-resolution optical images and multi-temporal\
    \ SAR data. GISCIENCE & REMOTE\nSENSING, 56(8):1170\u20131191,November 2019. ISSN\
    \ 1548-1603. doi: 10.1080/15481603.2019.1628412.\n23"
  format: application/pdf
- content: "1\nA systematic review of the use of Deep Learning in\nSatellite Imagery\
    \ for Agriculture\nBrandon Victor , Aiden Nibali , Zhen He\nAbstract\u2014Agriculturalresearchisessentialforincreasingfood\
    \ and thus applying them across huge areas [61]. Compared\nproduction to meet\
    \ the needs of a rapidly growing human to ground-level images, satellite images\
    \ have lower spatial\npopulation.Collectinglarge quantitiesof agricultural datahelps\n\
    3 resolutions, higher spectral resolution and are typically pro-\nto improve decision\
    \ making for better food security at various\n2 cessed to obtain re\uFB02ectances\
    \ (a physical measurement), so\nlevels: from international trade and policy decisions,\
    \ down to\n0\nindividual farmers. Recently, there has been great interest in these\
    \ algorithms have typically operated per-pixel, ignoring\n2\nusingsatelliteimagestocollectagriculturaldataoverhugeareas\
    \ the contextual or spatial information around them. This is\n \nc and at different\
    \ scales. As more satellite images have become in stark contrast with generic\
    \ computer vision research -\ne available at various different spatial, spectral\
    \ and temporal\nand Convolutional Neural Networks (CNNs) in particular -\nD resolutions\
    \ many researchers have sought to utilise these extra\nwhich has always emphasised\
    \ learning spatial relationships.\n  dimensions \u2014 along with the recent successes\
    \ in deep learning\n5 \u2014 to effectively translate from satellite images to\
    \ agriculturally However,the greatsuccesses of genericcomputervision have\n1 relevant\
    \ data. This systematic review of 193 studies describes encouragedresearcherstotransferthese\
    \ popularalgorithmsto\n \n  a taxonomy of the various ways deep learning is being\
    \ used many application areas [6], includingEarth Observation tasks\n]\non satellite\
    \ images for agriculture and compares it to generic\nV [70,12],andwe\uFB01ndthatthistrendhasalsosuccessfullybeen\n\
    computervision.Thebreadthof agriculturaltasksareidenti\uFB01ed\nC and the trends\
    \ within each analysed. As an overall trend, adopted for agricultural tasks.\n\
    . Convolutional Neural Networks (CNNs) consistently outperform In this review,\
    \ we systematically identi\uFB01ed 193 studies\ns older machine learning methods,\
    \ whereas Long Short-Term at the intersection of deep learning techniques, satellite\
    \ im-\nc\n[ Memory (LSTM) models do not. Unfortunately, there is a lack agery\
    \ and agricultural applications (see Section II). To our\n  ofdirectcomparisonsbetweenmethodsforallagriculturaltasks,\n\
    \  knowledge this is the \uFB01rst such systematic review. We start\n2 highlighting\
    \ the need for benchmarking on public datasets.\nby describing how satellite images\
    \ differ from ground-based\nv\n2 Index Terms\u2014Systematic Review, Deep learning,\
    \ Satellite im- images, and thus how deep learning approaches on satellite\nagery,\
    \ Agriculture, Computer Vision\n7 images typically differ (Section III). We highlight\
    \ relevant\n2 modern deep learning methods and architectures (Section IV)\n1\n\
    and thus describe a taxonomy of methods for how each\n0 I. INTRODUCTION\nmodelisactuallybeingapplied,speci\uFB01\
    callytosatelliteimages\n0. THEREarebigagriculturalchallengescoming.Thehuman (Section\
    \ V). We identify various different agricultural tasks,\n1 population is expected\
    \ to increase signi\uFB01cantly in the\nanddescribe them eachin moredetail(Section\
    \ VI), including\n2 next decades [115], which will require an estimated global\n\
    thetrendswithineachwithrespecttothetaxonomyofmethods\n2\nyield increase of 25-70%[47],\
    \ along with a changing climate\n: from earlier.\nv bringing additional challenges\
    \ [111] and the need to reduce\nWefoundthattherewereveryfewexamplesofmoderndeep\n\
    Xi the environmentalimpact of agriculture [36]. learning methods from before 2020,\
    \ but since then they have\nRemote sensing is an extremely useful tool because\
    \ it\nr becomeincreasinglypopular,withanexplosionofresearchin\na provides a non-destructive\
    \ and non-intrusive way to monitor\njust the last few years, mostly in crop segmentation\
    \ and yield\nagricultural \uFB01elds simultaneously at a \uFB01ne level of detail\
    \ and\nprediction. We found that where spatial ConvolutionalNeural\nacross wide\
    \ areas and times. This makes it a technology that\nNetworks (CNNs) were used,\
    \ they consistently outperformed\ncan be used for fast and targeted interventionsat\
    \ a farm-level\ntraditional machine learning methods across all tasks, but,\n\
    [40], regional studies of ecological change over time [94],\nspeci\uFB01cally\
    \ in the case of yield prediction, this was not\ncounty-level yield prediction\
    \ for logistics [31] and interna-\ntrue of Long Short-Term Memory models (LSTMs).\
    \ There\ntional trade decisions [71]. To achieve these, there are many\nwere few\
    \ papers that included attention-based models (both\nsources of worldwide satellite\
    \ imagery freely available to the\nViT[117] and custom architectures [34]), but\
    \ there was no\npublic and the most popular for agricultural purposes are:\nconsistentimprovement.Therewere\
    \ manyworksthatdirectly\nSentinel [113, 24], Landsat [95] and MODIS. Each of these\n\
    followed generic computer vision research, simply applying\nsatellite programs\
    \ store and manage enormous collections of\npopulararchitectures,andmanythatdidnot,butunlikegeneric\n\
    historical worldwideimagery,e.g. Sentineladded 7.34 PiB of\ncomputer vision research,\
    \ very few works utilised benchmark\nimagery to their archive in 2021 [102].\n\
    datasets or compared results with others at all. There were\nMuch research has\
    \ gone into translating these satellite many works that utilised extra spectral\
    \ data available in\nimages into agriculturally relevant information [38, 128,\
    \ 55],\nsatelliteimages,butveryfewusedthegeolocationdataortook\nadvantage of the\
    \ multi-scale inputs available, so we conclude\nBrandon Victor, Aiden Nibali and\
    \ Zhen He work within the School of\nwithrecommendationsforfutureresearchdirectionstoaddress\n\
    Computing, Engineering andMathematical Sciences atLaTrobeUniversity,\nMelbourne,\
    \ Victoria, Australia these gaps.2\nII. SEARCH STRATEGY often signi\uFB01cantly\
    \ better. Almost all satellite imagery have at\nleast 4 colour channels (red,\
    \ green, blue and near-infrared),\nTo create an initial list of papers, we used\
    \ a search query\nmany have more than 10 colour channels (e.g. Sentinel-2),\n\
    for Clarivate\u2019s Web of Science. To broadly \uFB01nd papers at the\nand some\
    \ have over 100 different colour channels [105],\nintersection of deep learning,\
    \ satellite images and agriculture,\nprovidingsigni\uFB01cantlymoreinformationperpixelthantypical\n\
    we used both generic and speci\uFB01c terms for each (see Table\nground-based\
    \ sources. Additionally, satellite image sensors\nI). For deep learning, this\
    \ was speci\uFB01c algorithm names. For\nare calibrated to obtain functions for\
    \ converting from sensor\nagriculture this was speci\uFB01c crop names from the\
    \ Cropland\nbrightness to re\uFB02ectance - a physical property of the imaged\n\
    Data Layer [116]. The resultant tagged library of studies is\nsurface,independentofilluminationandsensor-whichallows\n\
    available as supplementary materials.\nquantitative analysis of the Earth\u2019\
    s surface.\nThis initial search yielded 770 studies. We performed an\nTheoretically,\
    \ with a suf\uFB01ciently precise sensor - and con-\ninitial rapid pass through\
    \ the collection of studies to \uFB01lter out\nverting to re\uFB02ectance values\
    \ - all surfaces could be uniquely\nstudiesthatwerenotattheintersectionofdeeplearning,satel-\n\
    identi\uFB01ed by matching each pixel to a spectral signature\nlite imagery and\
    \ agriculture, ultimately yielding 193 studies.\nmeasuredinalab.Indeed,thisidealisthebasisofmanyhand-\n\
    The majority of these studies were for crop segmentationand\ncrafted models (e.g.\
    \ Linear Mixture Model [2]). However,\nyield prediction, thus, the studies for\
    \ those tasks were further\nsuch a precise sensor does not exist, and signi\uFB01\
    cant noise\n\uFB01ltered as follows:\nis introduced by the lack of spatial and\
    \ spectral resolutions,\n\u2022 2020andearlier:studyisincludedifithasatleastxcita-\n\
    atmosphericeffectsandothererrorsin calculatingre\uFB02ectance,\ntions on Google\
    \ Scholar (x=50 for crop segmentation;\nleading to the dominance of machine learning\
    \ algorithms to\nx=25 for yield prediction)\nlearnthevariedappearancesofsurfacesfromthedata[67,58].\n\
    \u2022 Jan 2021 - October 2022: all were included.\nTherearecurrentlymanysourcesoffreelyavailablesatellite\n\
    WedidnotincludemethodsusingUAVimagerybecausewe\nimagerywithworldwidecoveragetotrainthesealgorithms.In\n\
    were interested in methods for resolving the tension between\nthe reviewed studies,\
    \ the most common were:\nobjectsizeandpixelsizeinsatelliteimagery.Forcropsegmen-\n\
    \u2022 Moderate Resolution Imaging Spectroradiometer\ntation studies (Section\
    \ VI-A), we only include studies which\n(MODIS) imagery at 250-1000m resolution\
    \ which has\nused multiple agricultural classes. Soil monitoring studies\nbeen\
    \ publicly available since 2000, along with many\n(SectionVI-B)oftenonlyimpliedanagriculturalsigni\uFB01\
    cance,\nmodel-based maps, such as land surface temperatures,\nbut, since soil\
    \ has such a strong in\uFB02uence on agriculture, and\nevapotranspirationand leaf\
    \ area index (LAI).\nrelatively few studies, we include all found soil monitoring\n\
    \u2022 Landsat imagery which has been freely available to the\nstudies, even if\
    \ they did not explicitly have an agricultural\npublic since 2008 [137], of which\
    \ most reviewed studies\nmotivation.\nused Landsat-8 imagery at 30m resolution.\n\
    Although this review is systematic, it is not exhaustive,\n\u2022 Sentinel imagery\
    \ from the Sentinel program of the Eu-\nand not just because of the above \uFB01\
    ltering. By limiting the\nropean Space Agency which has provided optical im-\n\
    review to studies indexed by Clarivate\u2019s Web of Science, we\nageryat10-60mresolutionandSyntheticApertureRadar\n\
    are deliberately selecting for higher pro\uFB01le works than if we\n(SAR) imagery\
    \ at 5-40m resolution since 2014.\nincludedsearchesacross all publishedliterature.Additionally,\n\
    The resolution of these data sources can dictate the res-\nthe search terms may\
    \ not reveal all possible relevant studies,\nolution at which analysis can be\
    \ performed; for example,\nhowever, we believe that they are suf\uFB01cient to\
    \ return a repre-\ncounty-level yield prediction always uses MODIS imagery\nsentative\
    \ sample of all relevant studies.\nand \uFB01eld-level yield prediction always\
    \ uses Landsat/Sentinel\nThere was also some inconsistency in terminology in the\n\
    imagery. These are obvious pairings because MODIS pixels\nreviewedstudies.Intheinterestofclarity,andtoassistanyone\n\
    are largerthan individual\uFB01elds, andimagesof entirecounties\nunfamiliar with\
    \ these terms, the variations are summarised in\nusingLandsat/Sentinelimagerywouldrequireanunreasonable\n\
    Table II.\namount of disk space and computation time. At the coarser\nresolutions,\
    \ there was a strong preference in the reviewed\nIII. SATELLITEIMAGES articles\
    \ to pose the problem as just time series analysis,\nObjects imaged by satellites\
    \ are typically signi\uFB01cantly rather than a spatio-temporal one. Further,\
    \ in several works\nsmaller than the ground spatial distance (GSD) covered by\
    \ [53, 103, 78] and datasets like LUCAS [19], the problem is\neach pixel. For\
    \ example, the colour of each pixel in a satel- posedasasingle-pixelproblem,onlyprovidinglabelsforaset\n\
    lite image of farmland might be aggregated from hundreds, of sparsely distributed\
    \ points. Although this doesn\u2019t preclude\nthousands or even millions of individual\
    \ plants. This massive the use of CNNs [52], such a dataset discourages it.\n\
    differencein scale between objectand pixelsizes has encour- Spatial resolution\
    \ in satellite imagery has increased over\naged researchers to focus on understanding\
    \ the contents of the years, such that some commercial satellite providers now\n\
    individual pixels with per-pixel algorithms [8, 9], rather than sell images with\
    \ resolution as \uFB01ne as 34cm per pixel, a\nthe typical computer vision approaches\
    \ which primarily use resolution suf\uFB01ciently \uFB01ne to detect individual\
    \ trees from\nthe structured pattern of multiple spatially-related pixels to satellite\
    \ images [37, 65, 30, 66]. This increased resolution\nunderstand an image [32,\
    \ 123]. has encouragedsatellite imagery analysis to utilise the spatial\nWhile\
    \ the spatial resolution relative to the imaged objects information - as in generic\
    \ computer vision - as well as the\nis much worse for satellite imagery, the spectral\
    \ resolution is higher spectral resolution and re\uFB02ectance calibration typically3\n\
    TABLEI\nTHESEARCHTERMSUSEDINTHEQUERYFORCLARIVATE\u2019SWEBOFSCIENCE.THEREISAN\"\
    AND\"BETWEENEACHTOP-LEVELCONCEPT(I.E.[DEEP\nLEARNING]AND[SATELLITE]AND[AGRICULTURE]),ANDAN\"\
    OR\"BETWEENEACHTERMUNDERTHAT.THELISTOFSPECIFICCROPSCOMESFROM\nTHECDL[116].THESEARCHINTERFACEENFORCESALIMITTOTHENUMBEROF\"\
    ALL\"SEARCHTERMS,SOONLYTHEABSTRACTANDTOPICWERE\nSEARCHEDFORSPECIFICAGRICULTURETERMS.THEFULLLISTOFAGRICULTURALTERMSISAVAILABLEINTHESUPPLEMENTARYMATERIALS\n\
    SECTION.\nDeep Learning Satellite Agriculture\nAll All All Abstract Topic\nDeepLearn*,CNN,RNN,LSTM,\
    \ Satellite Farm, Wheat, Corn, Maize, Orchard, Coffee, Vineyard, *wheat, *\uFB02\
    ower*,\nGRU,Transformer,NeuralNetwork, Agri*, Soy,Rice,Cotton,Sorghum,Peanut*,Tobacco,Bar-\
    \ *berries, *melon*,\nDeepBeliefNetwork, Autoencoder Crop ley,Grain,Rye,Oat,Millet,Speltz,Canola,...[+52\
    \ *berry\nmore]\nTABLEII\nSOMEDEFINITIONSFOR(SOMETIMESINCONSISTENT)TERMINOLOGYFOUNDINTHELITERATURE.\n\
    Words Idea\nRadiative transfer;re\uFB02ectance; backscatter Re\uFB02ectanceistheproportionoflightwhichre\uFB02\
    ectsoffofasurface.Thisisaphysicalproperty\nof the surface, and can be measured\
    \ in a laboratory. Radiative transfer models describe the\nphysical process of\
    \ re\uFB02ectance, while backscatter is re\uFB02ectance that is the result of\
    \ arti\uFB01cial\nlighting, typically microwaves.\nSub-pixel fractional estimation;\
    \ Linear Unmix- Amodelofapixelasbeingsomeproportionofjustafewtypesoflandcover,andthusevery\n\
    ingModel;LinearMixture Model pixel\u2019scolourisexplainable asan(oftenlinear)combinationofthesecovertypes(seeSection\n\
    III)\nDownscale; upsample;\uFB01nerresolution Downscaling and upsampling can have\
    \ the same meaning because there is a con\uFB02ict in\nterminologybetweenremotesensingscientistsandcomputerscientists,withinversemeanings.\n\
    Inthisreview, wehaveused\u201Ccoarser\u201D or\u201C\uFB01ner\u201Dtoavoidconfusion.\n\
    Multitemporalimages;timeseries;SatelliteIm- Indicates the use of temporal data.\
    \ Generally, stacked images of the same location over\nageTimeSeries (SITS);temporaldata\
    \ weeks/months (seeSection V)\nMulti-layerperceptron(MLP);Arti\uFB01cialNeural\
    \ Although ANN can technically refer toany Neural Network, itis typically usedto\
    \ refer to a\nNetwork(ANN);DeepNeuralNetwork(DNN) smallMLP.Generally, DNNrefers\
    \ toanMLP,butaDCNNreferstoaCNNspeci\uFB01cally.\nModelinversion Training a statistical\
    \ model to predict the inputs of a theoretical model from either ground-\nmeasuredoutputs,oroutputsofthetheoretical\
    \ modelitself.Agoodsummaryofthewaysthis\nisusedisgivenin[128].\nObject-based;\
    \ \uFB01eld-based; parcel-based; super- Usingaggregated colourinformation acrossawholeobjector\uFB01\
    eldorparcelorsuperpixel for\npixel prediction.\nused for satellite images (e.g.\
    \ [26, 99, 121]). We note that performance. In all studies reviewed in all tasks\
    \ except yield\nalthough spatio-temporal input has the richest information, prediction,moderndeeplearningmethodsoutperformedtradi-\n\
    it is not always available. For example, very-high resolution tionalmachinelearningmethods.Inyieldprediction,2DCNNs\n\
    commercial satellite imagery is expensive and sparsely col- consistently outperformed\
    \ traditional machine learning meth-\nlected, thus most studies using commercial\
    \ satellite imagery ods, but LSTMs did not.\noperated on a relatively small number\
    \ of individual images In the literature, various algorithms are called \u201C\
    deep learn-\n(e.g. [90, 18, 101]). ing\u201D. In this review, we refer to three\
    \ main types of modern\ndeep learning: CNNs, RNNs and Attention. With a decade\n\
    since AlexNet [60], and an explosion of research, Convo-\nIV. DEEPLEARNING\nlutional\
    \ Neural Networks (CNNs) are the current de facto\nIn many domains, machine learning\
    \ has found accurate standard in generic computer vision tasks. Recurrent Neural\n\
    relationships in spite of many variations in appearance and Networks (RNNs) are\
    \ a common deep learning method for\nmuch noise. The data-drivennature of machine\
    \ learningtech- sequence modelling; almost all cases of which use either\nniqueshandlessuchvariationsandmodelsarbitrarilycomplex\
    \ a Long Short-term Memory (LSTM) or a Gated Recurrent\nrelationships while simultaneously\
    \ including tools to prevent Unit (GRU) version of RNNs. \u201CAttention\u201D\
    \ can mean many\nover\uFB01ttingtothenoise.Wefoundthatinsingle-pixelproblems,\
    \ different things; here we will use it to mean, speci\uFB01cally,\nRandomForests(RFs),\
    \ SupportVectorMachines(SVMs)and multi-headattention as describedby [117], as\
    \ this is the basis\nMulti-layerPerceptrons(MLPs)weregenerallyclosecompeti- for\
    \ the recently popularised Vision Transformers [23] which\ntors,witheachmethodbeingmoreaccurateindifferentstudies\
    \ have outperformed CNNs on recent ImageNet competitions.\nin roughly equal proportions\
    \ (e.g. [29, 54, 103]). In this review we use \u201Cdeep learning\u201D to mean\
    \ any neural\nComparedtoothermachinelearningmethods,deeplearning networkmethod,and\u201C\
    moderndeeplearning\u201DtoexcludeMLP-\nis known to be able to construct signi\uFB01\
    cantly more complex only algorithms. We will not discuss the technical details\
    \ of\nmodels[39],allowingthemtobemorerobusttonoisytraining these deep learning\
    \ algorithmsin this review; instead we will\ndata. Another major bene\uFB01t of\
    \ deep learning models is that mention the most signi\uFB01cant modern advances\
    \ and refer the\nmanual feature extraction is no longer required because the reader\
    \ to existing explanations for more details [39, 12, 55].\nmodel learns to create\
    \ its own features. This comes at the The ImageNet classi\uFB01cation dataset\
    \ [21] has had an enor-\nprice of requiring larger datasets to observe this improved\
    \ mous in\uFB02uence on the trajectory of computer vision research.4\ncontextualcluesin\
    \ itsprediction.Thus,we createa taxonomy\nof input types to help understand how\
    \ satellite images are\nbeing used differently across studies.\nIn Figure 1, we\
    \ highlight the initial data shapes used\nin existing literature: a single pixel\
    \ (type P-x), a temporal\nsequence of pixels (type T-x), a single image (type\
    \ S-x) or\na temporalsequenceof images(type ST-x). Then,in Figure2\nwedescribeourtaxonomyofdifferentinterpretationsofthose\n\
    data shapes which authors have used to structure their data\nfor use in modern\
    \ deep learning algorithms. We name these\ninterpretationsby their initial data\
    \ shape as the \uFB01rst character\nandtheirinterpretedshapeas the secondcharacter.Theinitial\n\
    data shapes can then be interpreted as one of: a vector of\nfeatures (type X-f),\
    \ a sequence of pixels (type X-s), a single\nimage(typeX-i),animagecube(typeX-c),oranobject(type\n\
    X-o). For example, type T-s denotes an interpretation of a\ntemporalsequenceofpixels(T)formodelsthattakeadvantage\n\
    of the fact that it is a sequence (s).\nTraditional machine learning methods such\
    \ as Random\nForests (RFs), Support Vector Machines (SVMs) and Multi-\nFig. 1.\
    \ Depending on the images available, a problem can be posed as a layer Perceptrons\
    \ (MLPs) generally require a 1D vector of\nrelationship between a single pixel\
    \ input (blue cell) from a single image\nfeaturesasinput(typesP-fandT-f),butmoderndeeplearning\n\
    (yellowgridofcells)andeachprediction(redcell),oritcanincludecontextual\npixelsfromspatialand/ortemporaldomains(bluegridofcells).Thebottom\
    \ methodsgenerallyhaveamulti-dimensional/sequentialinter-\nrightsituation isalsocalledspatio-temporal\
    \ (ST)data. pretation of the data (see Table III). Several papers reframed\nthedatatomakespeci\uFB01\
    cmoderndeeplearningmethodsmore\nobviouscandidates.Inparticular,treatingspectralinformation\n\
    It is common - when deep learning is applied to a new\nas a sequence in order\
    \ to apply sequence analysis algorithms.\ndomain - for authors to use architecturesthat\
    \ achieved a high\nFor example, type P-f and type P-s have precisely the same\n\
    rankintheImageNetcompetition.Inparticular,AlexNet[60],\ndata, but by interpreting\
    \ a single pixel (type P) as a sequence\nVGG [104]andResNet [44] havereceivedthemostattention.\n\
    of colours (type P-s), 1DCNNs and LSTMs become obvious\nSimilarly for segmentation\
    \ models, models that performed\nmodelchoices. Similarly,temporaldata (type T)\
    \ can be inter-\nwell on the MS COCO and PASCALVOC datasets have been\npreted\
    \ as a spectral/temporal \u201Cimage\u201D (type T-i), and spatial\nadopted. The\
    \ most popular segmentation architectures are\ndata(typeS)canbeinterpretedasaspatial/spectralimagecube\n\
    based on UNet [93] and DeepLabv3 [17].\n(typeS-c)tousehigherdimensionalCNNkernels.Interpreting\n\
    Two of the most signi\uFB01cant innovations of modern deep\nspectral information\
    \ as a sequence is rarely theoretically\nlearningare focusedaroundtrainingdeepermodels:skip\
    \ con-\njusti\uFB01ed, but multiple authors noted improved performance\nnections\
    \ [44] and inter-layer normalisation (e.g. BatchNorm\ndoing so [61, 20, 101].\n\
    [50], LayerNorm [4], etc). These two ideas have been almost\nSometimestheinterpretationcomesaboutbecauseoflabels.\n\
    universally adopted by all popular modern deep learning\nIn yield prediction especially\
    \ (see Section VI-E), ground\narchitectures, and with modern programming libraries\
    \ these\nlabels are often annotated at a \uFB01eld or county or country\nare easily\
    \ incorporated into custom architectures created by\nlevel (collectively, \u201C\
    objects\u201D) which are shown as types S-o\nindividual studies (e.g. [5, 33]).\
    \ Many works reviewed also\nand ST-o, depending on whether temporal data was included.\n\
    used Dropout [46]; another popular addition to training deep\nIn such cases, the\
    \ relationship between the colour in the\nlearning models for training more robust\
    \ models.\npixels and the \uFB01nal prediction are not necessarily present in\n\
    each and every pixel contained within the the object, so a\nV. COMMON METHODS\n\
    common method is to aggregate the information within an\nA. Taxonomy\nobject before\
    \ a model sees the data. Most commonly, the\nSatellite images are quantised measurements\
    \ of our real colour information is averaged, however [57] showed good\nworldalongmultipledimensions:onespectral,twospatialand\
    \ performance by computing a colour histogram per county\nonetemporal.Inthebestcaseeverypredictionisbasedona4-\
    \ instead. These interpretations remove the spatial component,\ndimensional data\
    \ cube of spatio-temporal (ST) data, but such so after aggregation, S-o is subsequently\
    \ re-interpreted as\ndata can be computationally expensive to use or impractical\
    \ either P-f or P-s, and ST-o is subsequently re-interpreted as\nto obtain, so\
    \ many works operate on data without a spatial or one of T-f, T-s or T-i.\ntemporal\
    \ (or both) dimension. The shape of input data puts It is worth noting that a\
    \ single 2D image is actually a\nimportantemphasisandlimitationsonmodelstrainedonsuch\
    \ three-dimensionaltensorofdata:twospatialandonespectral.\ndata: for example,\
    \ LSTMs are usually applied by processing A 2DCNN operates on this 3D data by\
    \ treating the spectral\neach temporal sequence of pixels independently, which\
    \ can informationasthe\u201Cchannels\u201Ddimension.Similarly,atemporal\nobservechangesovertime,butwouldn\u2019\
    tbeabletousespatial stack of 2D images is a four-dimensional tensor of data: two5\n\
    Fig.2. Thedatacanbeinterpreted indifferentwaystoallowtheuseofdifferentmodels.Eachofthesedatashape/interpretations\
    \ pairsisgivenanamelike\nTypeX-xtodenotetheoriginal typeandit\u2019sinterpretation.\
    \ The\uFB01rstcolumnofinterpretations havenotemporalcomponent, whilethesecondcolumndoes.\n\
    The top row treat the input as a 1D vector with no special ordering. The second\
    \ row treat the input as a 1D sequence. The third row treat the input as an\n\
    image.Thefourthrowtreattheinputasanimagecube.Thelastrowaggregatenon-squarespatialinformationtoproduce\uFB01\
    xedsizefeaturesformodelinput.\nAlthoughspectralinformationisdepictedhere,severalstudiesreplacedthespectralinformationwithasetofotherfeatures:vegetationindices,topographical,\n\
    atmospheric, soil,etc.\nspatial, onespectralandonetemporal.A 3DCNN operateson\
    \ imagery by obscuring the targets of interest. It is common\na 4D \u201Cimage\
    \ cube\u201D. Thus, in the literature, an \u201Cimage cube\u201D to simply exclude\
    \ single and multitemporal pixels that are\nmay referto the 3D data froma single\
    \ 2D imageafter adding occludedbyclouds[61]whenoperatingata pixellevel(Type\n\
    a singleton \u201Cchannels\u201D dimension (type S-c), or it may refer PorTypeT),orinterpolatethecolourinformationfromearlier\n\
    to the standard 4D data, using the spectral information as the and later images\
    \ (e.g. [48, 5, 49]) when using temporal data\n\u201Cchannels\u201D dimension\
    \ (type ST-c). (Type T or ST). Another common strategy is to create single\nThe\
    \ terminology used for this taxonomy can be used for image composites from images\
    \ taken at different times (e.g.\ncombinations not shown in Figure 2. For example,\
    \ [15] and [120, 68]). Some authors remove entire images from their\n[82] both\
    \ interpreted spatiotemporal as an image (type ST- training set if there is too\
    \ much cloud cover [76]. Discarding\ni) without aggregationand in completely differentways.\
    \ This entire samples reduces the number of examples available for\ntaxonomydoesnotexhaustivelydescribeeverypossiblewayto\
    \ modeltraining,andwhenusingmultitemporaldata,discarding\nuse data with modern\
    \ deep learning algorithms, but describes either the whole multitemporal pixel\
    \ or individual images\nthe main cases with a consistent terminology. in the sequence\
    \ degrades performance. [91] collected both\nLandsat-8andSentinel-2images,andwhenaSentinel-2image\n\
    B. Clouds was too cloudy,replaced it with a Landsat-8image. And [75]\nshowamethodtoexplicitlyencodevariabletemporalsampling\n\
    Cloud cover and other atmospheric effects present sig-\ninto a recurrent model\u2019\
    s architecture to prevent performance\nni\uFB01cant challenges to Earth Observation\
    \ tasks using optical6\nTABLEIII\nEACHMODELHASAREQUIREDINPUTSHAPE,ANDEACHDATAINTERPRETATIONISINTENDEDTORE-ARRANGETHEINPUTTOFITTHEMODEL.TYPE\n\
    X-FISANYFEATURESTACKINTERPRETATION,TYPEX-SISANYSEQUENCEINTERPRETATION,TYPEX-IISANYIMAGEINTERPRETATIONANDTYPE\n\
    X-CISANYIMAGECUBEINTERPRETATION(SEEFIGURE2).\nN\nN\nR n\nTree SVM MLP 1DCNN 2DCNN\
    \ 3DCNN RNN CNN+ Attentio\nTypeX-f X X X\nTypeX-s X X X\nTypeX-i X X\nTypeX-c\
    \ X X X\ndegradation. Other authors argue that deep learning is robust in the\
    \ reviewed articles (98/193),and within LULC crop seg-\ntooccasionalentireimagesbeingcompletelycoveredincloud\
    \ mentationwasthemostpopularsubtask(73/98LULCstudies;\nand use the data without\
    \ explicitly handling clouds [26, 114]. see Table VI and supplementarymaterials).\
    \ This popularityis\nCloud cover poses no issue for Synthetic Aperture Radar not\
    \ surprising, as land cover mapping is considered the most\n(SAR)imagery,socloudcovercanbemitigatedbyusingboth\
    \ important descriptor of the environment [45]. The power of\nopticalandSAR imagery(e.g.[124]).Fewworkstookadvan-\
    \ LULCiswidelyrecognisedandgovernmentsacrosstheworld\ntage of Sentinel-1 SAR imagery\
    \ in addition to their own, but publicly provide large-scale LULC maps (e.g. [116,\
    \ 19, 1]),\nthosethatdidnotedimprovedperformance[124,77,109,81]. createdthrougha\
    \ combinationof visualinspectionof satellite\nimagery, census information, local\
    \ expertise and automated\nmethods (e.g. linear unmixing model). Automated methods\n\
    C. Temporal mismatch\nare the least reliable of these, but are the easiest to\
    \ scale up.\nGround-basedin situ measurementsare generally not coor- Thus, the\
    \ goal of research into LULC and crop segmentation\ndinated with satellite imagery.\
    \ Instead the measurements are is to improve the quality of the automated methods\
    \ so that\ntaken, and then paired with images at the closest available eventually\
    \ they become at least as reliable as expert humans.\ntime, leading to a temporalmismatch.\
    \ In the reviewed studies\nWhen creating data sources for developing LULC models\n\
    there are three methods for handling this temporal mismatch\nit is impossible\
    \ to both manually annotate every pixel and\n(roughly in order of popularity):\
    \ ignore it; interpolate ground\nthen manually verify each \uFB01eld at ground\
    \ level. There is\nlabels to match image collection date [59]; or interpolate\
    \ im-\nalso inherent ambiguity of what is visible in these images,\nages to match\
    \ measurement date [10]. Ignoring the mismatch\nso, even with the huge manual\
    \ effort that goes into creating\nis popular because it is a reasonable action\
    \ to take if the\nthese data sources, they are known to have signi\uFB01cant error\n\
    property is not expected to change signi\uFB01cantly during the\nin them; e.g.\
    \ the Cropland Data Layer (CDL) [116] has an\ntimescale of mismatch, and most\
    \ properties of interest do not\nerrorrateof5-15%formajorcroptypes[11].ManyEuropean\n\
    change much over a few days to a week.\ncountries require that farmers register\
    \ what crops they grow -\nalong with farm boundaries - when applying for government\n\
    VI. TASKS rebates.Notably,France,Switzerland,Norwayandothershave\nstarted to provide\
    \ this data publicly in a quasi-anonymised\nThe reviewed studies were manually\
    \ categorised into one\nform providing huge data sources of labels to train machine\n\
    of 5 groups of tasks (see Table IV). These categories were\nlearning models, and\
    \ is the basis of most public benchmark\ndetermined based on the papers reviewed,\
    \ rather than being\ndatasets for LULC. These initiatives create high quality\
    \ data\nimposedfromthebeginningandareroughlyarrangedinorder\nsources with few\
    \ errors, although it should be noted that\noftheplant\u2019slifecycle:\uFB01\
    rst,weconsiderhowdeeplearningis\nfarmers may accidentally or deliberately misreport\
    \ the crops\nusedtodescribewherecropsarebeinggrownandthelocation\nthey are growing\
    \ [43], so even these are not error-free.\nof other farm equipment/landmarks(Section\
    \ VI-A). Next, we\nThis review makes a distinction between a data source and\n\
    explorehowdeeplearningisusedto evaluatethe soil\u2019shealth\na benchmarkdataset.Theformerisa\
    \ livingcollectionof data\n(SectionVI-B).Wethenconsidermethodsforobservingplants\n\
    that is frequently updated and covers wide areas, whereas a\nafter establishment:\
    \ evaluating the plant\u2019s growth (Section\nbenchmarkdatasetisa\uFB01xedsetofimagesandlabelsonwhich\n\
    VI-C), monitoring damage from disease or disaster (Section\ndifferent methods\
    \ can be compared directly across studies.\nVI-D), and \uFB01nally estimating\
    \ crop yield (Section VI-E). See\nLULC was the only task to have any benchmark\
    \ dataset or\nsupplementary materials for the full list of studies.\nnamed data\
    \ sources. See Table V for the list of data sources\nand benchmark datasets used\
    \ by the reviewed studies.\nA. Land Use and Land Cover\nDespite the availability\
    \ of this data, only 22 out of the 73\nThe task of Land Use and Land Cover (LULC)\
    \ is to either reviewed crop segmentation studies used continually updated\nclassify\
    \ each pixel of satellite/UAV imagery (segment), or government data sources, and\
    \ 9 used benchmark datasets\ndetect speci\uFB01c regions/objects in the images.\
    \ LULC is by far (mostly, their own). Over half (46/73) described methods\nthe\
    \ most common use of deep learning in satellite imagery for obtaining their own\
    \ segmentation maps. There are three7\nTABLEIV\nNUMBEROFPAPERSFOREACHTASK.BYFAR,CROPSEGMENTATIONWASTHEMOSTPOPULAR,FOLLOWEDBYCOUNTY-LEVELYIELDPREDICTION.\n\
    Land Use, Land Cover Soil Monitoring Plant Growth Disease/Damage Yield Est.\n\
    CropSegmentation (73) Moisture(14) Canopy cover/LAI(14) Disease(6) County-level\
    \ (23)\nFieldBoundary(8) Nutrients (6) GrowthStage(2) Damage(4) Field-level (7)\n\
    TreeCrownDelineation (6) Salinity (4) Other(3) Plot-level (2)\nDamDetection (4)\
    \ Pixel-level (2)\nOther(8) Other(7)\nLandsat\nTime\nType ST-c\n3DCNN,\nCrop\n\
    Spatial/Temporal 2DCNN+RNN,\nSegment.\nor Transformer\nImage cube\nFig.3. OneofthemorecommoninputmethodsforCropSegmentation\
    \ wasspatiotemporal datatreated asa4Dimagecube(TypeST-c).Thistypeofdata\ntypicallycomesfromLandsatorSentineldatasourceswhichprovideimagesatauniformtemporalresolution,andcanbeusedina3DCNN,or2DCNN/RNN\n\
    hybrid,orTransformermodels.\nTABLEV\nIDENTIFIEDCROPSEGMENTATIONSATELLITEBENCHMARKDATASETSANDDATASOURCES.BENCHMARKDATASETS(THOSEWITHATICKINB)HAVEA\n\
    CLEARLYDEFINEDSIZE,ANDTHUSCANBEUSEDTOCOMPAREDIFFERENTMETHODS.ONLYTHEMOSTPOPULARPUBLICGOVERNMENT\n\
    (NON-BENCHMARK)SOURCESAREINCLUDEDHERE.\nName Labels Location Years Size Source\
    \ B\nLUCAS[19] PointData Europe 2006-2018 63,000points;11.8MB In Situ / X\nVisual\n\
    Munichdataset [97] Shape\uFB01le Munich 2016-2017 137,000\uFB01elds;41.5GB Govt.\
    \ X\nBreizhCrops [98] Superpixels Brittany 2017 750,000 superpixel se- Govt. X\n\
    quences; 4.6GB\nZueriCrop[114] Shape\uFB01le Switzerland 2019 116,000\uFB01elds;38.5GB\
    \ Govt. X\nReunionIsland[25] Shape\uFB01le Reunion Island 2019 50,000\uFB01elds;290MB\
    \ Model X\nCampoVerde[100] Shape\uFB01le Brazil 2015-2016 513\uFB01elds;6.7GB\
    \ Visual X\nUOS2[83] Segmentation Spain 2020 1958x 256x256 tiles; Visual X\n5.5GB\n\
    PASTIS-R[35] Segmentation France 2019 2433x 128x128 tiles; Govt. X\n54GB\nSen4AgriNet\
    \ [106] Segmentation France, 2019-2020 250,000x S2 images; Govt. X\nCatalonia\
    \ 10TB\nFrenchLandParcel Shape\uFB01le France - - -\nIdenti\uFB01cation System\n\
    CroplandDataLayer Segmentation US - - -\n[116]\nCorineLandCover Segmentation Europe\
    \ - - -8\nmethods studies used to do this: manual \uFB01eld survey (26/73), reviewed\
    \ studies was Kussul et al. [61], who used their own\nmanual image survey (17/73),and\
    \ automated methods (8/73). custom architectures with \uFB01ve convolution layers\
    \ using a\nManual \uFB01eld surveys are the more dif\uFB01cult, expensive and\
    \ dataset of 100,000s of labelled pixels from \uFB01eld surveys and\nreliable\
    \ way to obtain ground data for training models. Using found that 2DCNNs outperformed\
    \ RF, MLP and 1DCNNs.\nan automated method to obtain training data for models\
    \ is From this time onwards, the majority of the papers reviewed\ncheaper and\
    \ less reliable, and largely limits deep learning used modern deep learning (excludingpurely\
    \ MLP methods):\nmodels to matching the automated method\u2019s dynamics, rather\
    \ there were 28 deep learning studies reviewed from 2021 and\nthan allowing it\
    \ to learn the true distribution, so a few works 21 of those used modern deep\
    \ learning methods.\nused a combination of each. For example, Rahimi-Ajdadi Most\
    \ studies in crop segmentation utilising 2DCNNs cre-\nand Khani [89] gathered\
    \ 55 data points from \uFB01eld surveys, ated their own architectures/ arrangementof\
    \ layers, typically\n360 from visual inspection and 550 from automatedmethods.\
    \ favouring shallower networks (<10 layers), with only a few\nAnd Zhou et al.\
    \ [136] and Hamer et al. [43] used automated using common architectures used in\
    \ generic computer vision\nsystems to initially label their satellite images,\
    \ then manually like VGG, ResNet and UNet (e.g. [52, 99, 121]). However,\n\uFB01\
    x the errors. Several works relied entirely on manual image using those existing\
    \ architectures was extremely common\nsurveys (e.g. [52, 78]), which is less reliable\
    \ than ground in all other LULC tasks, with all but two studies [84, 72]\nsurveys,howeveronlySaraliogluandGungor[101]\
    \ described using an existing architecture, and several using pretrained\na validation\
    \ method for their manual image survey. weights from ImageNet (e.g. [64, 30]).\
    \ There were two main\n1) Trends and recommendations: The most common data algorithms\
    \ used to process spatiotemporal data (Type ST-c;\nsources for the reviewed LULC\
    \ studies were the Sentinel- see Figure 3) the \uFB01rst is to use a 3DCNN (e.g.\
    \ [52, 124, 33]),\n1/Sentinel-2/Landsat-8satellites:18,40and10studies,respec-\
    \ and the second is to use 2DCNNs on the images and then\ntively,outof the 73\
    \ crop segmentationpapers. The Sentinel-1 use RNNs(GRUs/LSTMs)on theoutputs(e.g.[96,\
    \ 63,108]),\nsatellites provides SAR imagery (active microwave imaging), howeverthesemethodswerenotcomparedagainsteachother.\n\
    and the Sentinel-2 and Landsat-8 satellites provides multi- In generic computer\
    \ vision, transformers [23] are state-of-\nspectralopticalimagery(passiveimaging).Conceptually,these\
    \ the-artonsomemajorbenchmarks,soonemightwonderabout\ndifferent modalities contain\
    \ complementary information, and their performanceon satellite tasks. There were\
    \ 8 studies that\n9studiesusedbothtypesofdata.Ofthese,6studiesevaluated directly\
    \ referenced transformer networks, and a further 6 that\nthe bene\uFB01t of using\
    \ both image sources, and consistently used a similar multi-head attention mechanism\
    \ as is used in\nfound that it improved performance compared to using only transformers.\
    \ In all works that compared a transformer net-\none source [124, 77, 109]. Speci\uFB01\
    cally, while Ofori-Ampofo work to other moderndeep learning methods,the transformer\n\
    et al. [81] found that late fusion (averaging two model\u2019s performed equal\
    \ or worse [96, 131, 114, 75, 107, 106]. The\noutputs) was the most effective,\
    \ Garnot et al. [35] compared main other attention method used is a model called\
    \ Pixel-Set\nfusion types in many different scenarios and concluded with Encoder\
    \ and Temporal Attention Encoder (PSE-TAE) [34].\nrecommendationsfor each scenario.\
    \ This was only compared against other methods in a single\nOut of all of the\
    \ tasks reviewed in this paper, the deep study, and it was out-performedby a 1DCNN\
    \ with a Squeeze\nlearning methods for crop segmentation were the most varied\
    \ and Excitation module [107]. It has been noted that typical\nand novel, with\
    \ researchers using every different type from transformer networks require even\
    \ more training data than\nthe taxonomy in Section V-A. There seems to be two\
    \ main CNNs [23], stating that even ImageNet (1 million labelled\nreasons for\
    \ this: \uFB01rst is the popularityof the task, and second images) is too small,\
    \ so it is possible that the datasets used\nis the relative ease of obtaining\
    \ data, allowing datasets large in these satellite studies are simply not large\
    \ enough for\nenough to train modern deep learning methods. Most works transformer\
    \ networks to begin to outperform CNNs.\nreviewed were using at least 2000 data\
    \ points, and many LSTMsandGRUsaredrop-inreplacementsforoneanother\nwere in the\
    \ 10,000s, which - while small by deep learning when using RNNs, so it is possible\
    \ to compare these directly.\nstandards - are signi\uFB01cantly larger than datasets\
    \ used for There were 4 studies that found GRUs to perform better than\nthe other\
    \ reviewed satellite tasks. All major modern deep LSTMs, and 2 studies that found\
    \ the inverse.\nlearning algorithms are represented in the reviewed papers:\n\
    1DCNNs (19 studies), 2DCNNs (27), 3DCNNs (8), LSTMs\nB. Soil health\n(22), GRUs\
    \ (9), ConvLSTM/ConvGRU (7) and transformers\n(8)/other attention (6), with many\
    \ studies comparing between Soilhealthhasanimpactonallsurfacevegetation,however\n\
    these methods. In the reviewed articles, the best modern itcanbedif\uFB01culttomeasurefromspace.We\
    \ are-asalways-\ndeeplearningmethods(CNN/RNN/Attn)outperformedalltree limited\
    \ to measuring properties that cause a visible change\n(22 comparisons) (including\
    \ RF (21 comparisons)), SVM (12 within the spectra used to image the surface.\
    \ There were\ncomparisons)and MLP (6 comparisons)methodsin all cases. only 24\
    \ using deep learning to measure soil properties using\nAnecdotally, it was observed\
    \ that in many studies there were satellite images (see Table VII). These can\
    \ be put into three\nseveraldeeplearningalgorithmstested,andalmostallofthese groups:measuringsoil\
    \ moisture(14),soilnutrients(6)or soil\noutperformedtrees,SVMsandMLPsaswell.ForLULCtasks\
    \ salinity (4). In this section we include several papers which\nother than crop\
    \ segmentation, almost all of them posed the werenotspeci\uFB01callyonagricultural\uFB01\
    elds,sincethedistinction\nproblem as Type S-i and used 2D spatial CNNs (22/25).\
    \ between \u201Cagricultural\u201D and not isn\u2019t very clear. Only three of\n\
    The \uFB01rst use of modern deep learning techniques in the these studies used\
    \ modern deep learning methods and most9\nTABLEVI\nCOUNTSOFSTUDIESONLANDCOVERANDLANDUSE(LULC).VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHELABELSCOLUMN:FS\n\
    =FIELDSURVEY,IS=IMAGESURVEY,MB=MODEL-BASED,GOVT.=GOVERNMENT.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPES\n\
    INTHESAMESTUDY.SOMEUNCOMMONTYPESNOTSHOWN;FORFULLLISTSEESUPPLEMENTARYMATERIALS.\n\
    n VI Labels Model Type\nFS IS MB Govt. Dataset Tree SVM MLP CNN RNN Attn P-f P-s\
    \ T-f T-s S-i ST-c S-o(P-f) ST-o(T-f) ST-o(T-s)\nCrop Seg. 73 25 26 17 8 18 10\
    \ 28 21 23 54 31 14 17 3 12 18 18 18 2 4 7\nField Bounds 8 0 0 7 0 2 0 0 0 0 8\
    \ 0 0 0 0 0 0 8 0 0 0 0\nDamDet. 4 0 0 3 0 0 0 0 1 0 3 0 0 1 0 0 0 3 0 0 0 0\n\
    Tree Bounds 6 1 2 4 0 0 0 0 0 2 3 1 1 2 0 0 0 4 0 0 0 0\nOther 8 0 2 7 0 1 0 0\
    \ 0 0 8 0 0 0 0 0 0 8 0 0 0 0\nTABLEVII\nCOUNTSOFSTUDIESONSOILHEALTH.NISTHETOTALNUMBEROFSTUDIES.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHELABELS\n\
    COLUMN:FS=FIELDSURVEY,MBT/FSE=MODEL-BASEDFORTRAINANDFIELDSURVEYFOREVALUATION,SELF=SELF-LABELLED,GOVT.=\n\
    GOVERNMENT.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPESINTHESAMESTUDY.\nn VI Labels\
    \ Model Type\ne\nFS MBt/FS Self Govt. Tree SVM MLP CNN RNN P-f T-s S-i S-o(P-f)\n\
    Moisture 14 6 6 5 2 1 3 2 14 1 1 12 1 1 1\nNutrients 6 2 6 0 0 0 4 2 6 0 0 4 0\
    \ 0 1\nSalinity 4 3 4 0 0 0 1 2 3 1 0 3 0 1 0\nusing only an MLP (Type P-f; see\
    \ Figure 4) and did not over 500 data points. The three other studies [125, 86,\
    \ 41]\ncompare against any other method. only used MLPs and were small in scope,\
    \ with less than 100\nMapping soil moisture is useful for understanding hydro-\
    \ data points each.\nlogic processes, vegetation states, and climatic conditions\n\
    [27]. Active microwave imaging is often used to predict soil C. Plant physiology\n\
    moisturebecausethedielectricpropertiesofsoilchangeswith\nLeaf Area Index (LAI)\
    \ and Canopy Cover have a history\nmoisture for microwaves [22]. There are several\
    \ satellite-\nof being a proxy for overall plant growth [130], and are\nbased\
    \ worldwide spatially and temporally continuous active\nthe most commonlypredictedplantphysiologymeasurements\n\
    microwave imaging satellites used to estimate soil moisture\nfrom satellite imagery\
    \ using deep learning (14/19; see Table\nfrom space [80, 28, 56, 119]. Rabiei\
    \ et al. [88] provide a\nVIII).Canopycoverissimplyameasurementoftheproportion\n\
    summaryofdifferentbene\uFB01tsanddrawbackstousingdifferent\nof light being intercepted\
    \ by the plant, and thus is fairly\nremote sensing techniques. They point out\
    \ that much existing\nstraight forward to measure with remote sensing. LAI is\
    \ half\nwork utilising the active microwave satellites and distributed\nofthegreenleafareaperunitgroundsurfacearea[16],which\n\
    networks of soil monitoring stations are at a much coarser\nhas the capacity to\
    \ measure the extent of vertical/overlapping\nresolution than is useful for a\
    \ single \uFB01eld. In their work,\ncanopy cover. At ground level, LAI is typically\
    \ measured\ntheyusedrelatively\uFB01neresolutionopticalimagery(10m)with\nwith\
    \ a device such as the LAI-2000. This device measures\nCNNs (Type S-i), which\
    \ they found to be superior to other\nthe canopy cover at multiple angles, and\
    \ uses the assumption\nmachine learning methods.\nof uniformly randomly distributed\
    \ leaves to calculate LAI.\nThere were six studies which attempted to measure\
    \ soil Canopy cover and LAI are highly correlated metrics [79], so\nnutrients\
    \ using deep learning on satellite imagery, with all of these are considered together\
    \ for this review.\nthem using MLPs, but only three of them comparedmethods. The\
    \ majority plant physiology studies reviewed used only\nWang et al. [122] and\
    \ Zhang et al. [134] found that RFs MLPsastheirprimarymodelwithoutcomparingagainstother\n\
    worked better than MLPs and Song et al. [105] found that an machinelearningmethods;11/19TypeP-f,3/19TypeS-o(P-f)\n\
    MLPworkedbetterthananRForSVM.Noneofthesestudies and 1/19 Type T-f (see Figure\
    \ 4). The only study that made a\nused CNNs or other modern deep learning architectures.\
    \ comparisonor used anymoderndeep learningwasThorpand\nHighsoilsalinityisagrowingproblemworldwide,andthere\
    \ Drajat [109], who found that LSTMs outperformed MLPs at\nisgrowinginterestinmappingthisenvironmentalhazardusing\
    \ classifying growth stage. There were no examples of modern\nsatellite imagery\
    \ [74]. Despite the dire impacts of high soil deep learning for canopy cover or\
    \ LAI prediction.\nsalinity, there were only 4 studies that investigated predicting\
    \ 1) Radiative Transfer models: A radiative transfer model\nsoil salinity from\
    \ satellite imagery using deep learning. Only (RTM) is a method to estimate the\
    \ re\uFB02ectance from physical\noneusedamoderndeeplearningapproach[3],andtheyfound\
    \ properties of the object being imaged. Most of the studies\nthat it performed\
    \ signi\uFB01cantly better than SVM models using used the PROSAIL model [51],\
    \ to model the plants and the10\nLandsat\nType P-f RF,\nSoil\nSVM, or\nColour\
    \ Feature Stack Moisture\nMLP\nFig.4. Themostcommoninputmethodforsoilhealth,plantphysiologyandcropdamagedetection\
    \ istooperateoneachpixelindependently, andtreatthe\npixelasaunorderedcollection\
    \ offeatures (TypeP-f).Thissimplemethodcaneasilybeappliedtoanypixel-level data,butlacksanycontextual\
    \ information\nandisusedintraditional machinelearning methodslike RFandSVM,aswellassimpleMLPs.\n\
    TABLEVIII\nCOUNTSOFSTUDIESONPLANTPHYSIOLOGY.NISTHETOTALNUMBEROFSTUDIES.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHE\n\
    LABELSCOLUMN:FS=FIELDSURVEY,IS=IMAGESURVEY,MB=MODEL-BASED,MBT/FSE=MODEL-BASEDFORTRAINANDFIELDSURVEYFOR\n\
    EVALUATION.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPESINTHESAMESTUDY.\nn VI Labels\
    \ Model Type\ne\nFS MB MBt/FS Govt. Tree SVM MLP CNN RNN P-f T-f S-i ST-c S-o(P-f)\n\
    CanopyCover/LAI 14 3 6 1 7 0 1 1 14 0 0 10 0 0 0 4\nOther 5 4 1 1 1 2 1 1 4 2\
    \ 1 3 1 2 1 0\nsoil beneath them. It takes as input: the chlorophyll content,\
    \ thescaleoftheplants,whentheybecomewide-spreadenough,\nthe water/dry matter content,\
    \ the Leaf Area Index, average they become visible via remote sensing [132].\n\
    leaf inclination, ratio of diffuse to direct incident radiation,\nMost of the\
    \ found studies posed the damage caused by\nsoil brightness, solar zenith angle,\
    \ sensor zenith angle and\ndisease and natural disasters as a classi\uFB01cation/segmentation\n\
    relative azimuth angle; and outputs re\uFB02ectance. Since the\nproblem (8/10).\
    \ In these cases, the models were segmenting\nphysiologicalpropertiesarethe inputto\
    \ the PROSAIL model,\nbetween \"damage\" and \"no damage\". A notable exception\n\
    the processofdeterminingoneofthe physiologicalproperties\nwas Rodriguez et al.\
    \ [92], who used a modi\uFB01ed ResNet-18\n(e.g. LAI) from the re\uFB02ectance\
    \ is called \u201Cmodel inversion\u201D in\n[44] CNN model to detect damage to\
    \ Coconut crops in the\nthese contexts.\nPhilippines by comparing tree density\
    \ estimates before and\nAlmost half of the studies (8/19) collected ground-level\n\
    after Typhoon Goni, making it the only study to measure the\nphysical properties\
    \ and used an RTM in forward mode to\nextent of the damage per unit area.\ngeneratetraining\
    \ pairsof LAI/re\uFB02ectancefor their MLPs, and\nthen tested them on real data.\
    \ However, Tomicek et al. [112]\nThe threshold for considering an area to be infected\
    \ with a\nfound that the PROSAIL RTM predicted re\uFB02ectances only\ndisease\
    \ varied signi\uFB01cantly between studies, with Yuan et al.\ncorrelated with\
    \ Sentinel-2 images between R2 > 0.6 for red,\n[133] requiring 80% of the plants\
    \ to have visible pustules on\ngreenandbluebandsanduptoR2 >0.9forred-edgeandNIR\n\
    thetopofthecanopytobeconsidered\"infected\"withpowdery\nbands, which implies fundamental\
    \ limits on the accuracy of\nmildew, and Ma et al. [69] requiring more than 10%\
    \ of the\nLAI estimation using this method. Despite the acknowledged\nleafs to\
    \ be infected to be considered \"infected\". Obviously a\nerrors, these studies\
    \ treat the PROSAIL model as inherently\nmore extensive spread of a disease makes\
    \ the disease more\ncorrect, and thus no study compared PROSAIL in reverse\nvisible,\
    \ and hence, predictable. For example, Pignatti et al.\nmode to a machine learning\
    \ model on a held-out test set of\n[85] explicitly tested their MLP model at differenttimes\
    \ after\n\uFB01eld survey data.\ninitial infectionand notedsigni\uFB01cantly improvedaccuracyfor\n\
    later predictions.\nD. Crop Damage\nThesestudieswereallstraight-forwardapplicationsofwell-\n\
    There are only10 worksusing deep learningto detect crop knowndeeplearningalgorithms(mostlyMLPsonsingle-pixel\n\
    damage using satellite data (see Table IX, and of these, only data) mostly using\
    \ \uFB01eld survey data. All of the studies used\ntwo used CNNs (Type S-i) [118,\
    \ 92] and one used a GRU medium resolution images between 1.5m and 30m resolution\n\
    (Type T-s) [7]. Although pests and diseases are features on to match the resolution\
    \ of the \uFB01elds in the \uFB01eld surveys.11\nTABLEIX\nCOUNTSOFSTUDIESONCROPDAMAGE.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.INTHELABELSCOLUMN:FS=FIELDSURVEY,IS=\n\
    IMAGESURVEY.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPESINTHESAMESTUDY.\nn VI Labels\
    \ Model Type\nFS IS Tree SVM MLP CNN RNN P-f S-o(P-f) T-f T-s S-i\nDisease 6 5\
    \ 6 0 2 2 6 0 0 3 2 1 1 0\nOther 4 0 3 2 1 0 2 2 1 1 1 0 0 2\nE. Yield tion observed\
    \ (23/41); this is likely because several govern-\nments publicly provide yield\
    \ measurements aggregated at a\nThe task of yield prediction is to predict the\
    \ average yield\ncounty/state level and thus, the data for such work is readily\n\
    per hectare for a parcel of land. Unlike LULC, which can be\naccessible. This\
    \ provides data for a whole country at once,\nidenti\uFB01edbyahumanexpertfromasatelliteimagemoderately\n\
    but is highly aggregated. It is likely that MODIS imagery is\nreliably[73],yieldis\
    \ generallymeasuredat eitherthe county-\npopularfor this task because the relatively\
    \ large pixels makes\nlevel by governmentbodies,or at the \uFB01eld-levelby individual\n\
    aggregation of re\uFB02ectances and VIs a less computationally\nresearchers.Forthepurposesofthisreview,\"\
    county\"refersto\nintensive task than using Landsat. Conversely,\uFB01eld-level\
    \ data\nanything larger than a \uFB01eld (e.g. \u201Cmunicipality\u201D, \u201C\
    province\u201D,\n(7/41) is generally more dif\uFB01cult to obtain as there are\
    \ no\n\u201Cstate\u201D, etc.) due to their varying meaning across different\n\
    public databases to work from. We note that Landsatimagery\npapers/governments.We\
    \ note that almost universally, county-\nis used at a \uFB01eld-level in much\
    \ the same way as MODIS\nlevel yield uses MODIS imagery with yield measurements\n\
    imageryis usedat a county-level(e.g.[135]),and when\uFB01eld-\npublished by governments;\
    \ while \uFB01eld-level yield uses Sen-\nlevel prediction is formulated in the\
    \ same way as county-\ntinel/Landsat imagery and \uFB01eld surveys, where the\
    \ data was\nlevel, the input is the same shape, and a single model can\ncollected\
    \ speci\uFB01cally for the study (see Table X). However,\noperate seamlessly at\
    \ both granularities [14, 110]. However,\nthe modelling is similar in both cases\
    \ for the vast majority\naggregating over pixels removes all spatial information,\
    \ and\nof studies. Since the yield is measured with respect to large\nthus the\
    \ models cannot learn spatial relationships.\nshapes(counties/\uFB01elds)andnotwithrespecttopixels,theinput\n\
    to the modelsis an aggregatedcolour value from the imagery When averaging over\
    \ counties, it is still possible to use\n(or NDVI) across the county/\uFB01eld,\
    \ effectively removing all a 2D CNN, but not over spatial data. Khaki et al. [57]\
    \ and\nspatial information from the data (Type T-o and ST-o; see Qiaoetal. [87]chosetoaggregatethecounty-leveldatausing\n\
    Figure5).Therearemultiplewaysonecouldaggregateacross a histogram, providing a\
    \ much richer understanding of the\na whole county or \uFB01eld, yet several papers\
    \ did not describe informationwithin a countythanjust takingthe average.This\n\
    their method for doing so. The most commonly mentioned creates a 3D block of data\
    \ (bins, time, bands) which can be\nmethod is to take an average, so it is likely\
    \ that the studies used with a 2D CNN (Type ST-o interpreted as Type T-i). In\n\
    that did not specify the aggregation method simply used an these cases, the 2D\
    \ CNNs performed better than traditional\naverage. machinelearningmethods.However,thismethodof\
    \ using2D\nCNNs doesn\u2019t use spatial data - instead convolving over the\n\
    Aggregatingallpixelsofacountybyaveragingnaivelywill\ntemporal and spectral dimensions.\
    \ Engen et al. [26] collated\nincorporatealotofnon-cropinformationfrombodiesofwater,\n\
    several Norwegian government sources to create a dataset of\nresidential areas,\
    \ and other unfarmed land. Since the process\nfarm-level yields and applied novel\
    \ architectures including\nreduces the data for a whole county to just a few numbers\n\
    both a 2D CNN and GRU. They used the \uFB01eld shape \uFB01les\n(one per colour\
    \ band; often just NDVI), it is important to\nto onlyincludethe pixelsforthe \uFB01\
    eld beingpredicted,setting\nensure that the recorded aggregate is as accurate\
    \ as possible.\nthe other pixels to zero. They compared these to aggregating\n\
    FortheUSandChina,therearenation-wideestimatesofcrop\ndataacrossthewhole\uFB01\
    eldandusinganLSTMandfoundthat\ntypes aligned to Landsat imagery (e.g. CDL). Since\
    \ Landsat\ntheir novel 2DCNN/GRU architecture performed better.\nimagery is at\
    \ a signi\uFB01cantly \uFB01ner resolution than MODIS, it\u2019s\npossible to\
    \ calculate an estimated proportion of each crop While averaging over pixels within\
    \ the \uFB01eld/county was\nwithin each MODIS pixel using these crop maps and\
    \ \uFB01lter the most popular method, two works [42, 99] used com-\nthemforeachcountytoonlyselectthepixelsthatrelatetothe\
    \ bine harvesters equipped with yield measuring technology\ncropofinterest.ForexampleLietal.[62]describe\uFB01\
    lteringout to obtain a yield map across a whole \uFB01eld. This provides\nMODISpixelswithlessthan0.1NDVIorlessthan75%ofthe\
    \ yield at a signi\uFB01cantly \uFB01ner resolution than other methods,\narea\
    \ coveredby the cropof interest, as indicatedbythe CDL. and also provides an obvious\
    \ pathway to include a CNN in\nEven when using such a method, there are still\
    \ signi\uFB01cant the solution as the yield measurements can now be aligned\n\
    sources of error in the NDVI aggregation: the pixels still to the uniform pixel\
    \ grid of the imagery. More speci\uFB01cally,\ncontain non-crop information, the\
    \ \uFB01elds may be mislabelled, Haghverdiet al. [42] collected many densely predicted\
    \ yields\nand\uFB01eldsthataredouble-croppedmayormaynotcontainthe along with combine\
    \ harvester locations, and then averaged\ncrop of interest at the time the image\
    \ is taken. these to match Landsat imagery, and Sagan et al. [99] tasked\nCounty-level\
    \ is the most popular scale of yield predic- commercial satellites to take 30cm\
    \ resolution images of their12\nMODIS\n* * * * * Mask\nFig.5. Themostcommoninputmethodforcounty-level\
    \ yieldpredictionistouseobjectboundaries toselectandaggregatepixelsfromspatiotemporal\
    \ data\n(TypeST-o),andreinterpret thisdataasasimplesequenceofcounty-averaged \u201C\
    pixels\u201D(TypeT-s).TogetherthisisdenotedasTypeST-o(T-s).ThisT-sdata\ncanthenbeusedinmodelslike1DCNNsorLSTMs.ManyworksadditionallymasktheimagedatabycroptypeusingtheUSDA\u2019\
    sCDL[116]orequivalent,\nbut other works indiscriminately aggregate over all pixels\
    \ within the county boundary, including pixels from different crop types and some\
    \ non-farmland.\nSomeworksadditionally \uFB02attenthosecounty-averaged \u201C\
    pixels\u201D toacollection offeatures (TypeST-o(T-f))foruseinRF,SVMandMLPmodels.\n\
    TABLEX\nCOUNTSOFSTUDIESONYIELDPREDICTION.VICOUNTSSTUDIESTHATUSEDVEGETATIONINDICES.CLIM.COUNTSSTUDIESTHATUSEDCLIMATE\n\
    VARIABLESINTHELABELSCOLUMN:FS=FIELDSURVEY,ANDGOVT.=GOVERNMENT.NOTETHATSTUDIESMAYUSEMULTIPLEMODELSANDTYPES\n\
    INTHESAMESTUDY.ONLYTYPESUSEDINMORETHANONESTUDYARESHOWN.\nm.\nn VI Cli Labels Model\
    \ Type\nFS Govt. Other Tree SVM MLP CNN RNN P-f T-f ST-c S-o(P-f) ST-o(P-f) ST-o(T-f)\
    \ ST-o(T-s) ST-o(T-i) ST-o(T-c)\nCounty-level 23 21 20 1 22 3 16 6 11 7 12 0 0\
    \ 0 0 1 18 14 2 2\nField-level 7 7 2 6 0 1 3 2 5 1 2 0 0 0 2 3 2 2 0 0\nPlot-level\
    \ 2 1 1 2 0 0 1 1 2 1 0 0 1 1 0 1 0 0 0 0\nPixel-level 2 2 1 2 0 1 0 0 1 1 1 1\
    \ 0 0 0 0 0 0 0 0\nOther 7 5 3 5 1 1 1 1 7 1 1 3 2 1 0 0 0 0 0 1\ncropsduringtheirstudyto\
    \ obtainan extremely\uFB01neresolution also notbe applicable.In contrast,thereweretwo\
    \ studiesthat\ndataset to train on. They were then able to train CNNs on used\
    \ CNNs on spatial data [26, 99], and in both cases the\ndense spatiotemporal data\
    \ (Type ST-c) and compare against CNN models performed better than other methods.\n\
    traditionalML methods(trees, SVMs) and found that 2D and Severalof the county-levelstudies\
    \ have over1000counties\n3D CNNs worked better. Although they only used a single\
    \ recordedforover10years.Thisscaleofdataiseasytoobtain\nsite, each pixel is effectively\
    \ another example, meaning they foraresearcher,asitisallpubliclydownloadable.Incontrast,\n\
    had many thousands of examples to train on. with the exception of Zhang et al.\
    \ [135] (11000 data points),\nthe \uFB01eld-levelstudies used small datasets containingless\
    \ than\nThere were several studies which compared performance\n100datapoints;presumablybecausethedatawassoexpensive\n\
    between models, but even for county-level prediction, which\nto obtain.\nhad the\
    \ most homogeneous approach, there was no model\nwhich always performed the best.\
    \ Unlike for the other tasks Interestingly, Watson-Hernandez et al. [127] was\
    \ the only\n- where modern deep learning methods consistently outper- study found\
    \ that attempted to forecast the yield outside the\nformedtraditionalmethods-foryieldpredictionthereisonlya\
    \ current season.\nslightmajorityofLSTMsperformingbetterthantreemethods 1) Climatic\
    \ and soil variables: Nearly all of the county-\n(6/10).Itisnotclearwhythisisthecase;thedatasetsizeswere\
    \ level studies used climatic variables (e.g. ground temperature\napproximately\
    \ the same for studies where LSTMs performed and precipitation) and soil properties\
    \ (e.g. soil particle size,\nbetter. Each of these studies compared different\
    \ times, places soil moisture content) in addition to the re\uFB02ectances/VIs\n\
    and crops types, so comparing RMSE or R2 values would (22/23), and universally\
    \ noted improved performance when13\ncompared to not using these variables [13,\
    \ 126, 129]. How- and not being widely tracked or collated, which has resulted\n\
    ever, there was no consistency in which soil variables were in relatively small-scale\
    \ studies, and less research interest -\nused, nor how the temperature was encoded\
    \ and no works at least as far as deep learning is concerned. There were\ncomparedtheirclimaticdataencodingtootherencodings.For\
    \ 51 studies identi\uFB01ed across soil health, plant physiology and\nexample,\
    \ the temperature was variously classi\uFB01ed/aggregated crop damage tasks, and\
    \ among these only eight of them used\nintoGrowingDegreeDays,KillingDegreeDaysandFreezing\
    \ moderndeeplearningalgorithmsandmostofthosewereafter\nDegree Days before being\
    \ fed into the model (e.g. [135]). It 2020. Of these eight, only four compared\
    \ the modern deep\nwasalsocommontousevariousdifferenttemperaturestatistics learningalgorithmtoatree/forest,SVMorMLP,butinallfour\n\
    (e.g.min/mean/max)andsomestudiesevencombinedmultiple cases the modern deep learning\
    \ algorithm performed better.\nsources of meteorological data (e.g [54]). This\
    \ makes it The vast majority of modern deep learning methods were\ndif\uFB01cult\
    \ to recommend any climatic and soil properties in for LULC tasks, in which there\
    \ was a very noticeable trend\nparticular. of modern deep learning algorithms\
    \ performing better. In\nThese variables can sometimes be dif\uFB01cult to obtain.\
    \ Me- crop segmentation, modern deep learning algorithms were\nteorological stations\
    \ are not uniformly distributed, and don\u2019t compared with trees, SVMs or MLPs\
    \ in 25 studies, and\nnecessarily cover everywhere in the study area, so when\
    \ performed better in all but one case. However, the Vision\noperating at smaller\
    \ than county-level, Engen et al. [26] Transformer [23] model and variants, which\
    \ have performed\nshowedthatthemeteorologicalinformationcanbeinterpolated very\
    \ well in generic computer vision tasks, did not show any\nbetweenmeteorologicalstationsto\
    \ providebetterestimates of particular improvement over CNNs and RNNs. Transformers\n\
    local climatic variables. have been noted to require much more data than CNNs\
    \ to\nachieve state-of-the-artperformance,and it\u2019s possible that the\ntransformersusedinthereviewedstudieshavenotbeentrained\n\
    VII. DISCUSSION\nwith enough data. So, there is room for further investigation\n\
    Inthis review,we haveobservedthatmoderndeeplearning of this phenomenon, perhaps\
    \ utilising unsupervised or semi-\nmethods have become dramatically more popular\
    \ in the last supervised training methods to bridge the gap in data scale.\nfew\
    \ years. This trend is likely to continue, as the research For as many examples\
    \ of straightforward uses of standard-\nappears to be following generic computer\
    \ vision. However, ised forms of modern deep learning algorithms (e.g. UNet\n\
    generic computer vision research has been partially propelled \uFB01ne-tunedon\
    \ type S-idata [83]), therewere also manyexam-\nby large public benchmarkdatasets,\
    \ which are mostly lacking ples of speci\uFB01c ideas being directly transferred\
    \ and adapted\nin the agricultural tasks identi\uFB01ed in this review, especially\
    \ from generic computer vision to the satellite setting (e.g.\nmonitoring soil\
    \ health, plant physiology and crop damage. discriminator loss [63], neural ordinary\
    \ differential equations\nWithout accessible large datasets, methods are not easily\
    \ [75], channel attention maps [107]). However, there was only\ncomparable and\
    \ deep learning in these areas is constrained to one main variation observed that\
    \ explicitly took advantage of\nthose who have the resources to conduct large\
    \ \uFB01eld surveys. the differences between satellite imagery and ground-based\n\
    Crop segmentation is the only identi\uFB01ed task with bench- imagery: several\
    \ works utilised the higher spectral resolution\nmark datasets (see Table V; Section\
    \ VI-A), and this data is and convolvedover the spectral dimension(typesP-s, T-i\
    \ and\nmostly derived from large public data sources. Even within S-c; e.g. [61,\
    \ 20, 101]). There is a gap here; satellite imagery\ncrop segmentation, there\
    \ are very few examples of compar- is not the same as ground-based images or video.\
    \ There is\nisons on these benchmark datasets. And county-level yield temporal\
    \ continuity at every pixel. There are spatial patterns\nprediction - despite\
    \ also being quite popular, and having at hugely varied scales. There is an order\
    \ of magnitude more\npublic data sources - does not have any benchmark datasets.\
    \ data available, and it is all associated with physicallocations.\nMore accessible\
    \ data makes more research easier and enables All of these properties are not\
    \ being taken advantage of in\nreliable comparisons. For example, the recommendation\
    \ to existing work tackling agricultural tasks, and are interesting\nalwaysuseSentinel-1dataalongwithSentinel-2dataisviable\
    \ directions for future research.\nbecauseallSentineldataisalwaysfreelyavailable,andreliable\n\
    because many studies were able to independently \uFB01nd the ACKNOWLEDGEMENTS\n\
    same conclusion. Public benchmark datasets would provide\nThe fundingfor this\
    \ work comes from the SmartSat Coop-\nan accessible collectionof data for manydifferentresearchers\n\
    erative Research Centre.\nto train deep learning models, which would lead to more\n\
    CertaindataincludedhereinarederivedfromClarivateWeb\nreproducibleresults,andallowresearcherstomoreeasilybuild\n\
    of Science. \xA9 Copyright Clarivate 2022. All rights reserved.\noff of each others\
    \ work. Provided, of course, that researchers\nutilise them.\nCrop segmentation\
    \ and county-level yield prediction are REFERENCES\nthe two tasks with the most\
    \ interest, and the only ones with [1] ABARES. Catchment Scale Land Use of Australia\
    \ -\nexistingcountry-widedatasourceswhichcouldbeutilisedfor Update December 2020.\
    \ Australian Bureau of Agricul-\ncreatingbenchmarkdatasetseasily.Thisislikelybecausecrop\
    \ turalandResourceEconomicsandSciences,Canberra,\nsegmentation is relatively easy\
    \ to label, and monitoring yield 2021. doi: 10.25814/aqjw-rq15.\ncountry-wide\
    \ is already well-established in many countries. [2] John B. Adams, Donald E.\
    \ Sabol, Valerie Kapos,\nThe other tasks suffer from being more dif\uFB01cult\
    \ to measure Raimundo Almeida Filho, Dar A. Roberts, Milton O.14\nSmith, and Alan\
    \ R. Gillespie. Classi\uFB01cation of multi- [13] Yaping Cai, Kaiyu Guan, David\
    \ Lobell, Andries B.\nspectralimagesbasedonfractionsofendmembers:Ap- Potgieter,\
    \ Shaowen Wang, Jian Peng, Tianfang Xu,\nplicationtoland-coverchangeintheBrazilianAmazon.\
    \ SentholdAsseng,YongguangZhang,LiangzhiYou,and\nRemote Sensing of Environment,\
    \ 52(2):137\u2013154, May Bin Peng. Integrating satellite and climate data to\n\
    1995. ISSN 0034-4257. doi: 10.1016/0034-4257(94) predictwheatyieldin Australiausingmachinelearning\n\
    00098-8. approaches. AGRICULTURAL AND FOREST METE-\n[3] SeymaAkcaandOguzGungor.\
    \ Semanticsegmentation OROLOGY, 274:144\u2013159, August 2019. ISSN 0168-\nofsoilsalinityusingin-situECmeasurementsanddeep\
    \ 1923. doi: 10.1016/j.agrformet.2019.03.010.\nlearning based U-NET architecture.\
    \ CATENA, 218, [14] Juan Cao, Zhao Zhang, Yuchuan Luo, Liangliang\nNovember 2022.\
    \ ISSN 0341-8162. doi: 10.1016/j. Zhang,JingZhang,ZiyueLi,andFuluTao.Wheatyield\n\
    catena.2022.106529. predictions at a county and \uFB01eld scale with deep learn-\n\
    [4] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. ing, machine learning, and\
    \ google earth engine. EU-\nHinton. Layer Normalization, July 2016. ROPEAN JOURNAL\
    \ OF AGRONOMY, 123, February\n[5] Paola Benedetti, Dino Ienco, Raffaele Gaetano,\
    \ Kenji 2021.ISSN1161-0301.doi:10.1016/j.eja.2020.126204.\nOse, Ruggero G. Pensa,\
    \ and Stephane Dupuy. [15] Mohamed Chelali, Camille Kurtz, Anne Puissant, and\n\
    M(3)Fusion: A Deep Learning Architecture for Multi- Nicole Vincent. Deep-STaR:\
    \ Classi\uFB01cation of image\nscale Multimodal Multitemporal Satellite Data Fusion.\
    \ time series based on spatio-temporal representations.\nIEEEJOURNALOFSELECTEDTOPICSINAPPLIED\
    \ COMPUTER VISION AND IMAGE UNDERSTAND-\nEARTHOBSERVATIONSANDREMOTESENSING,11\
    \ ING, 208, July 2021. ISSN 1077-3142. doi: 10.1016/j.\n(12):4939\u20134949, December\
    \ 2018. ISSN 1939-1404. cviu.2021.103221.\ndoi: 10.1109/JSTARS.2018.2876357. [16]\
    \ J.M.ChenandT.A.Black. De\uFB01ningleafareaindexfor\n[6] Lucas Beyer, Olivier\
    \ J. H\xE9naff, Alexander Kolesnikov, non-\uFB02at leaves. Plant, Cell & Environment,\
    \ 15(4):421\u2013\nXiaohua Zhai, and A\xE4ron van den Oord. Are we done 429,1992.\
    \ ISSN1365-3040.doi:10.1111/j.1365-3040.\nwith ImageNet? arXiv:2006.07159[cs],\
    \ June 2020. 1992.tb00992.x.\n[7] Luning Bi, Guiping Hu, Muhammad Mohsin Raza,\
    \ [17] Liang-Chieh Chen, George Papandreou, Florian\nYuba Kandel, Leonor Leandro,\
    \ and Daren Mueller. A Schroff, and Hartwig Adam. Rethinking Atrous\nGated Recurrent\
    \ Units (GRU)-Based Model for Early Convolution for Semantic Image Segmentation,\n\
    DetectionofSoybeanSuddenDeathSyndromethrough December 2017.\nTime-Series Satellite\
    \ Imagery. REMOTE SENSING, 12 [18] Yun-Jae Choung and Donghwi Jung. Comparison\
    \ of\n(21), November 2020. doi: 10.3390/rs12213621. Machineand DeepLearningMethodsfor\
    \ MappingSea\n[8] ThomasBlaschke and Josef Strobl. What\u2019s wrong with Farms\
    \ Using High-Resolution Satellite Image. Jour-\npixels? Some recent developments\
    \ interfacing remote nal of Coastal Research, 114(sp1):420\u2013423, October\n\
    sensing and GIS. Zeitschrift f\xFCr Geoinformationssys- 2021. ISSN 0749-0208,\
    \ 1551-5036. doi: 10.2112/\nteme, 14:12\u201317, June 2001. JCR-SI114-085.1.\n\
    [9] Thomas Blaschke, Geoffrey J. Hay, Maggi Kelly, Ste- [19] Rapha\xEBl d\u2019\
    Andrimont, Astrid Verhegghen, Michele\nfan Lang, Peter Hofmann, Elisabeth Addink,\
    \ Raul Meroni, Guido Lemoine, Peter Strobl, Beatrice Eiselt,\nQueiroz Feitosa,\
    \ Freek van der Meer, Harald van der MomchilYordanov,LauraMartinez-Sanchez,and\
    \ Mar-\nWerff, Frieke van Coillie, and Dirk Tiede. Geo- ijn van der Velde. LUCAS\
    \ Copernicus 2018: Earth-\ngraphic Object-Based Image Analysis - Towards a new\
    \ observation-relevantin situ data on land cover and use\nparadigm. ISPRS Journal\
    \ of Photogrammetry and Re- throughout the European Union. Earth System Science\n\
    mote Sensing, 87:180\u2013191, January 2014. ISSN 0924- Data,13(3):1119\u2013\
    1133,March2021. ISSN1866-3508.\n2716. doi: 10.1016/j.isprsjprs.2013.09.014. doi:\
    \ 10.5194/essd-13-1119-2021.\n[10] Monica Bocco, Gustavo Ovando, Silvina Sayago,\
    \ En- [20] MisganuDebella-GiloandArntKristianGjertsen.Map-\nrique Willington,\
    \ and Susana Heredia. Estimating soy- ping Seasonal Agricultural Land Use Types\
    \ Using\nbean ground cover from satellite images using neural- Deep Learning on\
    \ Sentinel-2 Image Time Series. RE-\nnetworks models. INTERNATIONAL JOURNAL OF\
    \ MOTE SENSING, 13(2), January 2021. doi: 10.3390/\nREMOTE SENSING, 33(6):1717\u2013\
    1728, 2012. ISSN rs13020289.\n0143-1161. doi: 10.1080/01431161.2011.600347. [21]\
    \ Jia Deng,WeiDong,RichardSocher,Li-Jia Li, KaiLi,\n[11] ClaireBoryan,ZhengweiYang,RickMueller,andMike\
    \ and Li Fei-Fei. ImageNet: A large-scale hierarchical\nCraig. MonitoringUS agriculture:The\
    \ US Department imagedatabase.In2009IEEEConferenceonComputer\nof Agriculture,\
    \ National AgriculturalStatistics Service, Vision and Pattern Recognition, pages\
    \ 248\u2013255, June\nCroplandData LayerProgram. GeocartoInternational, 2009.\
    \ doi: 10.1109/CVPR.2009.5206848.\n26(5):341\u2013358, August 2011. ISSN 1010-6049.\
    \ doi: [22] Myron C. Dobson, Fawwaz T. Ulaby, Martti T. Hal-\n10.1080/10106049.2011.562309.\
    \ likainen, and Mohamed A. El-rayes. Microwave Di-\n[12] Philip G. Brodrick, Andrew\
    \ B. Davies, and Gregory P. electric Behaviorof Wet Soil-PartII:DielectricMixing\n\
    Asner. Uncovering Ecological Patterns with Convo- Models. IEEETransactionsonGeoscienceandRemote\n\
    lutional Neural Networks. Trends in Ecology and Sensing, GE-23(1):35\u201346,\
    \ January 1985. ISSN 1558-\nEvolution, 2019. doi: 10.1016/j.tree.2019.03.006.\
    \ 0644. doi: 10.1109/TGRS.1985.289498.15\n[23] Alexey Dosovitskiy, Lucas Beyer,\
    \ Alexander Gilliams, Sander M\xFCcher, Robert Tetrault, Inian Moor-\nKolesnikov,\
    \ Dirk Weissenborn, Xiaohua Zhai, Thomas thy,andIanMcCallum.Acomparisonofglobalagricul-\n\
    Unterthiner, Mostafa Dehghani, Matthias Minderer, turalmonitoringsystemsandcurrentgaps.\
    \ Agricultural\nGeorg Heigold, Sylvain Gelly, Jakob Uszkoreit, Systems,168:258\u2013\
    272,January2019.ISSN0308-521X.\nand Neil Houlsby. An Image is Worth 16x16 doi:\
    \ 10.1016/j.agsy.2018.05.010.\nWords: Transformers for Image Recognition at Scale.\
    \ [32] J. W Funck, Y Zhong, D. A Butler, C. C Brunner, and\narXiv:2010.11929[cs],\
    \ June 2021. J. B Forrer. Image segmentation algorithms applied\n[24] M. Drusch,\
    \ U. Del Bello, S. Carlier, O. Colin, V. Fer- to wood defect detection. Computers\
    \ and Electronics\nnandez, F. Gascon, B. Hoersch, C. Isola, P. Laberinti, in Agriculture,\
    \ 41(1):157\u2013179, December 2003. ISSN\nP.Martimort,A.Meygret,F.Spoto,O.Sy,F.Marchese,\
    \ 0168-1699. doi: 10.1016/S0168-1699(03)00049-8.\nand P. Bargellini. Sentinel-2:\
    \ ESA\u2019s Optical High- [33] IgnazioGallo, Riccardo La Grassa, Nicola Landro,and\n\
    Resolution Mission for GMES Operational Services. Mirco Boschetti. Sentinel 2\
    \ Time Series Analysis with\nRemoteSensingofEnvironment,120:25\u201336,May2012.\
    \ 3D Feature Pyramid Network and Time Domain Class\nISSN 0034-4257. doi: 10.1016/j.rse.2011.11.026.\
    \ Activation Intervals for Crop Mapping. ISPRS INTER-\n[25] St\xE9phane Dupuyand\
    \ Raffaele Gaetano. Reunion island NATIONAL JOURNAL OF GEO-INFORMATION, 10\n-\
    \ 2019, Land cover map (Spot6/7) - 1.5m, 2020. (7), July 2021. doi: 10.3390/ijgi10070483.\n\
    [26] Martin Engen, Erik Sand\xF8, Benjamin Lucas Oscar Sj\xF8- [34] Vivien Sainte\
    \ Fare Garnot, Loic Landrieu, Sebastien\nlander, Simon Arenberg, Rashmi Gupta,\
    \ and Morten Giordano, and Nesrine Chehata. Satellite Image Time\nGoodwin. Farm-Scale\
    \ Crop Yield Prediction from SeriesClassi\uFB01cationWithPixel-SetEncodersandTem-\n\
    Multi-Temporal Data Using Deep Hybrid Neural Net- poral Self-Attention. In Proceedings\
    \ of the IEEE/CVF\nworks. Agronomy,11(12):2576,December 2021. ISSN Conference\
    \ on Computer Vision and Pattern Recogni-\n2073-4395. doi: 10.3390/agronomy11122576.\
    \ tion, pages 12325\u201312334,2020.\n[27] Dara Entekhabi, Ignacio Rodriguez-Iturbe,\
    \ and Fabio [35] Vivien Sainte Fare Garnot, Loic Landrieu, and Nes-\nCastelli.\
    \ Mutual interaction of soil moisture state and rine Chehata. Multi-modal temporal\
    \ attention models\natmospheric processes. Journal of Hydrology, 184(1): for crop\
    \ mapping from satellite time series. ISPRS\n3\u201317, October 1996. ISSN 0022-1694.\
    \ doi: 10.1016/ JOURNAL OF PHOTOGRAMMETRY AND REMOTE\n0022-1694(95)02965-6. SENSING,\
    \ 187:294\u2013305, May 2022. ISSN 0924-2716.\n[28] Dara Entekhabi, Eni G. Njoku,\
    \ Peggy E. O\u2019Neill, doi: 10.1016/j.isprsjprs.2022.03.012.\nKent H. Kellogg,\
    \ Wade T. Crow, Wendy N. Edelstein, [36] Robin Gebbers and Viacheslav I. Adamchuk.\
    \ Pre-\nJared K. Entin, Shawn D. Goodman, Thomas J. Jack- cision Agriculture and\
    \ Food Security. Science, 327\nson, Joel Johnson, John Kimball, Jeffrey R. Piepmeier,\
    \ (5967):828\u2013831, February 2010. doi: 10.1126/science.\nRandal D. Koster,\
    \ Neil Martin, Kyle C. McDonald, 1183899.\nMahta Moghaddam, Susan Moran, Rolf\
    \ Reichle, J. C. [37] C. Gomez, M. Mangeas, M. Petit, C. Corbane, P. Ha-\nShi,\
    \ Michael W. Spencer, Samuel W. Thurman, Leung mon, S. Hamon, A. De Kochko, D.\
    \ Le Pierres, V. Pon-\nTsang, and Jakob Van Zyl. The Soil Moisture Active cet,\
    \ and M. Despinoy. Use of high-resolution satellite\nPassive (SMAP) Mission. Proceedings\
    \ of the IEEE, imagery in an integrated model to predict the distri-\n98(5):704\u2013\
    716, May 2010. ISSN 1558-2256. doi: bution of shade coffee tree hybrid zones.\
    \ REMOTE\n10.1109/JPROC.2010.2043918. SENSING OF ENVIRONMENT, 114(11):2731\u2013\
    2744,\n[29] Puyu Feng, Bin Wang, De Li Liu, and Qiang Yu. November 2010. ISSN\
    \ 0034-4257. doi: 10.1016/j.rse.\nMachine learning-based integration of remotely-sensed\
    \ 2010.06.007.\ndrought factors can improve the estimation of agricul- [38] Cristina\
    \ G\xF3mez, Joanne C. White, and Michael A.\ntural drought in South-Eastern Australia.\
    \ AGRICUL- Wulder. Optical remotely sensed time series data for\nTURAL SYSTEMS,\
    \ 173:303\u2013316, July 2019. ISSN land cover classi\uFB01cation: A review. ISPRS\
    \ Journal of\n0308-521X. doi: 10.1016/j.agsy.2019.03.015. PhotogrammetryandRemote\
    \ Sensing,116:55\u201372,June\n[30] Matheus Pinheiro Ferreira, Rodolfo Georjute\
    \ Lotte, 2016. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2016.\nFrancisco D\u2019\
    Elia, V, Christos Stamatopoulos, Do- 03.008.\nHyungKim,andAdamR.Benjamin.Accuratemapping\
    \ [39] Ian Goodfellow, Yoshua Bengio, and Aaron Courville.\nof Brazil nut trees\
    \ (Bertholletia excelsa) in Amazo- Deep Learning. MIT Press, 2016.\nnian forests\
    \ using WorldView-3 satellite images and [40] T. W. Grif\uFB01n and J. Lowenberg-DeBoer.\
    \ Worldwide\nconvolutional neural networks. ECOLOGICAL IN- adoption and pro\uFB01\
    tability of precision agriculture Im-\nFORMATICS, 63, July 2021. ISSN 1574-9541.\
    \ doi: plications for Brazil. Revista de Pol\xEDtica Agr\xEDcola, 14\n10.1016/j.ecoinf.2021.101302.\
    \ (4):20\u201337, 2005. ISSN 2317-224X.\n[31] Steffen Fritz, Linda See, Juan Carlos\
    \ Laso Bayas, [41] Vahid Habibi, Hasan Ahmadi, Mohammad Jafari, and\nFran\xE7\
    ois Waldner, Damien Jacques, Inbal Becker- Abolfazl Moeini. Quantitative assessment\
    \ of soil salin-\nReshef, Alyssa Whitcraft, Bettina Baruth, Rogerio ity using\
    \ remote sensing data based on the arti\uFB01cial\nBonifacio, Jim Crutch\uFB01\
    eld, Felix Rembold, Oscar Ro- neural network, case study: Sharif Abad Plain, Central\n\
    jas, Anne Schucknecht, Marijn Van der Velde, James Iran. MODELING EARTH SYSTEMS\
    \ AND ENVIRON-\nVerdin, Bingfang Wu, Nana Yan, Liangzhi You, Sven MENT, 7(2):1373\u2013\
    1383, June 2021. ISSN 2363-6203.16\ndoi: 10.1007/s40808-020-01015-1. tion characterization.\
    \ Remote Sensing of Environment,\n[42] Amir Haghverdi, Robert A. Washington-Allen,\
    \ and 113:S56\u2013S66, September 2009. ISSN 0034-4257. doi:\nBrian G. Leib. Prediction\
    \ of cotton lint yield from 10.1016/j.rse.2008.01.026.\nphenology of crop indices\
    \ using arti\uFB01cial neural net- [52] ShunpingJi,ChiZhang,AnjianXu,YunShi,andYulin\n\
    works. COMPUTERS AND ELECTRONICS IN AGRI- Duan. 3D Convolutional Neural Networks\
    \ for Crop\nCULTURE,152:186\u2013197,September2018.ISSN0168- Classi\uFB01cationwithMulti-TemporalRemoteSensingIm-\n\
    1699. doi: 10.1016/j.compag.2018.07.021. ages. REMOTE SENSING, 10(1), January\
    \ 2018. doi:\n[43] A. M. Hamer, D. M. Simms, and T. W. Waine. Re- 10.3390/rs10010075.\n\
    placing human interpretation of agricultural land in [53] YuJin,JiaweiGuo,HuichunYe,JinlingZhao,Wenjiang\n\
    Afghanistan with a deep convolutionalneural network. Huang, and Bei Cui. Extraction\
    \ of Arecanut Planting\nINTERNATIONAL JOURNAL OF REMOTE SENSING, Distribution\
    \ Based on the Feature Space Optimization\n42(8):3017\u20133038, April 2021. ISSN\
    \ 0143-1161. doi: of PlanetScope Imagery. AGRICULTURE-BASEL, 11\n10.1080/01431161.2020.1864059.\
    \ (4), April 2021. doi: 10.3390/agriculture11040371.\n[44] Kaiming He, Xiangyu\
    \ Zhang, Shaoqing Ren, and Jian [54] Sungha Ju, Hyoungjoon Lim, Jong Won Ma, Soohyun\n\
    Sun. IdentityMappingsin DeepResidualNetworks. In Kim, Kyungdo Lee, Shuhe Zhao,\
    \ and Joon Heo. Op-\nBastianLeibe,JiriMatas,NicuSebe,andMaxWelling, timal county-levelcrop\
    \ yield prediction using MODIS-\neditors, Computer Vision - ECCV 2016, Lecture\
    \ Notes based variables and weather data: A comparative\nin Computer Science,\
    \ pages 630\u2013645, Cham, 2016. study on machine learning models. AGRICUL-\n\
    Springer International Publishing. ISBN 978-3-319- TURALANDFORESTMETEOROLOGY,307,Septem-\n\
    46493-0. doi: 10.1007/978-3-319-46493-0\\_38. ber 2021. ISSN 0168-1923. doi: 10.1016/j.agrformet.\n\
    [45] M. Herold, J. S. Latham, A. Di Gregorio, and C. C. 2021.108530.\nSchmullius.\
    \ Evolving standards in land cover char- [55] Teja Kattenborn, Jens Leitloff,\
    \ Felix Schiefer, and Ste-\nacterization. Journal of Land Use Science, 1(2-4):\
    \ fan Hinz. Review on Convolutional Neural Networks\n157\u2013168, December 2006.\
    \ ISSN 1747-423X. doi: (CNN) in vegetation remote sensing. ISPRS Journal\n10.1080/17474230601079316.\
    \ of Photogrammetry and Remote Sensing, 173:24\u201349,\n[46] GeoffreyE.Hinton,NitishSrivastava,AlexKrizhevsky,\
    \ March2021. ISSN 0924-2716. doi:10.1016/j.isprsjprs.\nIlyaSutskever,andRuslanR.Salakhutdinov.Improving\
    \ 2020.12.010.\nneural networks by preventing co-adaptation of feature [56] Yann\
    \ H. Kerr,Philippe Waldteufel, Philippe Richaume,\ndetectors, July 2012. JeanPierreWigneron,PaoloFerrazzoli,AliMahmoodi,\n\
    [47] Mitchell C. Hunter, Richard G. Smith, Meagan E. Ahmad Al Bitar, Fran\xE7\
    ois Cabot, Claire Gruhier, Sil-\nSchipanski, Lesley W. Atwood, and David A. via\
    \ Enache Juglea, Delphine Leroux, Arnaud Mialon,\nMortensen. Agriculture in 2050:\
    \ Recalibrating Targets andStevenDelwart. TheSMOSSoilMoistureRetrieval\nfor Sustainable\
    \ Intensi\uFB01cation. BioScience, 67(4):386\u2013 Algorithm. IEEE Transactions\
    \ on Geoscience and\n391,April2017. ISSN0006-3568. doi:10.1093/biosci/ Remote\
    \ Sensing, 50(5):1384\u20131403, May 2012. ISSN\nbix010. 1558-0644. doi: 10.1109/TGRS.2012.2184548.\n\
    [48] Jordi Inglada, Marcela Arias, Benjamin Tardy, Olivier [57] Saeed Khaki, Hieu\
    \ Pham, and Lizhi Wang. Simulta-\nHagolle, Silvia Valero, David Morin, G\xE9rard\
    \ Dedieu, neous corn and soybean yield prediction from remote\nGuadalupe Sepulcre,\
    \ Sophie Bontemps, Pierre De- sensing data using deep transferlearning. SCIENTIFIC\n\
    fourny, and Benjamin Koetz. Assessment of an Op- REPORTS, 11(1), May 2021. ISSN\
    \ 2045-2322. doi:\nerational System for Crop Type Map Production Using 10.1038/s41598-021-89779-z.\n\
    High Temporaland Spatial Resolution Satellite Optical [58] Reza Khatami, Giorgos\
    \ Mountrakis, and Stephen V.\nImagery. Remote Sensing, 7(9):12356\u201312379,Septem-\
    \ Stehman. A meta-analysis of remote sensing research\nber 2015. ISSN 2072-4292.\
    \ doi: 10.3390/rs70912356. on supervised pixel-based land-cover image classi\uFB01\
    ca-\n[49] RobertoInterdonato,DinoIenco,RaffaeleGaetano,and tion processes: General\
    \ guidelinesfor practitionersand\nKenji Ose. DuPLO: A DUal view Point deep Learn-\
    \ future research. Remote Sensing of Environment, 177:\ning architecture for time\
    \ series classi\uFB01catiOn. ISPRS 89\u2013100, May 2016. ISSN 0034-4257. doi:\
    \ 10.1016/j.\nJOURNAL OF PHOTOGRAMMETRY AND REMOTE rse.2016.02.028.\nSENSING,\
    \ 149:91\u2013104,March 2019. ISSN 0924-2716. [59] Oz Kira, Anthony L. Nguy-Robertson,\
    \ Timothy J.\ndoi: 10.1016/j.isprsjprs.2019.01.011. Arkebauer, Raphael Linker,\
    \ and Anatoly A. Gitelson.\n[50] Sergey Ioffe and Christian Szegedy. Batch Normaliza-\
    \ Toward Generic Models for Green LAI Estimation in\ntion:AcceleratingDeepNetworkTrainingbyReducing\
    \ Maize and Soybean: Satellite Observations. REMOTE\nInternal Covariate Shift.\
    \ In Proceedings of the 32nd SENSING, 9(4), April 2017. ISSN 2072-4292. doi:\n\
    International Conference on Machine Learning, pages 10.3390/rs9040318.\n448\u2013\
    456. PMLR, June 2015. [60] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-\n\
    [51] St\xE9phane Jacquemoud, Wout Verhoef, Fr\xE9d\xE9ric Baret, ton. ImageNet\
    \ Classi\uFB01cation with Deep Convolutional\nC\xE9dric Bacour, Pablo J. Zarco-Tejada,\
    \ Gregory P. Neural Networks. In Advances in Neural Information\nAsner, Christophe\
    \ Fran\xE7ois, and Susan L. Ustin. ProcessingSystems,volume25,pages1106\u2013\
    1114.Cur-\nPROSPECT+SAILmodels:Areviewofuseforvegeta- ran Associates, Inc., 2012.17\n\
    [61] Nataliia Kussul, MykolaLavreniuk,SergiiSkakun,and earscirev.2021.103858.\n\
    AndriiShelestov. DeepLearningClassi\uFB01cationofLand [71] R. B. MacDonald and\
    \ F. G. Hall. Global Crop Fore-\nCover and Crop Types Using Remote Sensing Data.\
    \ casting. Science, 208(4445):670\u2013679, May 1980. doi:\nIEEE GEOSCIENCE AND\
    \ REMOTE SENSING LET- 10.1126/science.208.4445.670.\nTERS, 14(5):778\u2013782,\
    \ May 2017. ISSN 1545-598X. [72] Khairiya Mudrik Masoud, Claudio Persello, and\
    \ Va-\ndoi: 10.1109/LGRS.2017.2681128. lentyn A. Tolpekin. Delineation of Agricultural\
    \ Field\n[62] Ainong Li, Shunlin Liang, Angsheng Wang, and Jun Boundaries from\
    \ Sentinel-2 Images Using a Novel\nQin. Estimatingcropyieldfrommulti-temporalsatellite\
    \ Super-Resolution Contour Detector Based on Fully\ndata using multivariate regression\
    \ and neural network Convolutional Networks. REMOTE SENSING, 12(1),\ntechniques.\
    \ PHOTOGRAMMETRIC ENGINEERING January 2020. doi: 10.3390/rs12010059.\nAND REMOTE\
    \ SENSING, 73(10):1149\u20131157,October [73] Heather McNairn, Catherine Champagne,\
    \ Jiali Shang,\n2007. ISSN 0099-1112. doi: 10.14358/PERS.73.10. Delmar Holmstrom,\
    \ and Gordon Reichert. Integration\n1149. ofopticalandSyntheticApertureRadar(SAR)imagery\n\
    [63] Jingtao Li, Yonglin Shen, and Chao Yang. An Adver- for delivering operational\
    \ annual crop inventories. IS-\nsarial Generative Network for Crop Classi\uFB01\
    cation from PRS Journal of Photogrammetry and Remote Sensing,\nRemote Sensing\
    \ Timeseries Images. REMOTE SENS- 64(5):434\u2013449,September2009. ISSN0924-2716.doi:\n\
    ING, 13(1), January 2021. doi: 10.3390/rs13010065. 10.1016/j.isprsjprs.2008.07.006.\n\
    [64] Min Li, Zhijie Zhang, Liping Lei, Xiaofan Wang, and [74] G.IMetternichtandJ.AZinck.\
    \ Remotesensingofsoil\nXudong Guo. Agricultural Greenhouses Detection in salinity:\
    \ Potentials and constraints. Remote Sensing of\nHigh-Resolution Satellite Images\
    \ Based on Convolu- Environment,85(1):1\u201320,April2003. ISSN0034-4257.\ntionalNeuralNetworks:Comparisonof\
    \ Faster R-CNN, doi: 10.1016/S0034-4257(02)00188-8.\nYOLO v3 and SSD. SENSORS,\
    \ 20(17), September [75] Nando Metzger, Mehmet Ozgur Turkoglu, Stefano\n2020.\
    \ doi: 10.3390/s20174938. D\u2019Aronco, Jan Dirk Wegner, and Konrad Schindler.\n\
    [65] Weijia Li, Runmin Dong, Haohuan Fu, and Le Yu. Crop Classi\uFB01cation Under\
    \ Varying Cloud Cover With\nLarge-Scale Oil Palm Tree Detection from High- Neural\
    \ Ordinary Differential Equations. IEEE Trans-\nResolution Satellite Images Using\
    \ Two-Stage Convo- actions on Geoscience and Remote Sensing, 60:1\u201312,\nlutional\
    \ Neural Networks. REMOTE SENSING, 11(1), 2022. ISSN 1558-0644. doi: 10.1109/TGRS.2021.\n\
    January 2019. doi: 10.3390/rs11010011. 3101965.\n[66] Chenxi Lin, Zhenong Jin,\
    \ David Mulla, Rahul Ghosh, [76] Monica Y. Moreno-Revelo, Lorena Guachi-Guachi,\n\
    Kaiyu Guan, Vipin Kumar, and Yaping Cai. To- Juan Bernardo Gomez-Mendoza, Javier\
    \ Revelo-\nward Large-Scale Mapping of Tree Crops with High- Fuelagan, and Diego\
    \ H. Peluffo-Ordonez. Enhanced\nResolution Satellite Imagery and Deep Learning\
    \ Al- Convolutional-Neural-Network Architecture for Crop\ngorithms: A Case Study\
    \ of Olive Orchards in Mo- Classi\uFB01cation. APPLIED SCIENCES-BASEL, 11(9),\n\
    rocco. REMOTE SENSING, 13(9), May 2021. doi: May 2021. doi: 10.3390/app11094292.\n\
    10.3390/rs13091740. [77] Aicha Moumni and Abderrahman Lahrouni. Machine\n[67]\
    \ D. Lu and Q. Weng. A survey of image classi\uFB01cation Learning-Based Classi\uFB01\
    cation for Crop-Type Mapping\nmethods and techniques for improving classi\uFB01\
    cation Using the Fusion of High-Resolution Satellite Imagery\nperformance. InternationalJournalof\
    \ Remote Sensing, in a Semiarid Area. SCIENTIFICA, 2021, April 2021.\n28(5):823\u2013\
    870, March 2007. ISSN 0143-1161. doi: ISSN 2090-908X. doi: 10.1155/2021/8810279.\n\
    10.1080/01431160600746456. [78] EmileNdikumana,DinhHoTongMinh,NicolasBagh-\n[68]\
    \ Tingting Lu, Martin Brandt, Xiaoye Tong, Pierre Hi- dadi, Dominique Courault,\
    \ and Laure Hossard. Deep\nernaux, Louise Leroux, Babacar Ndao, and Rasmus Recurrent\
    \ Neural Network for Agricultural Classi\uFB01ca-\nFensholt. Mapping the Abundance\
    \ of Multipurpose tionusingmultitemporalSARSentinel-1forCamargue,\nAgroforestry\
    \ Faidherbia albida Trees in Senegal. RE- France. REMOTE SENSING, 10(8), August\
    \ 2018. doi:\nMOTE SENSING, 14(3), February 2022. doi: 10.3390/ 10.3390/rs10081217.\n\
    rs14030662. [79] David C. Nielsen, Juan J. Miceli-Garcia, and Drew J.\n[69] Huiqin\
    \ Ma, Wenjiang Huang, Yuanshu Jing, Chenghai Lyon.CanopyCoverandLeafAreaIndexRelationships\n\
    Yang, Liangxiu Han, Yingying Dong, Huichun Ye, for Wheat, Triticale, andCorn.\
    \ AgronomyJournal,104\nYue Shi, Qiong Zheng, Linyi Liu, and Chao Ruan. (6):1569\u2013\
    1573, 2012. ISSN 1435-0645. doi: 10.2134/\nIntegrating Growth and Environmental\
    \ Parameters to agronj2012.0107n.\nDiscriminate Powdery Mildew and Aphid of Winter\
    \ [80] E.G. Njoku, T.J. Jackson, V. Lakshmi, T.K. Chan, and\nWheat Using Bi-Temporal\
    \ Landsat-8 Imagery. RE- S.V. Nghiem. Soil moisture retrieval from AMSR-E.\nMOTE\
    \ SENSING, 11(7), April 2019. doi: 10.3390/ IEEETransactionsonGeoscienceandRemoteSensing,\n\
    rs11070846. 41(2):215\u2013229, February 2003. ISSN 1558-0644. doi:\n[70] Zhengjing\
    \ Ma and Gang Mei. Deep learning for 10.1109/TGRS.2002.808243.\ngeologicalhazardsanalysis:Data,models,applications,\
    \ [81] Stella Ofori-Ampofo, Charlotte Pelletier, and Stefan\nand opportunities.\
    \ Earth-ScienceReviews, 223:103858, Lang. Crop Type Mapping from Optical and Radar\n\
    December 2021. ISSN 00128252. doi: 10.1016/j. Time Series Using Attention-Based\
    \ Deep Learning.18\nRemote Sensing, 13(22):4668, January 2021. ISSN poral satellite\
    \ data processing: Classi\uFB01cation of paddy\n2072-4292. doi: 10.3390/rs13224668.\
    \ transplanted\uFB01elds. ECOLOGICALINFORMATICS,61,\n[82] Subir Paul, Mamta Kumari,\
    \ C. S. Murthy, and March 2021. ISSN 1574-9541. doi: 10.1016/j.ecoinf.\nD. Nagesh\
    \ Kumar. Generating pre-harvest crop maps 2021.101214.\nby applying convolutional\
    \ neural network on multi- [92] Andres C. Rodriguez, Rodrigo Caye Daudt, Stefano\n\
    temporalSentinel-1data. INTERNATIONALJOURNAL D\u2019Aronco, Konrad Schindler,\
    \ and Jan D. Wegner. Ro-\nOF REMOTE SENSING, February 2022. ISSN 0143- bust Damage\
    \ Estimation of Typhoon Goni on Coconut\n1161. doi: 10.1080/01431161.2022.2030072.\
    \ Crops with Sentinel-2 Imagery. REMOTE SENSING,\n[83] Oscar D. Pedrayes, Dario\
    \ G. Lema, Daniel F. Garcia, 13(21), November 2021. doi: 10.3390/rs13214302.\n\
    Ruben Usamentiaga, and Angela Alonso. Evaluation [93] Olaf Ronneberger, Philipp\
    \ Fischer, and Thomas Brox.\nof Semantic Segmentation Methods for Land Use with\
    \ U-Net: Convolutional Networks for Biomedical Image\nSpectralImagingUsingSentinel-2andPNOAImagery.\
    \ Segmentation. In Nassir Navab, Joachim Hornegger,\nREMOTE SENSING, 13(12), June\
    \ 2021. doi: 10.3390/ William M. Wells, and Alejandro F. Frangi, editors,\nrs13122292.\
    \ Medical Image Computing and Computer-Assisted In-\n[84] C. Persello, V. A. Tolpekin,\
    \ J. R. Bergado, and R. A. tervention - MICCAI 2015, Lecture Notes in Computer\n\
    de By. Delineation of agricultural\uFB01elds in smallholder Science, pages 234\u2013\
    241, Cham, 2015. Springer Inter-\nfarms from satellite images using fully convolutional\
    \ national Publishing. ISBN 978-3-319-24574-4. doi:\nnetworksandcombinatorialgrouping.\
    \ REMOTESENS- 10.1007/978-3-319-24574-4\\_28.\nING OF ENVIRONMENT, 231,September2019.\
    \ ISSN [94] J.Roughgarden,S.W.Running,andP.A.Matson.What\n0034-4257. doi: 10.1016/j.rse.2019.111253.\
    \ Does Remote Sensing Do For Ecology? Ecology, 72\n[85] Stefano Pignatti, Raffaele\
    \ Casa, Giovanni Laneve, (6):1918\u20131922, 1991. ISSN 1939-9170. doi: 10.2307/\n\
    Zhenhai Li, Linyi Liu, Pablo Marzialetti, Nada Mzid, 1941546.\nSimone Pascucci,\
    \ Paolo Cosmo Silvestro, Massimo [95] D. P. Roy, M. A. Wulder, T. R. Loveland,\
    \ Woodcock\nTolomio, Deepak Upreti, Hao Yang, Guijun Yang, and C.e., R. G. Allen,\
    \ M. C. Anderson, D. Helder, J. R.\nWenjiang Huang. Sino-EU Earth Observation\
    \ Data to Irons, D. M. Johnson, R. Kennedy, T. A. Scambos,\nSupport the Monitoring\
    \ and Management of Agricul- C. B. Schaaf, J. R. Schott, Y. Sheng, E. F. Vermote,\n\
    tural Resources. REMOTE SENSING, 13(15), August A. S. Belward, R. Bindschadler,\
    \ W. B. Cohen, F. Gao,\n2021. doi: 10.3390/rs13152889. J. D. Hipple, P. Hostert,\
    \ J. Huntington, C. O. Justice,\n[86] GuanghuiQi,GengxingZhao,andXueXi.SoilSalinity\
    \ A. Kilic, V. Kovalskyy, Z. P. Lee, L. Lymburner, J. G.\nInversion of Winter\
    \ Wheat Areas Based on Satellite- Masek,J.McCorkel,Y.Shuai,R.Trezza,J.Vogelmann,\n\
    Unmanned Aerial Vehicle-Ground Collaborative Sys- R. H. Wynne, and Z. Zhu. Landsat-8:\
    \ Science and\ntem in Coastal of the Yellow River Delta. SENSORS, product vision\
    \ for terrestrial global change research.\n20(22), November 2020. doi: 10.3390/s20226521.\
    \ Remote Sensing of Environment, 145:154\u2013172, April\n[87] MengjiaQiao,XiaohuiHe,XijieCheng,PanleLi,Hao-\
    \ 2014. ISSN0034-4257.doi:10.1016/j.rse.2014.02.001.\ntian Luo, Zhihui Tian, and\
    \ Hengliang Guo. Exploiting [96] Marc Ru\xDFwurm and Marco Koerner. Self-attention\
    \ for\nHierarchical Features for Crop Yield Prediction Based raw optical Satellite\
    \ Time Series Classi\uFB01cation. ISPRS\non3-DConvolutionalNeuralNetworksandMultikernel\
    \ JOURNAL OF PHOTOGRAMMETRY AND REMOTE\nGaussian Process. IEEE JOURNAL OF SELECTED\
    \ SENSING, 169:421\u2013435,November 2020. ISSN 0924-\nTOPICS IN APPLIED EARTH\
    \ OBSERVATIONS AND 2716. doi: 10.1016/j.isprsjprs.2020.06.006.\nREMOTE SENSING,14:4476\u2013\
    4489,2021. ISSN 1939- [97] Marc Ru\xDFwurm and Marco K\xF6rner. Multi-Temporal\n\
    1404. doi: 10.1109/JSTARS.2021.3073149. Land Cover Classi\uFB01cation with Sequential\
    \ Recurrent\n[88] Saman Rabiei, Ehsan Jalilvand, and Massoud Tajr- Encoders. ISPRS\
    \ International Journal of Geo-\nishy. A Method to Estimate Surface Soil Moisture\
    \ and Information, 7(4):129, April 2018. ISSN 2220-9964.\nMap the Irrigated Cropland\
    \ Area Using Sentinel-1 and doi: 10.3390/ijgi7040129.\nSentinel-2 Data. Sustainability,\
    \ 13(20):11355, January [98] Marc Ru\xDFwurm, Charlotte Pelletier, Maximilian\
    \ Zoll-\n2021. ISSN 2071-1050. doi: 10.3390/su132011355. ner,S\xE9bastienLef\xE8\
    vre,andMarcoK\xF6rner.BreizhCrops:\n[89] Fatemeh Rahimi-Ajdadi and Mahdi Khani.\
    \ Remote A time series dataset for crop type mapping. In-\nsensing-based detection\
    \ of tea land losses: The case of ternational Archives of the Photogrammetry,\
    \ Re-\nLahijan, Iran. REMOTE SENSING APPLICATIONS- mote Sensing and Spatial Information\
    \ Sciences IS-\nSOCIETY AND ENVIRONMENT, 23, August 2021. PRS (2020), pages 1545\u2013\
    1551, 2020. doi: 10.5194/\nISSN 2352-9385. doi: 10.1016/j.rsase.2021.100568. isprs-archives-XLIII-B2-2020-1545-2020.\n\
    [90] Muhammad Moshiur Rahman, Andrew Robson, and [99] VasitSagan,MaitiniyaziMaimaitijiang,SouravBhadra,\n\
    Mila Bristow. Exploring the Potential of High Res- Matthew Maimaitiyiming, Davis\
    \ R. Brown, Pahed-\nolution WorldView-3 Imagery for Estimating Yield of ing Sidike,\
    \ and Felix B. Fritschi. Field-scale crop\nMango. REMOTE SENSING, 10(12), December\
    \ 2018. yieldpredictionusingmulti-temporalWorldView-3and\ndoi: 10.3390/rs10121866.\
    \ PlanetScope satellite data and deep learning. ISPRS\n[91] Anuvi Rawat, Anil\
    \ Kumar, Priyadarshi Upadhyay, and JOURNAL OF PHOTOGRAMMETRY AND REMOTE\nShashi\
    \ Kumar. Deep learning-based models for tem- SENSING, 174:265\u2013281,April2021.\
    \ ISSN 0924-2716.19\ndoi: 10.1016/j.isprsjprs.2021.02.008. JOURNALOFAPPLIEDEARTHOBSERVATIONAND\n\
    [100] Ieda Del\u2019Arco Sanches, Raul Queiroz Feitosa, Pe- GEOINFORMATION, 102,\
    \ October 2021. ISSN 1569-\ndro Marco Achanccaray Diaz, Marinalva Dias Soares,\
    \ 8432. doi: 10.1016/j.jag.2021.102375.\nAlfredo Jose Barreto Luiz, Bruno Schultz,\
    \ and Luis [111] M. C. Tirado, R. Clarke, L. A. Jaykus, A. McQuatters-\nEduardo\
    \ Pinheiro Maurano. Campo Verde Database, Gollop, and J. M. Frank. Climate change\
    \ and food\nOctober 2017. safety: A review. Food Research International, 43(7):\n\
    [101] EkremSaraliogluandOguzGungor. Semanticsegmen- 1745\u20131765, August 2010.\
    \ ISSN 0963-9969. doi: 10.\ntation of land cover from high resolution multispec-\
    \ 1016/j.foodres.2010.07.003.\ntral satellite images by spectral-spatial convolutional\
    \ [112] Jiri Tomicek, Jan Misurec, and Petr Lukes. Proto-\nneural network. GEOCARTO\
    \ INTERNATIONAL, 37 typing a Generic Algorithm for Crop Parameter Re-\n(2):657\u2013\
    677, January 2022. ISSN 1010-6049. doi: trieval across the Season Using Radiative\
    \ Transfer\n10.1080/10106049.2020.1734871. Model Inversion and Sentinel-2 Satellite\
    \ Observations.\n[102] SERCO. Copernicus Sentinel Data Access Annual Re- REMOTE\
    \ SENSING, 13(18), September 2021. doi:\nport2021. https://sentinels.copernicus.eu/web/sentinel/-\
    \ 10.3390/rs13183659.\n/copernicus-sentinel-data-access-annual-report- [113] Ramon\
    \ Torres, Paul Snoeij, Dirk Geudtner, David\n2021/1.2, 2021. Bibby, Malcolm Davidson,\
    \ Evert Attema, Pierre\n[103] Andrii Shelestov, Mykola Lavreniuk, Nataliia Kussul,\
    \ Potin, Bj\xF6rn Rommen, Nicolas Floury, Mike Brown,\nAlexei Novikov, and Sergii\
    \ Skakun. Exploring Google Ignacio Navas Traver, Patrick Deghaye, Berthyl\nEarth\
    \ Engine Platform for Big Data Processing: Clas- Duesmann, Betlem Rosich, Nuno\
    \ Miranda, Claudio\nsi\uFB01cation of Multi-TemporalSatellite Imageryfor Crop\
    \ Bruno, Michelangelo L\u2019Abbate, Renato Croci, Andrea\nMapping. FRONTIERS\
    \ IN EARTH SCIENCE, 5:1\u201310, Pietropaolo, Markus Huchler, and Friedhelm Rostan.\n\
    February 2017. doi: 10.3389/feart.2017.00017. GMES Sentinel-1 mission. Remote\
    \ Sensing of Envi-\n[104] Karen Simonyan and Andrew Zisserman. Very Deep ronment,\
    \ 120:9\u201324, May 2012. ISSN 0034-4257. doi:\nConvolutionalNetworks for Large-Scale\
    \ Image Recog- 10.1016/j.rse.2011.05.028.\nnition, April 2015. [114] Mehmet Ozgur\
    \ Turkoglu, Stefano D\u2019Aronco, Gre-\n[105] Ying-Qiang Song, Xin Zhao, Hui-Yue\
    \ Su, Bo Li, Yue- gor Perich, Frank Liebisch, Constantin Streit, Konrad\nMing\
    \ Hu, and Xue-Sen Cui. Predicting Spatial Vari- Schindler, and Jan Dirk Wegner.\
    \ Crop mapping from\nations in Soil Nutrients with Hyperspectral Remote image\
    \ time series: Deep learningwith multi-scale label\nSensingatRegionalScale. SENSORS,18(9),September\
    \ hierarchies. REMOTE SENSING OF ENVIRONMENT,\n2018. doi: 10.3390/s18093086. 264,\
    \ October 2021. ISSN 0034-4257. doi: 10.1016/j.\n[106] Dimitrios Sykas, Maria\
    \ Sdraka, Dimitrios Zografakis, rse.2021.112603.\nand Ioannis Papoutsis. A sentinel-2\
    \ multiyear, multi- [115] UnitedNations.WorldPopulationProspectsHighlights,\n\
    country benchmark dataset for crop classi\uFB01cation and 2019 Revision Highlights.\
    \ 2019. ISBN 978-92-1-\nsegmentation with deep learning. IEEE JOURNAL OF 148316-1.\n\
    SELECTED TOPICS IN APPLIED EARTH OBSERVA- [116] USDA. National Agricultural Statistics\n\
    TIONSANDREMOTESENSING,15:3323\u20133339,2022. Service Cropland Data Layer. Published\
    \ crop-\nISSN 1939-1404. doi:10.1109/JSTARS.2022.3164771. speci\uFB01c data layer\
    \ [Online]. Available at:\n[107] Pengfei Tang, Peijun Du, Junshi Xia, Peng Zhang,\
    \ https://nassgeodata.gmu.edu/CropScape/. USDA-\nand Wei Zhang. Channel Attention-Based\
    \ Temporal NASS, Washington, DC, 2022.\nConvolutionalNetwork for Satellite Image\
    \ Time Series [117] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nClassi\uFB01\
    cation. IEEE Geoscience and Remote Sens- Uszkoreit,LlionJones,AidanNGomez,LukaszKaiser,\n\
    ing Letters, 19:1\u20135, 2022. ISSN 1558-0571. doi: and Illia Polosukhin. Attention\
    \ is All you Need. In\n10.1109/LGRS.2021.3095505. Advances in Neural Information\
    \ Processing Systems,\n[108] Nima Teimouri, Mads Dyrmann, and Rasmus Nyholm volume\
    \ 30, pages 5998\u20136008. Curran Associates, Inc.,\nJorgensen. A Novel Spatio-TemporalFCN-LSTM\
    \ Net- 2017.\nworkforRecognizingVariousCropTypesUsingMulti- [118] Shyamal S. Virnodkar,\
    \ Vinod K. Pachghare, Virupak-\nTemporal Radar Images. REMOTE SENSING, 11(8),\
    \ shagouda C. Patil, and Sunil Kumar Jha. DenseRe-\nApril 2019. doi: 10.3390/rs11080990.\
    \ sUNet: An Architecture to Assess Water-Stressed\n[109] K. R. Thorp and D. Drajat.\
    \ Deep machine learning Sugarcane Crops from Sentinel-2 Satellite Imagery.\nwithSentinelsatellitedatatomappaddyriceproduction\
    \ TRAITEMENT DU SIGNAL, 38(4):1131\u20131139,August\nstagesacrossWestJava,Indonesia.REMOTESENSING\
    \ 2021. ISSN 0765-0019. doi: 10.18280/ts.380424.\nOF ENVIRONMENT, 265, November\
    \ 2021. ISSN [119] Wolfgang Wagner, Sebastian Hahn, Richard Kidd,\n0034-4257.\
    \ doi: 10.1016/j.rse.2021.112679. ThomasMelzer,ZoltanBartalis,StefanHasenauer,Julia\n\
    [110] Huiren Tian, Pengxin Wang, Kevin Tansey, Dong Han, Figa-Salda\xF1a, Patricia\
    \ de Rosnay, Alexander Jann, Ste-\nJingqi Zhang, Shuyu Zhang, and Hongmei Li.\
    \ A fan Schneider, J\xFCrgen Komma, Gerhard Kubu, Katha-\ndeeplearningframeworkunderattentionmechanismfor\
    \ rina Brugger, Christoph Aubrecht, Johann Z\xFCger, Ute\nwheat yield estimation\
    \ using remotely sensed indices Gangkofner, Stefan Kienberger, Luca Brocca, Yong\n\
    in the Guanzhong Plain, PR China. INTERNATIONAL Wang, G\xFCnter Bl\xF6schl, Josef\
    \ Eitzinger, and Kla Stein-20\nnocher. The ASCAT Soil Moisture Product: A Review\
    \ [129] Aleksandra Wolanin, Gonzalo Mateo-Garcia, Gustau\nof its Speci\uFB01cations,\
    \ Validation Results, and Emerging Camps-Valls, Luis Gomez-Chova, Michele Meroni,\n\
    Applications. Meteorologische Zeitschrift, pages 5\u201333, GregoryDuveiller,YouLiangzhi,andLuisGuanter.Es-\n\
    February 2013. ISSN ,. doi: 10.1127/0941-2948/2013/ timatingandunderstandingcropyieldswithexplainable\n\
    0399. deep learning in the Indian Wheat Belt. ENVIRON-\n[120] Fran\xE7ois Waldner\
    \ and Foivos I. Diakogiannis. Deep MENTALRESEARCHLETTERS,15(2),February2020.\n\
    learning on edge: Extracting \uFB01eld boundaries from ISSN 1748-9326. doi: 10.1088/1748-9326/ab68ac.\n\
    satellite images with a convolutional neural network. [130] Qiong Wu, Yunxiang\
    \ Jin, Yuhai Bao, Quansheng\nRemote Sensing of Environment, 2019. doi: 10.1016/j.\
    \ Hai, Ruirui Yan, Baorui Chen, Hongbin Zhang, Bao-\nrse.2020.111741. hui Zhang,\
    \ Zhenwang Li, Xiaoyu Li, and Xiaoping\n[121] Francois Waldner, Foivos I. Diakogiannis,\
    \ Kathryn Xin. Comparison of two inversion methods for leaf\nBatchelor, Michael\
    \ Ciccotosto-Camp, Elizabeth area index using HJ-1 satellite data in a temperate\n\
    Cooper-Williams, Chris Herrmann, Gonzalo Mata, meadow steppe. INTERNATIONAL JOURNAL\
    \ OF\nand Andrew Toovey. Detect, Consolidate, Delineate: REMOTESENSING,36(19-20,SI):5192\u2013\
    5207,October\nScalable Mapping of Field Boundaries Using Satellite 2015. ISSN\
    \ 0143-1161. doi: 10.1080/01431161.2015.\nImages. REMOTE SENSING, 13(11), June\
    \ 2021. doi: 1040135.\n10.3390/rs13112197. [131] Jinfan Xu, Yue Zhu, Renhai Zhong,\
    \ Zhixian Lin, Jialu\n[122] Li Wang, Yong Zhou, Jingyi Liu, Yujie Liu, Qian Zuo,\
    \ Xu, Hao Jiang, Jingfeng Huang, Haifeng Li, and Tao\nand Qing Li. Exploring the\
    \ potential of multispectral Lin. DeepCropMapping: A multi-temporal deep learn-\n\
    satellite imagesforestimatingthe contentsofcadmium ing approach with improved\
    \ spatial generalizability\nand lead in cropland: The effect of the dimidiate\
    \ pixel for dynamic corn and soybean mapping. REMOTE\nmodel and random forest.\
    \ JOURNAL OF CLEANER SENSING OF ENVIRONMENT, 247, September 2020.\nPRODUCTION,\
    \ 367, September 2022. ISSN 0959- ISSN 0034-4257. doi: 10.1016/j.rse.2020.111946.\n\
    6526. doi: 10.1016/j.jclepro.2022.132922. [132] Sijing Ye, Shuhan Lu, Xuesong\
    \ Bai, and Jinfeng Gu.\n[123] Sherrie Wang, William Chen, Sang Michael Xie, ResNet-Locust-BN\
    \ Network-Based Automatic Identi-\nSangMichaelXie,GeorgeAzzari,andDavidB.Lobell.\
    \ \uFB01cation of East Asian Migratory Locust Species and\nWeakly SupervisedDeep\
    \ Learningfor Segmentationof Instars from RGB Images. INSECTS, 11(8), August\n\
    Remote Sensing Imagery. Remote Sensing, 2020. doi: 2020. doi: 10.3390/insects11080458.\n\
    10.3390/rs12020207. [133] Lin Yuan, Jingcheng Zhang, Yeyin Shi, Chenwei Nie,\n\
    [124] Sherrie Wang, Stefania Di Tommaso, Joey Faulkner, Liguang Wei, and Jihua\
    \ Wang. Damage Mapping\nThomas Friedel, Alexander Kennepohl, Rob Strey, and of\
    \ Powdery Mildew in Winter Wheat with High-\nDavid B. Lobell. Mapping Crop Types\
    \ in Southeast Resolution Satellite Image. REMOTE SENSING, 6(5):\nIndiawithSmartphoneCrowdsourcingandDeepLearn-\
    \ 3611\u20133623, May 2014. doi: 10.3390/rs6053611.\ning. REMOTESENSING,12(18),September2020.\
    \ doi: [134] Bo Zhang, Bin Guo, Bin Zou, Wei Wei, Yongzhi Lei,\n10.3390/rs12182957.\
    \ and Tianqi Li. Retrieving soil heavy metals concentra-\n[125] Xiaoping Wang,\
    \ Fei Zhang, Jianli Ding, Hsiang-te tions based on GaoFen-5 hyperspectral satellite\
    \ image\nKung, Aamir Latif, and Verner C. Johnson. Estimation at an opencast coal\
    \ mine, Inner Mongolia, China. EN-\nof soil salt content (SSC) in the Ebinur Lake\
    \ Wetland VIRONMENTAL POLLUTION, 300, May 2022. ISSN\nNationalNatureReserve(ELWNNR),NorthwestChina,\
    \ 0269-7491. doi: 10.1016/j.envpol.2022.118981.\nbased on a Bootstrap-BP neural\
    \ network model and [135] Liangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan\noptimal\
    \ spectral indices. SCIENCE OF THE TOTAL Cao, Ruizhi Xie, and Shaokun Li. Integratingsatellite-\n\
    ENVIRONMENT, 615:918\u2013930, February 2018. ISSN derivedclimaticandvegetationindicestopredictsmall-\n\
    0048-9697. doi: 10.1016/j.scitotenv.2017.10.025. holder maize yield using deep\
    \ learning. AGRICUL-\n[126] YumiaoWang, ZhouZhang,LuweiFeng, QingyunDu, TURALAND\
    \ FORESTMETEOROLOGY, 311,Decem-\nand Troy Runge. Combining Multi-Source Data and\
    \ ber 2021. ISSN 0168-1923. doi: 10.1016/j.agrformet.\nMachineLearningApproachestoPredictWinterWheat\
    \ 2021.108666.\nYield in the Conterminous United States. REMOTE [136] Ya\u2019\
    nan Zhou, Jiancheng Luo, Li Feng, Yingpin Yang,\nSENSING,12(8),April2020. doi:10.3390/rs12081232.\
    \ YuehongChen,andWeiWu. Long-short-term-memory-\n[127] FernandoWatson-Hernandez,NataliaGomez-Calderon,\
    \ based crop classi\uFB01cation using high-resolution optical\nandRouversonPereiradaSilva.\
    \ Oilpalmyieldestima- images and multi-temporal SAR data. GISCIENCE\ntionbasedonvegetationandhumidityindicesgenerated\
    \ & REMOTE SENSING, 56(8):1170\u20131191, November\nfrom satellite images and\
    \ machine learning techniques. 2019. ISSN 1548-1603. doi: 10.1080/15481603.2019.\n\
    AGRIENGINEERING, 4(1):279\u2013291,March 2022. doi: 1628412.\n10.3390/agriengineering4010019.\
    \ [137] Zhe Zhu, Michael A. Wulder, David P. Roy, Curtis E.\n[128] M. Weiss, F.\
    \ Jacob, and G. Duveiller. Remote sensing Woodcock, Matthew C. Hansen, Volker\
    \ C. Radeloff,\nfor agricultural applications: A meta-review. Remote Sean P. Healey,\
    \ Crystal Schaaf, Patrick Hostert, Pe-\nSensing of Environment, 236:111402, January\
    \ 2020. ter Strobl, Jean-Francois Pekel, Leo Lymburner, Nima\nISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2019.111402. Pahlevan, and Ted A. Scambos. Bene\uFB01ts of\
    \ the free21\nand open Landsat data policy. Remote Sensing of\nEnvironment, 224:382\u2013\
    385, April 2019. ISSN 0034-\n4257. doi: 10.1016/j.rse.2019.02.016.1 Supplementary\n\
    1.1 Search terms\nThe full list of crop names searchedfor: Wheat, Corn, Maize,\
    \ Orchard,Co\uFB00ee, Vineyard, Soy, Rice, Cotton, Sorghum,\nPeanut*, Tobacco,\
    \ Barley, Grain, Rye, Oat, Millet, Speltz, Canola, Flaxseed, Mustard, Alfalfa,\
    \ Camelina, Beans,\nPotato*,Sugar*,Vegetable*,Fruit,Onion*,Cucumber*,Peas,Lentils,Tomato*,Hops,Herbs,Peach*,Apple*,Grape*,\n\
    Citrus, Pecan*, Almond*, Walnut*, Pear*, Aquaculture, Perrenial, Pistachio*, Triticale,\
    \ Carrot*, Asparagus, Garlic,\nCantaloupes,Prune*,Orange*,Olive*,Broccoli,Avocado*,Pepper*,Pomegranate*,Nectarine*,Plum*,Squash,Apri-\n\
    cot*, Vetch, Lettuce, Pumpkin, Cabbage, Celery, Radish*, Turnip*, Eggplant*, Gourd*\n\
    1.2 Dataset links\nTable 1: Identi\uFB01ed crop segmentation satellite benchmark\
    \ datasets and data sources,along with links to download the\ndataset.\nName Link\n\
    3 LUCAS [d\u2019Andrimont et al., 2021] https://data.jrc.ec.europa.eu/dataset/cfe66a0c-bdee-4074-96e1-a2f7030b9515\n\
    2 Munich dataset https://github.com/MarcCoru/MTLCC\n0\n[Ru\xDFwurm and K\xA8orner,\
    \ 2018]\n2\nBreizhCrops [Ru\xDFwurm et al., 2020] https://github.com/dl4sits/BreizhCrops\n\
    \ \nc ZueriCrop [Turkoglu et al., 2021] https://polybox.ethz.ch/index.php/s/uXfdr2AcXE3QNB6\n\
    e\nReunionIsland[Dupuyand Gaetano, https://dataverse.cirad.fr/dataset.xhtml?persistentId=doi:10.18167/DVN1/YZJQ7Q\n\
    D\n2020]\n5  Campo Verde[Sanches et al., 2017] https://ieee-dataport.org/documents/campo-verde-database\n\
    1 UOS2[Pedrayes et al., 2021] https://zenodo.org/record/4648002\n  PASTIS-R[Garnot\
    \ et al., 2022] https://zenodo.org/record/5735646\n \n] Sen4AgriNet [Sykaset al.,\
    \ 2022] https://github.com/Orion-AI-Lab/S4A\nV\nFrench Land Parcel Identi\uFB01\
    cation https://www.data.gouv.fr/fr/datasets/registre-parcellaire-graphique-rpg-contours-des-\n\
    C\nSystem parcelles-et-ilots-culturaux-et-leur-groupe-de-cultures-majoritaire/\n\
    . Cropland Data LayerUSDA[2022] https://nassgeodata.gmu.edu/CropScape/\ns\nc Corine\
    \ Land Cover https://land.copernicus.eu/pan-european/corine-land-cover\n[ CLUM\
    \ https://www.awe.gov.au/abares/aclump/catchment-scale-land-use-of-australia-\n\
    \ \n  update-december-2020\n2\nv\n2\nEach dataset from the LULC section can be\
    \ downloaded from the links in Table 1.\n7\n2\n1 1.3 Tagged database\n0\n. All\
    \ references for this review are made available as a Zotero rdf \uFB01le. It includes\
    \ notes and tags on all studies.\n0\n1\n2\n2\n:\nv\ni\nX\nr\na\n11.4 All Crop\
    \ Segmentation studies\nHere, we list all of the crop segmentation studies.\n\
    Studies on crop segmentation (up to 2020). N is the number of classes that the\
    \ study distinguished between\n(number of agricultural classes in brackets). VI\
    \ stands for vegetative indices, and indicates whether VIs were used\n(possibly\
    \ in combination with other features). GSD = Ground Spatial Distance/resolution.\
    \ In the labels column, a \u2020\nindicates that the labels are from a dataset\
    \ (see Table 1). The best performing model type in each study is\nunderlined.\
    \ Where no model is underlined, no one model performed best. Where two model types\
    \ are underlined, it\nmeans the model had components of both types. In the Tree\
    \ column: RF = Random Forest, and a tick means any\nother kind of tree. In the\
    \ CNN column: nD = nDCNN, including non-spatial CNNs. In the RNN column: L =\n\
    LSTM, G = GRU, and nD = nD ConvRNN (ConvGRU or ConvLSTM). In the Attn column:\
    \ T = Transformer,P =\nPSE-TAE Garnot et al. [2020] and a tick indicates any other\
    \ transformer-like attention.\nModel\ne M P N N n\nStudy N Images VI GSD Labels\
    \ Tre SV ML CN RN Att Type\nBan [2003] 8 (8) ERS-1, 30m Field Survey X ST-o\n\
    Landsat (T-f)\nKarkee et al. [2009] 2 (1) MODIS X 1km Model-based X P-f\nPena\
    \ et al. [2014] 9 (9) ASTER X 15m Priv. govt. X X X S-o\n(P-f)\nKumar et al. [2015]\
    \ 13 (7) LISS IV 5.8m Field Survey X X P-f\nLoew et al. [2015] 10 (7) RapidEye\
    \ X 6.5m Field Survey RF X X ?-f\nX\nKussul et al. [2017] 11 (7) Sentinel-1, 30m\
    \ Field Survey RF X 1D P-f\nLandsat-8 2D P-s\nST-i\nShelestov et al. 13 (8) Landsat-8\
    \ 30m Field Survey RF X X S-o\n[2017] (P-f)\nBenedettiet al. 13 (4) Sentinel-2,\
    \ X 20m, Reunion RF 2D G ST-f\n[2018] SPOT6/7 2m Island\u2020 ST-c\nJi et al.\
    \ [2018] 9 (4) GaoFen-1/2 X 15m, Image Survey X 2D S-i\n4m 3D ST-c\nKussul et\
    \ al. [2018] 13 (8) Sentinel-1, 10m, Field Survey X P-f\nLandsat-8 30m\nNdikumanaet\
    \ al. 11 (8) Sentinel-1 20m Image Survey RF X L ST-o\n[2018] G (T-f\nT-s)\nInterdonatoet\
    \ al. 13 (4) Sentinel-1/2 X 10m Reunion RF 2D L T-f\n[2019] Island\u2020, G T-s\n\
    Koumia\u2020 2D ST-c\nSidike et al. [2019] 19 WV-3 0.3m Field Survey RF X 1D P-f\n\
    (11) P-s\nTeimouri et al. 16 Sentinel-1 10m Model-based 2D 2D ST-c\n[2019] (13)\n\
    Xie et al. [2019] 15 GaoFen-1 2m Image Survey RF 2D S-i\n(12)\nZhao et al. [2019]\
    \ 5 (5) Sentinel-1 10m Field Survey RF 1D L T-f\nG T-s\nZhou et al. [2019] 7 (7)\
    \ Sentinel-1 10m, Image Survey RF X L ST-o\n5.1m (T-f\nT-s)\nMazzia et al. [2020]\
    \ 3 (3) Sentinel-2 X 10m LUCAS RF X 2D L T-f\nX T-i\nNguyenet al. 2 (1) Sentinel-2,\
    \ 30m, Field Survey 2D L ST-c\n[2020] Landsat-8 10m\nRu\xDFwurm and Koerner 23\
    \ Sentinel-2 10m Pub. govt. RF 1D L T ST-o\n[2020] (18) 2D G (T-f\nT-s)\nWanget\
    \ al. [2020a] 10 Sentinel-1/2 X 10m Field Survey RF 1D T-f\n(10) 3D T-s\nST-c\n\
    Xu et al. [2020] 3 (2) Landsat-8 30m CDL RF X L T T-f\nT-s\n2Studies on crop segmentation\
    \ (year 2021).\nModel\ne M P N N n\nStudy N Images VI GSD Labels Tre SV ML CN\
    \ RN Att Type\nChelali et al. 4 (4) Sentinel-2 10m Pub. govt. 1D L ST-o\n[2021]\
    \ 2D 2D (ST-i)\nChoung and Jung 3(2) KOMPSAT- 0.7m Image Survey X X S-i\n[2021]\
    \ 3\nDebella-Gilo and Gjer3ts(e1n) Sentinel-2 20m Pub. govt. X 1D T-f T-s\n[2021]\
    \ 2D T-i\nFernandez-Sellers et al.111 Sentinel-2 10m Pub. govt. X T-f\n[2021]\
    \ (?)\nFu et al. [2021] 4 (2) GaoFen-1 16m Field/Image 2D S-i\nSurvey\nGallo et\
    \ al. [2021] 17 Sentinel-2 X 10m Munich 3D ST-c\n(17)\nHamer et al. 2 (1) DMC\
    \ 32m Image Survey, RF 2D P-f\n[2021] Model-based S-i\nJin et al. [2021] 2(1)\
    \ PlanetScope X 3m Field Survey RF X X P-f\nLaban et al. 8 (6) Sentinel-2 10m\
    \ Field Survey 2D P-f (S-i)\n[2021]\nLei et al. [2021] 2(2) Zhuhai-1, 10m Field/Image\
    \ 2D S-i\nSentinel- Survey\n1/2\nLi et al. [2021] 3 (2) Landsat-8 30m CDL X 2D\
    \ L ST-c\nLozano-Tello et al. 2(1) Sentinel-2 10m Priv. govt. X P-f\n[2021]\n\
    Martini et al. 9 (7) Sentinel-2 10m BreizhCrops\u2020 T ST-o\n[2021] (T-s)\nMeng\
    \ et al. [2021] 6(2) Zhuhai-1, X 10m Field/Image 1D P-s\nSentinel-2 Survey 2D\
    \ S-i\n3D S-c\nMoreno-Revelo et al. 11 Sentinel-1, 30m Campo Verde\u2020 2D L\
    \ S-iS-s\n[2021] (6) Landsat-8\nMoumni and Lahroun6i (4) Sentinel- X 10m Field/Image\
    \ RF X X T-f\n[2021] 1/2 Survey\nMukharamovaet al. 12 MODIS X 250m Pub. govt.\
    \ RF X L T-s\n[2021] (8)\nOfori-Ampofo et al. 12 Sentinel- 10m Pub. govt. P ST-c\n\
    [2021] (8) 1/2\nPedrayes et al. 11 Sentinel-2 10m UOS2\u2020 RF X 2D P-f\n[2021]\
    \ (4) S-i\nQuinton and Landrieu 20 Sentinel-2 10m Pub. govt. P ST-c\n[2021] (18)\n\
    Rahimi-Ajdadiand K4ha(n2i) Landsat- 30m Field/Image X P-f\n[2021] 5/7/8 Survey,\n\
    Model-based\nRawat et al. 5(4) Sentinel-2, 10m Field Survey 1D 1D T-s\n[2021]\
    \ Landsat-8\nThorp and Drajat 6 (3) Sentinel- X 10m Priv. govt. RF X X 2D L P-f\
    \ S-i\n[2021] 1/2 G T-s ST-c\n2D\nTurkoglu et al. 48 Sentinel-2 10m ZueriCrop\u2020\
    \ RF 2D L T ?-f S-i\n[2021] (41) 2D T-s ST-c\nWu et al. [2021] 2 (1) Sentinel-1\
    \ 10m Model-based 2D S-i\nXie and Huang 2(1) MODIS X 250m Image Survey RF 1D L\
    \ T-f\n[2021] T-s\nZhang et al. 3 (2) Sentinel-2, X 10m, Pub. govt., X T-f\n[2021a]\
    \ Landsat-8 30m Field Survey\nZhao et al. [2021] 7(6) Sentinel-2 10m Field/Image\
    \ 1D L T-s\nSurvey G\n1D\n3Studies on crop segmentation (year 2022).\nModel\n\
    e M P N N n\nStudy N Images VI GSD Labels Tre SV ML CN RN Att Type\nAsminget al.\
    \ 9 (2) Landsat-8, 30m, Image Survey X P-f\n[2022] Sentinel-2 10m\nDesloires et\
    \ al. 2 (1) Sentinel-2 10m Pub. govt. G T-s\n[2022]\nFontanelli et al. 10 (9)\
    \ COSMO- 15m Field Survey 1D T-s\n[2022] SkyMed 3D ST-c\nGarnot et al. 30 Sentinel-1/2\
    \ 10m Pub. govt. 2D P ST-c\n[2022] (27) ST-o\n(T-s)\nJiang et al. 10 (3) Sentinel-2\
    \ 10m CDL RF X X P-f\n[2022] X\nLei et al. [2022] 2 (1) SPOT, X 6m, Pub. govt.\
    \ X X ST-f\nSentinel-1 10m\nLi et al. [2022a] 3 (2) RadarSat-2 X 8m Field Survey\
    \ 1D P-f\nLi et al. [2022c] 15 (3) Jilin-1, 1m, Image Survey 2D X S-i\nGaoFen-2\
    \ 4m\nMetzger et al. 48 Sentinel-2 10m ZeuriCrops\u2020 L T ST-s\n[2022] (41)\
    \ G\nNyborget al. 11 Sentinel-2 X 10m Pub. govt. P ST-o\n[2022] (10) (T-s)\nPaul\
    \ et al. [2022] 6 (5) Sentinel-1 10m Field Survey X X 2D ?-f\nST-i\nPavlovic et\
    \ al. 10 (2) Sentinel-2 10m Image Survey 2D S-i\n[2022]\nRauf et al. [2022] 3\
    \ (2) Sentinel-2 X 10m Field Survey, 2D T-i\nModel-based\nRawat et al. 2 (1) Sentinel-2\
    \ X 10m Field Survey 1D T-s\n[2022]\nSaralioglu and Gungor7 (2) [Commercial] 0.5m\
    \ Image Survey RF X 2D P-f\n[2022] 3D S-i\nS-c\nSharma [2022] 101 Sentinel-2 X\
    \ 10m Pub. govt. 1D T-s\n(4)\nSykaset al. 11 Sentinel-2 X 10m Dataset: 1D 2D T\
    \ ST-c\n[2022] (11) Sen4AgriNet 2D L ST-o\n(T-s)\nTang et al. 13 (8) Sentinel-2\
    \ 10m Breizhcrops\u2020 RF 1D L X T-f\n[2022] T-s\nST-c\nTeimouri et al. 7 (7)\
    \ Sentinel-1/2 10m Pub. govt. X X 2D P-f\n[2022] 3D S-i\nST-c\nWanget al. 4 (3)\
    \ Sentinel-2 10m Pub. govt. 2D T S-i\n[2022a]\nWanget al. 10 (5) Sentinel-2 X\
    \ 10m Field Survey 2D S-i\n[2022c]\nWanget al. 5 (5) MODIS X 1km Model-based RF\
    \ X 1D L T-f\n[2022d] T-s\nYanget al. 4 (3) Sentinel-2 10m Model-based 1D T-s\n\
    [2022] 3D ST-c\n4Studies on speci\uFB01c land cover tasks other than segmentation.\
    \ The best performing model in each study is\nunderlined.\nModel\ne\ne M P N N\
    \ n p\nStudy Task/N Images VI GSD Labels Tre SV ML CN RN Att Ty\nField Boundary\
    \ Detection\nPersello et al. - WV-2/3 0.3m Image Survey 2D S-i\n[2019]\nWaldnerand\
    \ Diakogiannis - Sentinel-2 10m Image Survey 2D S-i\n[2019]\nMasoud et al. - Sentinel-2\
    \ 10m Pub. govt. 2D S-i\n[2020]\nWaldneret al. - Sentinel-2 10m Image Survey 2D\
    \ X S-i\n[2021]\nJong et al. [2022] - MODIS, 10m Pub. govt., 2D S-i\nLandsat,\
    \ Image Survey\nSentinel\nLong et al. - GF-1/2 4m Image Survey 2D S-i\n[2022]\n\
    Shari\uFB01 et al. - Sentinel-2 10m Image Survey 2D S-i\n[2022]\nMei et al. [2022]\
    \ - WV-3 0.5m Image Survey 2D S-i\nDam Detection\nCarvajal et al. - Quickbird\
    \ 1m ??? X P-f\n[2016]\nMalerba et al. - [Maps] - Image Survey 2D S-i\n[2021]\n\
    Ma et al. [2022] - GF1, GF2 15m, Image Survey 2D S-i\n4m\nMalerba et al. - [Maps]\
    \ - Image Survey 2D S-i\n[2022]\nCenter Pivot Irrigation Detection\nZhanget al.\
    \ Classify Landsat-8 30m Image Survey 2D S-i\n[2018]\ndeAlbuquerqueet al.Segment\
    \ Landsat-8 30m Pub. govt. 2D S-i\n[2020]\nSaraiva et al. Segment PlanetScope\
    \ 3m Image Survey 2D S-i\n[2020]\nLi et al. [2022b] Classify Landsat 30m Image\
    \ Survey 2D S-i\nIrrigation Detection\nColligan et al. Segment Landsat 30m Field/Image\
    \ 2D S-i\n[2022] Survey\nGreenhouse Detection\nLi et al. [2020] Detection GF1,\
    \ GF2 2m, Image Survey 2D S-i\n1m\nZhanget al. Segment GF2 0.8m Image Survey 2D\
    \ S-i\n[2021c] Boundary\nHedgerow Detection\nAhlswedeet al. Segment IKONOS 1m\
    \ Field/Image 2D S-i\n[2021] Survey\nTree Crown Delineation\nGomez et al. Segment\
    \ QuickBird 0.6m ??? X P-f\n[2010]\nLi et al. [2019] Classify QuickBird 0.6m Image\
    \ Survey 2D S-i\nFerreira et al. Segment WV-3 0.3m Field/Image 2D S-i\n[2021]\
    \ Survey\nLin et al. [2021] Classify WV-3, 0.3m, Image Survey 2D L S-i\nPlanetScope\
    \ 3m\nAbozeid et al. Segment Satellites.pro ? Image Survey T S-i\n[2022]\nLu et\
    \ al. [2022] Segment Sentinel X 10m Field Survey X P-f\n51.5 All Soil Monitoring\
    \ studies\nStudies on soil health; mostly soil moisture and soil salinity studies.\
    \ VI stands for vegetative indices, and indicates\nwhether VIs were used (possibly\
    \ in combination with other features). GSD = Ground Spatial Distance/resolution.\n\
    The best performing model type in each study is underlined. In the Tree column:\
    \ RF = Random Forest, and a tick\nmeans any other kind of tree. In the CNN column:\
    \ 2D = 2DCNN.\nModel\ne M P N N\nStudy Task Images VI GSD Labels Tre SV ML CN\
    \ RN Type\nSoil Moisture\nDel Frateet al. SM ERS-2 30m Model-based X P-f\n[2004]\
    \ (train), Field\nsurvey (eval)\nSantiet al. SM ASAR 30m Model-based X P-f\n[2013]\
    \ (train), Field\nsurvey (eval)\nBaghdadi et al. SM RADARSAT- 12m, Field Survey\
    \ X S-o\n[2016] 2, Landsat-7/8 30m (P-\nf)\nKolassa et al. SM [Many] 3km, Model-based\
    \ X P-f\n[2018] 16km, (train), Field\n36km survey (eval)\nvan derSchalie et al.Agreement\
    \ AMSR-E, 25km, Self-labelled X P-f\n[2018] MIRAS, 35km,\nASCAT 25km\nEroglu et\
    \ al. SM CYGNSS X 9km Government X P-f\n[2019]\nKumaret al. SM Sentinel-1 20m\
    \ Field Survey RF X X P-f\n[2019]\nZhanget al. SM Landsat, X 30m, Model-based\
    \ X P-f\n[2020b] Terra-SAR 3m (train), Field\nsurvey (eval)\nRabiei et al. SM\
    \ Sentinel-1, 10m Field Survey X 2D P-f\n[2021] Sentinel-2 S-i\nSenanayakeet al.\
    \ SM MODIS X 1km Field Survey X X P-f\n[2021]\nGhasemloo et al. SM Landsat, X\
    \ 30m, Field Survey X P-f\n[2022] Sentinel-1 10m\nTripathi et al. SM, Sentinel-1/2\
    \ X 10m Field Survey RF X X P-f\n[2022] salinity, X\netc.\nXu et al. [2022] SM\
    \ SMAP, X 36km, Model-based X P-f\nMODIS 1km (train),\nGovernment (eval)\nZeynoddin\
    \ and BonaSkMdari SMAP 36km Self-labelled L T-s\n[2022]\nSoil Nutrients/Minerals\n\
    Gautam et al. Nitrate Landsat 30m Field Survey X S-o\n[2011] (P-\nf)\nSong et\
    \ al. [2018] Nitrogen HJ-1 100m Field Survey RF X X ?-f\nZhanget al. Potassium\
    \ Landsat 30m Field Survey X P-f\n[2020a]\nPeng et al.[2022] Fertility Sentinel-2\
    \ X 10m Field Survey X X P-f\nWanget al. Pb, Cd Sentinel-2 X 10m Field Survey\
    \ RF X P-f\n[2022b]\nZhanget al. Zn, Ni, GaoFen-5 30m Field Survey RF X X P-f\n\
    [2022] Cu\nSoil Salinity\nWanget al. Regress Landsat, HJ-1 X 30m, Field Survey\
    \ X P-f\n[2018] 100m\nQi et al. [2020] Regress Sentinel-2 X 10m Field Survey/\
    \ RF X X P-f\nModel-based\nHabibiet al. Regress Landsat 30m Field Survey X P-f\n\
    [2021]\nAkcaand Gungor Classify RapidEye X 6.5m Field Survey X 2D S-i\n[2022]\n\
    61.6 All Plant Physiology studies\nStudies on plant physiology; mostly canopy\
    \ cover/LAI estimates. VI stands for vegetative indices, and indicates\nwhether\
    \ VIs were used (possibly in combination with other features). GSD = Ground Spatial\
    \ Distance/resolution.\nThe best performing model type in each study is underlined.\
    \ LAI = Leaf Area Index, LCC = Leaf Chlorophyl\nContent, LWC = Leaf Water Content,\
    \ GPP = Gross Primary Production, SIF = Solar-Induced Fluorescence. In the\nRNN\
    \ column: L = LSTM, G = GRU, and 2D = 2D ConvRNN (ConvGRU or ConvLSTM).\nModel\n\
    e M P N N\nStudy Task Images VI GSD Labels Tre SV ML CN RN Type\nCanopy Cover/LAI\n\
    Del Frateet al. Regress LAI ERS-2 30m Model-based X P-f\n[2004] (train), Field\n\
    survey(eval)\nGascon et al. Regress LAI POLDER 60m Model-based X P-f\n[2007] (train),\
    \ Field\nsurvey(eval)\nBsaibes et al. Regress LAI FORMOSAT- 8m Field Survey X\
    \ S-o\n[2009] 2 (P-\nf)\nRichteret al. Regress LAI CASI 10m Model-based X P-f\n\
    [2009] (train), Field\nsurvey(eval)\nVergeret al. Regress LAI PROBA-1 34m Model-based\
    \ X P-f\n[2011] / Canopy (train), Field\nCover survey(eval)\nBocco et al. Regress\
    \ MODIS, X 500m, Field Survey X S-o\n[2012] Canopy Landsat 30m (P-\nCover f)\n\
    Wuet al. Regress LAI HJ-1 X 30m Field Survey X P-f\n[2015]\nBaghdadi et al. Regress\
    \ LAI RADARSAT- 12m, Field Survey X S-o\n[2016] 2, 30m (P-\nLandsat-7/8 f)\nKira\
    \ et al. Regress LAI MODIS, 500m, Field Survey X X S-o\n[2017] Landsat, 30m, (P-\n\
    MERIS 250m f)\nDelloye et al. Regress LAI Sentinel-2 10m Model-based X P-f\n[2018]\
    \ (train), Field\nsurvey(eval)\nSunet al. Regress LAI MODIS 500m Model-based X\
    \ P-f\n[2021] (train), Field\nsurvey(eval)\nTomicek et al. Regress LAI, Sentinel-2\
    \ 10m Model-based X P-f\n[2021] LCC, LWC (train), Field\nsurvey(eval)\nElmetwalli\
    \ et al. Regress LAI, QuickBird X 0.6m Field Survey RF X P-f\n[2022] height, AGB,\n\
    SPAD\nIgderet al. Regress LAI Sentinel-2 10m Model-based X P-f\n[2022]\nOther\n\
    Wagle et al. RegressLight MODIS X 500m Government X T-f\n[2016] / Water Use\n\
    E\uFB03ciency\nWolanin et al. Regress GPP Sentinel-2 X 10m Model-based X P-f\n\
    [2019] (train), Field\nsurvey(eval)\nKira and Sun Regress SIF MODIS 500m Government\
    \ X P-f\n[2020]\nThorp and DrajatClassify Sentinel-1, X 10m Government RF X X\
    \ 2D L P-f\n[2021] Growth Sentinel-2 G S-i\nStage 2D T-s\nST-c\nZhao et al. Classify\
    \ Sentinel-1/2 X 10m Field survey, 2D S-i\n[2022] Growth Model-based\nStage\n\
    71.7 All Crop Damage studies\nStudies on crop damage. VI stands for vegetative\
    \ indices, and indicates whether VIs were used (possibly in\ncombination with\
    \ other features). GSD = Ground Spatial Distance/resolution. In the Tree column:\
    \ RF = Random\nForest, and a tick means any other kind of tree. In the RNN column:\
    \ G = GRU. The best performing model type in\neach study is underlined.\nModel\n\
    e M P N N\nStudy Task Images VI GSD Labels Tre SV ML CN RN Type\nDisease\nYuanet\
    \ al. Segment powdery Spot-6 X 1.5m Field Sur- X S-o\n[2014] mildew vey (P-\n\
    f)\nMa et al. [2019] Segment powdery Landsat X 30m Field Sur- X X P-f\nmildew\
    \ and vey\naphids\nBi et al. [2020] Segment SDS in PlanetScope 3m Field Sur- X\
    \ X G T-f\nsoybeans vey T-s\nPignatti et al. Segment P. Sentinel-2, X 10m, Field\
    \ Sur- X S-o\n[2021] syringae and RapidEye-1, 6.5m, vey (P-\nYellow Rust PRISMA\
    \ 30m f)\nRuanet al. Segment wheat Sentinel-2 X 10m Field Sur- X X P-f\n[2021]\
    \ stripe rust vey\nGuo et al. [2022] Segment Yellow PlanetScope X 3.1m Field Sur-\
    \ RF X P-f\nLeaf Disease vey\nGeneric Damage\nMuradyan et al. Regress heavy SPOT-7\
    \ 1.5m Field Sur- X S-o\n[2020] metal conc. vey (P-\nf)\nRodriguez et al. Regress\
    \ coconut Sentinel-2 10m Image Sur- 2D S-i\n[2021] tree density vey\nVirnodkaret\
    \ al. Segment water Sentinel-2 10m Field Sur- 2D S-i\n[2021] stress vey\nBoroughani\
    \ et al. Segment dusty MODIS 250m Field/Image X X P-f\n[2022] day Survey\n81.8\
    \ All Yield Estimation studies\nThe majority of the yield estimation studies were\
    \ county-level.\nVI stands for vegetative indices, and indicates whether VIs were\
    \ used (possibly in combination with other\nfeatures). GSD = Ground Spatial Distance/resolution.\
    \ \u201CClim.?\u201D indicates whether additional climate data was used\ninthe\
    \ prediction. The bestperformingmodeltype ineachstudy isunderlined. Where twomodeltypes\
    \ areunderlined,\nit means the model had components of both types. In the Tree\
    \ column: RF = Random Forest, and a tick means any\nother kind oftree. In the\
    \ CNN column: nD = nDCNN, including non-spatialCNNs. Inthe RNN column: L = LSTM\n\
    9Model\n?\nm. e M P N N\nStudy Crop Images VI GSD Cli Labels Tre SV ML CN RN Type\n\
    County-level yield\nLi et al. [2007] Maize, MODIS, X 1km Pub. govt. X ST-o\nSoy\
    \ AVHRR (T-f)\nCai et al. [2019] Wheat MODIS X 5.5km X Pub. govt. RF X X ST-o\n\
    (T-s)\nFeng et al. [2019] Wheat MODIS X 1km X Pub. govt. RF X X ST-o\n(P-f)\n\
    Kanget al. Maize MODIS, X 500m X Pub. govt. RF X 2D L ST-o\n[2020] [Many] X (T-f\n\
    T-s\nT-i)\nPotopova et al. Maize, MODIS X 5km X Pub. govt. X ST-o\n[2020] Sun-\
    \ (T-f)\n\uFB02ower,\nGrapes\nSchwalbert et al. Soy MODIS X 250m X Pub. govt.\
    \ RF L ST-o\n[2020] (T-f\nT-s)\nWanget al. Wheat MODIS X 500m X Pub. govt. RF\
    \ X X ST-o\n[2020b] X (T-f)\nWolanin et al. Wheat MODIS X 500m X Pub. govt. RF\
    \ 1D ST-o\n[2020] (T-f\nT-s)\nZhanget al. Maize MODIS X 1km X Pub. govt. RF L\
    \ ST-o\n[2020c] X (T-f\nT-s)\nCao et al. Rice MODIS X 1km X Pub. govt. RF L ST-o\n\
    [2021b] (T-f\nT-s)\nCao et al. Wheat MODIS X 1km X Pub. govt. RF X 1D L ST-o\n\
    [2021a] (T-f\nT-s)\nFeng et al. [2021] Wheat MODIS X 500m X Pub. govt. X ST-o\n\
    (T-f)\nJu et al. [2021] Maize, MODIS X 250m, X Pub. govt. RF X X 2D L ST-o\nSoy,Rice\
    \ 1km (T-f\nT-s)\nKhakiet al. Maize, MODIS 1km Pub. govt. RF X 2D ST-o\n[2021]\
    \ Soy 3D (T-f\nT-i\nT-c)\nMa et al. [2021] Maize MODIS X 500m X Pub. govt. X ST-o\n\
    (T-f)\nTian et al. [2021] Wheat MODIS X 1km X Pub. govt., L ST-o\nField Survey\
    \ (T-s)\nQiao et al. [2021] Wheat MODIS 500m Pub. govt. 3D ST-o\n(T-c)\nXie and\
    \ Huang Wheat MODIS X 250m X Model-based, RF 1D L ST-o\n[2021] Pub. govt. (T-f\n\
    T-s)\nJi et al. [2022] Maize MODIS X 1km X Pub. govt. RF L ST-o\n(T-f\nT-s)\n\
    Liu et al. [2022] Wheat MODIS X 1km X Pub. govt. RF X L ST-o\nX (T-f\nT-s)\nLuo\
    \ et al. [2022] Wheat AVHRR, X 1km X Pub. govt. RF L ST-o\nMODIS X (T-f\nT-s)\n\
    Watson-HernandezePtaallm. Oil Landsat- X 15m, X Business RF X ST-o\n[2022] 5/6/7/8\
    \ 30m X (T-f)\nXie [2022] Wheat Sentinel-2 X 10m X Model-based, L ST-o\nPub. govt.\
    \ (T-s)\n10There were a few studies attempting to predict yield at di\uFB00erent\
    \ scales, too, but not many.\nModel\n?\nm. e M P N N\nStudy Crop Images VI GSD\
    \ Cli Labels Tre SV ML CN RN Type\nField-level yield\nKhan et al. Mentha Landsat\
    \ X 30m Field X S-o\n[2020] Survey (P-\nf)\nArab et al. Grapes Landsat X 30m Field\
    \ X S-o\n[2021] Survey (P-\nf)\nEvans and Shen Wheat Landsat X 30m X Field RF\
    \ X X ST-o\n[2021] Survey (P-\nf)\nGbodjo et al. Millet Sentinel, X 10m, Field\
    \ RF X 2D L ST-o\n[2021] Planetscope 3.1m Survey (T-f\nT-s\n?-i)\nZhanget al.\
    \ Maize Landsat X 30m X Priv. govt. X L ST-o\n[2021b] (T-f\nT-s)\nAbebeet al.\
    \ Sugarcane Sentinel-2, X 30m Field X X ST-o\n[2022] Landsat Survey (P-\nf)\n\
    Krupavathiet al. Sugarcane Landsat X 30m Field X ST-o\n[2022] Survey (P-\nf)\n\
    Farm-level yield\nEngen et al. Any Sentinel-2 X 10m X Pub. govt. X 2D L ST-c\n\
    [2021] G\nPlot-level yield\nHaghverdiet al. Cotton Landsat X 30m X Field X T-f\n\
    [2018] Survey\nSagan et al. Maize, WorldView- 0.3m, Field RF X X 2D ST-o\n[2021]\
    \ Soy 3, 3.1m Survey 3D (P-\nPlanetScope f)\nST-c\nTree-level yield\nRahman et\
    \ al. Mango Worldview- X 0.3m Field X S-i\n[2018] 3 Survey\nPixel-level yield\n\
    Jeong et al. Rice MODIS X 1km X Model- 1D L T-s\n[2022] based\nTripathi et al.\
    \ Wheat Sentinel-1/2 X 10m Priv. govt. X P-f\n[2022]\nGrassland Biomass\nLi et\
    \ al. [2016] Grass Landsat 30m Field X P-f\nSurvey\nAli et al. [2017] Grass MODIS\
    \ X 500m Field X P-f\nSurvey\nBarnetson et al. Grass PlanetScope X 3m Field X\
    \ T-f\n[2021] Survey\nNickmilderet al. Grass Sentinel-1/2 X Field RF X X T-f\n\
    [2021] Survey\nCounty-level cumulative NDVI\nZambrano et al. All MODIS X 500m,\
    \ X Images X P-f\n[2018] 18km\n11References\nGebeyehu Abebe, Tsegaye Tadesse,\
    \ and Berhan Gessesse. Combined Use of Landsat 8 and Sentinel 2A Imagery\nfor\
    \ Improved Sugarcane Yield Estimation in Wonji-Shoa, Ethiopia. JOURNAL OF THE\
    \ INDIAN SOCIETY OF\nREMOTE SENSING, 50(1):143\u2013157,January 2022. ISSN 0255-660X.\
    \ doi: 10.1007/s12524-021-01466-8.\nAmrAbozeid,RayanAlanazi,AhmedElhadad,AhmedI.Taloba,andRashaM.AbdEl-Aziz.\
    \ Alarge-scaledatasetand\ndeeplearningmodelfordetectingandcountingolivetreesinsatelliteimagery.COMPUTATIONALINTELLIGENCE\n\
    AND NEUROSCIENCE, 2022, January 2022. ISSN 1687-5265. doi: 10.1155/2022/1549842.\n\
    Steve Ahlswede, Sarah Asam, and Achim Roeder. Hedgerow object detection in very\
    \ high-resolution satellite images\nusing convolutional neural networks. JOURNAL\
    \ OF APPLIED REMOTE SENSING, 15(1), January 2021. doi:\n10.1117/1.JRS.15.018501.\n\
    SeymaAkcaandOguzGungor. Semanticsegmentationofsoilsalinityusingin-situECmeasurementsanddeeplearning\n\
    based U-NET architecture. CATENA, 218, November 2022. ISSN 0341-8162. doi: 10.1016/j.catena.2022.106529.\n\
    Iftikhar Ali, Fiona Cawkwell, Edward Dwyer, and Stuart Green. Modeling Managed\
    \ Grassland Biomass Estimation\nby Using Multitemporal Remote Sensing Data-A Machine\
    \ Learning Approach. IEEE JOURNAL OF SELECTED\nTOPICS IN APPLIED EARTH OBSERVATIONS\
    \ AND REMOTE SENSING, 10(7):3254\u20133264, July 2017. ISSN\n1939-1404. doi: 10.1109/JSTARS.2016.2561618.\n\
    Sara Tokhi Arab, Ryozo Noguchi, Shusuke Matsushita, and Tofael Ahamed. Prediction\
    \ of grape yields from time-\nseries vegetation indices using satellite remote\
    \ sensing and a machine-learning approach. REMOTE SENSING\nAPPLICATIONS: SOCIETY\
    \ AND ENVIRONMENT, 22, April 2021. ISSN 2352-9385. doi: 10.1016/j.rsase.2021.\n\
    100485.\nMuhammad Anwar Azizan Asming, Azhar Mohd Ibrahim, and Intiaz Mohammad\
    \ Abir. Processing and classi\uFB01cation\nof landsat and sentinel images for\
    \ oil palm plantation detection. REMOTE SENSING APPLICATIONS: SOCIETY\nAND ENVIRONMENT,\
    \ 26, April 2022. ISSN 2352-9385. doi: 10.1016/j.rsase.2022.100747.\nNicolasN.Baghdadi,MohamadElHajj,MehrezZribi,andIbrahimFayad.\
    \ CouplingSARC-BandandOpticalDatafor\nSoilMoistureandLeafAreaIndex RetrievalOverIrrigatedGrasslands.\
    \ IEEE JOURNAL OF SELECTED TOPICS\nIN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,\
    \ 9(3, SI):1229\u20131243, March 2016. ISSN 1939-\n1404. doi: 10.1109/JSTARS.2015.2464698.\n\
    YF Ban. Synergy of multitemporal ERS-1 SAR and Landsat TM data for classi\uFB01\
    cation of agricultural crops. CANA-\nDIAN JOURNAL OF REMOTE SENSING, 29(4):518\u2013\
    526,August 2003. ISSN 0703-8992. doi: 10.5589/m03-014.\nJason Barnetson, Stuart\
    \ Phinn, and Peter Scarth. Climate-Resilient Grazing in the Pastures of Queensland:\
    \ An\nIntegrated Remotely Piloted Aircraft System and Satellite-Based Deep-Learning\
    \ Method for Estimating Pasture\nYield. AGRIENGINEERING, 3(3):681\u2013702,September\
    \ 2021. doi: 10.3390/agriengineering3030044.\nPaola Benedetti, Dino Ienco, Ra\uFB00\
    aele Gaetano, Kenji Ose, Ruggero G. Pensa, and Stephane Dupuy. M(3)Fusion:\nA\
    \ Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite\
    \ Data Fusion. IEEE JOURNAL\nOF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS\
    \ AND REMOTE SENSING, 11(12):4939\u20134949,\nDecember 2018. ISSN 1939-1404. doi:\
    \ 10.1109/JSTARS.2018.2876357.\nLuning Bi, Guiping Hu, Muhammad Mohsin Raza, Yuba\
    \ Kandel, Leonor Leandro, and Daren Mueller. A Gated\nRecurrent Units (GRU)-Based\
    \ Model for Early Detection of Soybean Sudden Death Syndrome through Time-Series\n\
    Satellite Imagery. REMOTE SENSING, 12(21), November 2020. doi: 10.3390/rs12213621.\n\
    Monica Bocco,GustavoOvando, Silvina Sayago,EnriqueWillington, andSusana Heredia.\
    \ Estimating soybeanground\ncoverfromsatellite imagesusingneural-networksmodels.\
    \ INTERNATIONAL JOURNALOF REMOTE SENSING,\n33(6):1717\u20131728,2012. ISSN 0143-1161.\
    \ doi: 10.1080/01431161.2011.600347.\nMahdi Boroughani, Maziar Mohammadi, Fahimeh\
    \ Mirchooli, and Stephanie Fiedler. Assessment of the impact of\ndust aerosols\
    \ on crop and water loss in the Great Salt Desert in Iran. COMPUTERS AND ELECTRONICS\
    \ IN\nAGRICULTURE, 192, January 2022. ISSN 0168-1699. doi: 10.1016/j.compag.2021.106605.\n\
    Aline Bsaibes, Dorninique Courault, Frederic Baret, Marie Weiss, Albert Olioso,\
    \ Frederic Jacob, Olivier Hagolle,\nOlivier Marloie, Nadine Bertrand, Veronique\
    \ Desfond, and Farzaneh Kzemipour. Albedo and LAI estimates from\nFORMOSAT-2 data\
    \ for crop monitoring. REMOTE SENSING OF ENVIRONMENT, 113(4):716\u2013729, April\
    \ 2009.\nISSN 0034-4257. doi: 10.1016/j.rse.2008.11.014.\nYaping Cai, Kaiyu Guan,\
    \ David Lobell, Andries B. Potgieter, Shaowen Wang, Jian Peng, Tianfang Xu, Senthold\n\
    Asseng,YongguangZhang,LiangzhiYou,andBinPeng. Integratingsatelliteandclimatedatatopredictwheatyield\n\
    inAustraliausingmachinelearningapproaches. AGRICULTURALAND FORESTMETEOROLOGY,274:144\u2013\
    159,\nAugust 2019. ISSN 0168-1923. doi: 10.1016/j.agrformet.2019.03.010.\n12JuanCao,\
    \ Zhao Zhang,Yuchuan Luo,Liangliang Zhang,Jing Zhang, Ziyue Li, andFulu Tao. Wheat\
    \ yield predictions\nat a county and \uFB01eld scale with deep learning, machine\
    \ learning, and google earth engine. EUROPEAN JOURNAL\nOF AGRONOMY, 123, February\
    \ 2021a. ISSN 1161-0301. doi: 10.1016/j.eja.2020.126204.\nJuan Cao, Zhao Zhang,\
    \ Fulu Tao, Liangliang Zhang, Yuchuan Luo, Jing Zhang, Jichong Han, and Jun Xie.\
    \ In-\ntegrating Multi-Source Data for Rice Yield Prediction across China using\
    \ Machine Learning and Deep Learning\nApproaches. AGRICULTURAL AND FOREST METEOROLOGY,\
    \ 297, February 2021b. ISSN 0168-1923. doi:\n10.1016/j.agrformet.2020.108275.\n\
    F. Carvajal, F. Aguera, and J. Sanchez-Hermosilla. Estimating the Evaporation\
    \ from Irrigation Reservoirs of Green-\nhouses Using Satellite Imagery. ENVIRONMENTAL\
    \ PROGRESS & SUSTAINABLE ENERGY, 35(6):1750\u20131757,\nNovember 2016. ISSN 1944-7442.\
    \ doi: 10.1002/ep.12419.\nMohamed Chelali, Camille Kurtz, Anne Puissant, and Nicole\
    \ Vincent. Deep-STaR: Classi\uFB01cation of image time series\nbasedonspatio-temporalrepresentations.\
    \ COMPUTER VISIONANDIMAGEUNDERSTANDING,208,July2021.\nISSN 1077-3142. doi: 10.1016/j.cviu.2021.103221.\n\
    Yun-Jae Choung and Donghwi Jung. Comparison of Machine and Deep Learning Methods\
    \ for Mapping Sea Farms\nUsing High-Resolution Satellite Image. Journal of Coastal\
    \ Research, 114(sp1):420\u2013423, October 2021. ISSN 0749-\n0208, 1551-5036.\
    \ doi: 10.2112/JCR-SI114-085.1.\nThomas Colligan, David Ketchum, Douglas Brinkerho\uFB00\
    , and Marco Maneta. A deep learning approach to mapping\nirrigationusinglandsat:\
    \ IrrMapperU-net. IEEE TRANSACTIONSON GEOSCIENCE AND REMOTE SENSING,\n60, 2022.\
    \ ISSN 0196-2892. doi: 10.1109/TGRS.2022.3175635.\nRapha\xA8el d\u2019Andrimont,\
    \ Astrid Verhegghen, Michele Meroni, Guido Lemoine, Peter Strobl, Beatrice Eiselt,\
    \ Momchil\nYordanov,LauraMartinez-Sanchez,andMarijnvanderVelde. LUCASCopernicus2018:\
    \ Earth-observation-relevant\nin situ data on land cover and use throughout the\
    \ European Union. Earth System Science Data, 13(3):1119\u20131133,\nMarch 2021.\
    \ ISSN 1866-3508. doi: 10.5194/essd-13-1119-2021.\nAnesmar Olino de Albuquerque,\
    \ Osmar Abilio de Carvalho Junior, Osmar Luiz Ferreira de Carvalho, Pablo Pozzobon\n\
    de Bem, Pedro Henrique Guimaraes Ferreira, Rebeca dos Santos de Moura, Cristiano\
    \ Rosa Silva, Roberto Arnaldo\nTrancoso Gomes, and Renato Fontes Guimaraes. Deep\
    \ Semantic Segmentation of Center Pivot Irrigation Systems\nfrom Remotely Sensed\
    \ Data. REMOTE SENSING, 12(13), July 2020. doi: 10.3390/rs12132159.\nMisganuDebella-GiloandArntKristianGjertsen.MappingSeasonalAgriculturalLandUseTypesUsingDeepLearning\n\
    on Sentinel-2 Image Time Series. REMOTE SENSING, 13(2), January 2021. doi: 10.3390/rs13020289.\n\
    FDelFrate,PFerrazzoli,LGuerriero,TStrozzi,UWegmuller,GCookmartin,andSQuegan. Wheatcyclemonitoring\n\
    using radar data and a neural network trained by a model. IEEE TRANSACTIONS ON\
    \ GEOSCIENCE AND\nREMOTE SENSING, 42(1):35\u201344,January 2004. ISSN 0196-2892.\
    \ doi: 10.1109/TGRS.2003.817200.\nCindy Delloye, Marie Weiss, and Pierre Defourny.\
    \ Retrieval of the canopy chlorophyllcontent from Sentinel-2 spectral\nbandstoestimatenitrogenuptakeinintensivewinterwheatcroppingsystems.\
    \ REMOTE SENSINGOF ENVIRON-\nMENT, 216:245\u2013261,October 2018. ISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2018.06.037.\nJohannDesloires,DinoIenco,AntoineBotrel,andNicolasRanc.\
    \ PositiveUnlabelledLearningforSatelliteImages\u2019Time\nSeries Analysis: An\
    \ Application to Cereal and Forest Mapping. REMOTE SENSING, 14(1), January 2022.\
    \ doi:\n10.3390/rs14010140.\nSt\xB4ephane Dupuy and Ra\uFB00aele Gaetano. Reunion\
    \ island - 2019, Land cover map (Spot6/7) - 1.5m, 2020.\nAdel H. Elmetwalli, Yasser\
    \ S. A. Mazrou, Andrew N. Tyler, Peter D. Hunter, Osama Elsherbiny, Zaher Mundher\n\
    Yaseen, and Salah Elsayed. Assessing the e\uFB03ciency of remote sensing and machine\
    \ learning algorithms to quantify\nwheat characteristics in the nile delta region\
    \ of egypt. AGRICULTURE-BASEL, 12(3), March 2022. doi: 10.3390/\nagriculture12030332.\n\
    Martin Engen, Erik Sand\xF8, Benjamin Lucas Oscar Sj\xF8lander, Simon Arenberg,\
    \ Rashmi Gupta, and Morten Goodwin.\nFarm-Scale Crop Yield Prediction from Multi-Temporal\
    \ Data Using Deep Hybrid Neural Networks. Agronomy, 11\n(12):2576, December 2021.\
    \ ISSN 2073-4395. doi: 10.3390/agronomy11122576.\nOrhan Eroglu, Mehmet Kurum,\
    \ Dylan Boyd, and Ali Cafer Gurbuz. High Spatio-Temporal Resolution CYGNSS Soil\n\
    Moisture Estimates Using Arti\uFB01cial Neural Networks. REMOTE SENSING, 11(19),\
    \ October 2019. doi: 10.3390/\nrs11192272.\nFiona H. Evans and Jianxiu Shen. Long-Term\
    \ Hindcasts of Wheat Yield in Fields Using Remotely Sensed Phenology,\nClimate\
    \ Data and Machine Learning. REMOTE SENSING, 13(13), July 2021. doi: 10.3390/rs13132435.\n\
    13LuweiFeng,YumiaoWang,ZhouZhang,andQingyunDu. Geographicallyandtemporallyweightedneuralnetworkfor\n\
    winter wheat yield prediction. REMOTE SENSING OF ENVIRONMENT, 262, September 2021.\
    \ ISSN 0034-4257.\ndoi: 10.1016/j.rse.2021.112514.\nPuyuFeng,BinWang,DeLiLiu,andQiangYu.\
    \ Machinelearning-basedintegrationofremotely-senseddroughtfactors\ncan improve\
    \ the estimation of agricultural drought in South-Eastern Australia. AGRICULTURAL\
    \ SYSTEMS, 173:\n303\u2013316,July 2019. ISSN 0308-521X. doi: 10.1016/j.agsy.2019.03.015.\n\
    Marcos Fernandez-Sellers, Guillermo Siesto, Adolfo Lozano-Tello, and Pedro J.\
    \ Clemente. Finding a suitable sensing\ntimeperiodforcropidenti\uFB01cationusingheuristictechniqueswithmulti-temporalsatelliteimages.INTERNATIONAL\n\
    JOURNAL OF REMOTE SENSING, September 2021. ISSN 0143-1161. doi: 10.1080/01431161.2021.1975846.\n\
    Matheus Pinheiro Ferreira, Rodolfo Georjute Lotte, Francisco D\u2019Elia, V, Christos\
    \ Stamatopoulos, Do-Hyung Kim,\nand Adam R. Benjamin. Accurate mapping of Brazil\
    \ nut trees (Bertholletia excelsa) in Amazonian forests using\nWorldView-3 satellite\
    \ images and convolutional neural networks. ECOLOGICAL INFORMATICS, 63, July 2021.\n\
    ISSN 1574-9541. doi: 10.1016/j.ecoinf.2021.101302.\nGiacomoFontanelli,AlessandroLapini,LeonardoSanturri,SimonePettinato,EmanueleSanti,GiulianoRamat,Simone\n\
    Pilia, Fabrizio Baroni, Deodato Tapete, Francesca Cigna, and Simonetta Paloscia.\
    \ Early-season crop mapping on\nan agricultural area in italy using X-band dual-polarization\
    \ SAR satellite data and convolutional neural networks.\nIEEE JOURNAL OF SELECTED\
    \ TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,\n15:6789\u20136803,2022.\
    \ ISSN 1939-1404. doi: 10.1109/JSTARS.2022.3198475.\nYongyong Fu, Jinsong Deng,\
    \ Hongquan Wang, Alexis Comber, Wu Yang, Wenqiang Wu, Shixue You, Yi Lin, and\n\
    Ke Wang. A new satellite-deriveddatasetfor marine aquaculture areasin China\u2019\
    s coastalregion. EARTH SYSTEM\nSCIENCE DATA, 13(4):1829\u20131842,May 2021. ISSN\
    \ 1866-3508. doi: 10.5194/essd-13-1829-2021.\nIgnazio Gallo, Riccardo La Grassa,\
    \ Nicola Landro, and Mirco Boschetti. Sentinel 2 Time Series Analysis with 3D\n\
    FeaturePyramidNetworkandTimeDomainClassActivationIntervalsforCropMapping.ISPRSINTERNATIONAL\n\
    JOURNAL OF GEO-INFORMATION, 10(7), July 2021. doi: 10.3390/ijgi10070483.\nVivien\
    \ Sainte Fare Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata.\
    \ Satellite Image Time Series\nClassi\uFB01cation With Pixel-Set Encoders and\
    \ Temporal Self-Attention. In Proceedings of the IEEE/CVF Conference\non Computer\
    \ Vision and Pattern Recognition, pages 12325\u201312334,2020.\nVivien Sainte\
    \ Fare Garnot, Loic Landrieu, and Nesrine Chehata. Multi-modal temporal attention\
    \ models for crop\nmapping from satellite time series. ISPRS JOURNAL OF PHOTOGRAMMETRY\
    \ AND REMOTE SENSING, 187:\n294\u2013305,May 2022. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2022.03.012.\n\
    F. Gascon, J. P. Gastellu-Etchegorry, and M. Leroy. Using multi-directional high-resolution\
    \ imagery from POLDER\nsensortoretrieveleafareaindex.INTERNATIONALJOURNALOFREMOTESENSING,28(1-2):167\u2013\
    181,January\n2007. ISSN 0143-1161. doi: 10.1080/01431160600647217.\nRamesh Gautam,\
    \ Suranjan Panigrahi, David Franzen, and Albert Sims. Residual soil nitrate prediction\
    \ from im-\nagery and non-imagery information using neural network technique.\
    \ BIOSYSTEMS ENGINEERING, 110(1):20\u201328,\nSeptember 2011. ISSN 1537-5110.\
    \ doi: 10.1016/j.biosystemseng.2011.06.002.\nYawogan Jean Eudes Gbodjo, Dino Ienco,\
    \ and Louise Leroux. Benchmarking statistical modelling approaches with\nmulti-sourceremotesensingdataformilletyieldmonitoring:\
    \ Acasestudyofthe groundnutbasinincentralSenegal.\nINTERNATIONAL JOURNAL OF REMOTE\
    \ SENSING, 42(24):9277\u20139300,December 2021. ISSN 0143-1161. doi:\n10.1080/01431161.2021.1993465.\n\
    Nima Ghasemloo, Ali Akbar Matkan, Abbas Alimohammadi, Hossein Aghighi, and Babak\
    \ Mirbagheri. Estimating\nthe agricultural farm soil moisture using spectral indices\
    \ of landsat 8, and sentinel-1, and arti\uFB01cial neural networks.\nJOURNAL OF\
    \ GEOVISUALIZATION AND SPATIAL ANALYSIS, 6(2), December 2022. ISSN 2509-8810.\
    \ doi:\n10.1007/s41651-022-00110-4.\nC. Gomez, M. Mangeas, M. Petit, C. Corbane,\
    \ P. Hamon, S. Hamon, A. De Kochko, D. Le Pierres, V. Poncet, and\nM.Despinoy.\
    \ Useofhigh-resolutionsatelliteimageryinanintegratedmodeltopredictthedistributionofshadeco\uFB00\
    ee\ntreehybridzones. REMOTE SENSINGOF ENVIRONMENT,114(11):2731\u20132744,November2010.\
    \ ISSN0034-4257.\ndoi: 10.1016/j.rse.2010.06.007.\nJiaweiGuo, Yu Jin, Huichun\
    \ Ye, Wenjiang Huang, Jinling Zhao, Bei Cui, Fucheng Liu, and Jiajian Deng. Recognition\n\
    of Areca Leaf Yellow Disease Based on PlanetScope Satellite Imagery. AGRONOMY-BASEL,\
    \ 12(1), January 2022.\ndoi: 10.3390/agronomy12010014.\nVahid Habibi, Hasan Ahmadi,\
    \ Mohammad Jafari, and Abolfazl Moeini. Quantitative assessment of soil salinity\n\
    using remote sensing data based on the arti\uFB01cial neural network, case study:\
    \ Sharif Abad Plain, Central Iran.\nMODELING EARTH SYSTEMS AND ENVIRONMENT, 7(2):1373\u2013\
    1383, June 2021. ISSN 2363-6203. doi:\n10.1007/s40808-020-01015-1.\n14Amir Haghverdi,\
    \ Robert A. Washington-Allen, and Brian G. Leib. Prediction of cotton lint yield\
    \ from phenology\nof crop indices using arti\uFB01cial neural networks. COMPUTERS\
    \ AND ELECTRONICS IN AGRICULTURE, 152:\n186\u2013197,September 2018. ISSN 0168-1699.\
    \ doi: 10.1016/j.compag.2018.07.021.\nA.M.Hamer,D.M.Simms,andT.W.Waine. ReplacinghumaninterpretationofagriculturallandinAfghanistanwith\n\
    a deep convolutional neural network. INTERNATIONAL JOURNAL OF REMOTE SENSING,\
    \ 42(8):3017\u20133038,\nApril 2021. ISSN 0143-1161. doi: 10.1080/01431161.2020.1864059.\n\
    Omid Mohammadi Igder, Hosein Alizadeh, Barat Mojaradi, and Mehrad Bayat. Multivariate\
    \ assimilation of satellite-\nbased leaf area index and ground-based river stream\uFB02\
    ow for hydrological modelling of irrigated watersheds using\nSWAT. JOURNAL OF\
    \ HYDROLOGY,610, July 2022. ISSN 0022-1694. doi: 10.1016/j.jhydrol.2022.128012.\n\
    Roberto Interdonato, Dino Ienco, Ra\uFB00aele Gaetano, and Kenji Ose. DuPLO: A\
    \ DUal view Point deep Learning\narchitecturefortimeseriesclassi\uFB01catiOn.ISPRSJOURNALOFPHOTOGRAMMETRYANDREMOTESENSING,\n\
    149:91\u2013104,March 2019. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2019.01.011.\n\
    SeungtaekJeong,JonghanKo,andJong-MinYeom.Predictingriceyieldatpixelscalethroughsyntheticuseofcropand\n\
    deep learningmodels with satellite data in South andNorth Korea. SCIENCE OF THE\
    \ TOTAL ENVIRONMENT,\n802, January 2022. ISSN 0048-9697. doi: 10.1016/j.scitotenv.2021.149726.\n\
    ShunpingJi,ChiZhang,AnjianXu,YunShi,andYulinDuan.3DConvolutionalNeuralNetworksforCropClassi\uFB01\
    cation\nwith Multi-Temporal Remote Sensing Images. REMOTE SENSING, 10(1), January\
    \ 2018. doi: 10.3390/rs10010075.\nZhonglinJi, YaozhongPan,Xiufang Zhu, Dujuan\
    \ Zhang,and JiajiaDai. Predictionofcornyieldin the USA cornbelt\nusingsatellitedataandmachinelearning:\
    \ Fromanevapotranspirationperspective. AGRICULTURE-BASEL,12(8),\nAugust 2022.\
    \ doi: 10.3390/agriculture12081263.\nDeyang Jiang, Shengbo Chen, Juliana Useya,\
    \ Lisai Cao, and Tianqi Lu. Crop mapping using the historical crop\ndata layer\
    \ and deep neural networks: A case study in jilin province, china. SENSORS, 22(15),\
    \ August 2022. doi:\n10.3390/s22155853.\nYu Jin, Jiawei Guo, Huichun Ye, Jinling\
    \ Zhao, Wenjiang Huang, and Bei Cui. Extraction of Arecanut Planting\nDistribution\
    \ Based on the Feature Space Optimization of PlanetScope Imagery. AGRICULTURE-BASEL,\
    \ 11(4),\nApril 2021. doi: 10.3390/agriculture11040371.\nMaxwell Jong, Kaiyu Guan,\
    \ Sibo Wang, Yizhi Huang, and Bin Peng. Improving \uFB01eld boundary delineation\
    \ in Re-\nsUNetsviaadversarialdeeplearning. INTERNATIONALJOURNALOFAPPLIED EARTH\
    \ OBSERVATIONAND\nGEOINFORMATION, 112, August 2022. ISSN 1569-8432. doi: 10.1016/j.jag.2022.102877.\n\
    Sungha Ju, Hyoungjoon Lim, Jong Won Ma, Soohyun Kim, Kyungdo Lee, Shuhe Zhao,\
    \ and Joon Heo. Optimal\ncounty-levelcropyield prediction using MODIS-based variables\
    \ and weather data: A comparativestudy on machine\nlearning models. AGRICULTURAL\
    \ AND FOREST METEOROLOGY, 307,September 2021. ISSN 0168-1923. doi:\n10.1016/j.agrformet.2021.108530.\n\
    Yanghui Kang, Mutlu Ozdogan, Xiaojin Zhu, Zhiwei Ye, Christopher Hain, and Martha\
    \ Anderson. Comparative\nassessmentofenvironmentalvariablesandmachinelearningalgorithmsformaizeyieldpredictionintheUSMidwest.\n\
    ENVIRONMENTAL RESEARCH LETTERS, 15(6), June 2020. ISSN 1748-9326. doi: 10.1088/1748-9326/ab7df9.\n\
    ManojKarkee,BrianL.Steward,LieTang,andSarnsuzanaA.Aziz. Quantifyingsub-pixelsignatureofpaddyrice\uFB01\
    eld\nusing anarti\uFB01cialneuralnetwork. COMPUTERS AND ELECTRONICS IN AGRICULTURE,65(1):65\u2013\
    76,January\n2009. ISSN 0168-1699. doi: 10.1016/j.compag.2008.07.009.\nSaeed Khaki,\
    \ Hieu Pham, and Lizhi Wang. Simultaneous corn and soybean yield prediction from\
    \ remote sensing\ndata using deep transfer learning. SCIENTIFIC REPORTS, 11(1),\
    \ May 2021. ISSN 2045-2322. doi: 10.1038/\ns41598-021-89779-z.\nMohammad Saleem\
    \ Khan, Manoj Semwal, Ashok Sharma, and Rajesh Kumar Verma. An arti\uFB01cial\
    \ neural network\nmodel for estimating Mentha crop biomass yield using Landsat\
    \ 8 OLI. PRECISION AGRICULTURE, 21(1):18\u201333,\nFebruary 2020. ISSN 1385-2256.\
    \ doi: 10.1007/s11119-019-09655-9.\nOz Kira and Ying Sun. Extraction of sub-pixel\
    \ C3/C4 emissions of solar-induced chlorophyll \uFB02uorescence (SIF) using\n\
    arti\uFB01cial neural network. ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,\
    \ 161:135\u2013146,\nMarch 2020. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2020.01.017.\n\
    Oz Kira, Anthony L. Nguy-Robertson, Timothy J. Arkebauer, Raphael Linker, and\
    \ Anatoly A. Gitelson. Toward\nGeneric Models for Green LAI Estimation in Maize\
    \ and Soybean: Satellite Observations. REMOTE SENSING, 9\n(4), April 2017. ISSN\
    \ 2072-4292. doi: 10.3390/rs9040318.\n15J.Kolassa,R.H.Reichle,Q.Liu,S.H.Alemohammad,P.Gentine,K.Aida,J.Asanuma,S.Bircher,T.Caldwell,A.Col-\n\
    liander,M. Cosh,C.Holi\uFB01eldCollins, T.J.Jackson,J.Martinez-Fernandez,H.McNairn,\
    \ A.Pacheco,M.Thibeault,\nand J.P. Walker. Estimating surface soilmoisture from\
    \ SMAP observations using a Neural Networktechnique. RE-\nMOTE SENSING OF ENVIRONMENT,\
    \ 204:43\u201359,January 2018. ISSN 0034-4257. doi: 10.1016/j.rse.2017.10.045.\n\
    K.Krupavathi,M.Raghubabu,A.Mani,P.R.K.Parasad,andL.Edukondalu. Field-ScaleEstimationandComparison\n\
    of the Sugarcane Yield from Remote Sensing Data: A Machine Learning Approach.\
    \ JOURNAL OF THE INDIAN\nSOCIETY OF REMOTE SENSING, February 2022. ISSN 0255-660X.\
    \ doi: 10.1007/s12524-021-01448-w.\nP. Kumar, R. Prasad, A. Choudhary, D. K. Gupta,\
    \ V. N. Mishra, A. K. Vishwakarma, A. K. Singh, and P. K.\nSrivastava. Comprehensiveevaluationofsoilmoistureretrievalmodels\
    \ underdi\uFB00erentcropcovertypesusingC-band\nsynthetic aperture radar data.\
    \ GEOCARTO INTERNATIONAL,34(9):1022\u20131041,July 2019. ISSN 1010-6049. doi:\n\
    10.1080/10106049.2018.1464601.\nPradeep Kumar, Dileep Kumar Gupta, Varun Narayan\
    \ Mishra, and Rajendra Prasad. Comparison of support vector\nmachine, arti\uFB01\
    cial neural network, and spectral angle mapper algorithms for crop classi\uFB01\
    cation using LISS IV data.\nINTERNATIONAL JOURNAL OF REMOTE SENSING, 36(6):1604\u2013\
    1617, 2015. ISSN 0143-1161. doi: 10.1080/\n2150704X.2015.1019015.\nNataliia Kussul,\
    \ Mykola Lavreniuk, Sergii Skakun, and Andrii Shelestov. Deep Learning Classi\uFB01\
    cation of Land Cover\nand Crop Types Using Remote Sensing Data. IEEE GEOSCIENCE\
    \ AND REMOTE SENSING LETTERS, 14(5):\n778\u2013782,May 2017. ISSN 1545-598X. doi:\
    \ 10.1109/LGRS.2017.2681128.\nNataliia Kussul, Lavreniuk Mykola, Andrii Shelestov,\
    \ and Sergii Skakun. Crop inventory at regional scale in Ukraine:\nDeveloping\
    \ in season and end of season crop maps with multi-temporal optical and SAR satellite\
    \ imagery. EURO-\nPEAN JOURNAL OF REMOTE SENSING, 51(1):627\u2013636,2018. doi:\
    \ 10.1080/22797254.2018.1454265.\nNoureldin Laban, Bassam Abdellatif, Hala M.\
    \ Ebeid, Howida A. Shedeed, and Mohamed F. Tolba. Sparse Pixel\nTraining of Convolutional\
    \ Neural Networks for Land Cover Classi\uFB01cation. IEEE ACCESS, 9:52067\u2013\
    52078, 2021.\nISSN 2169-3536. doi: 10.1109/ACCESS.2021.3069882.\nLeiLei,XinyuWang,YanfeiZhong,HengweiZhao,Xin\
    \ Hu, andChangLuo. DOCC:Deepone-classcropclassi\uFB01cation\nviapositiveandunlabeledlearningformulti-modalsatellite\
    \ imagery. INTERNATIONALJOURNALOF APPLIED\nEARTH OBSERVATION AND GEOINFORMATION,\
    \ 105, December 2021. ISSN 1569-8432. doi: 10.1016/j.jag.\n2021.102598.\nTsu Chiang\
    \ Lei, Shiuan Wan, You Cheng Wu, Hsin-Ping Wang, and Chia-Wen Hsieh. Multi-temporal\
    \ data fusion in\nMSandSARimagesusingthedynamictimewarpingmethodforpaddyriceclassi\uFB01\
    cation. AGRICULTURE-BASEL,\n12(1), January 2022. doi: 10.3390/agriculture12010077.\n\
    AinongLi,ShunlinLiang,AngshengWang,andJunQin. Estimatingcropyieldfrommulti-temporalsatellitedatausing\n\
    multivariate regression and neural network techniques. PHOTOGRAMMETRIC ENGINEERING\
    \ AND REMOTE\nSENSING, 73(10):1149\u20131157,October 2007. ISSN 0099-1112. doi:\
    \ 10.14358/PERS.73.10.1149.\nFei Li, Jiajia Zheng, Hao Wang, Juhua Luo, Ying Zhao,\
    \ and Ruibin Zhao. Mapping grazing intensity using remote\nsensing in the Xilingol\
    \ steppe region, Inner Mongolia, China. REMOTE SENSING LETTERS, 7(4):328\u2013\
    337,2016.\nISSN 2150-704X. doi: 10.1080/2150704X.2015.1137987.\nHepingLi,JingLu,GuixiangTian,HuijinYang,JianhuiZhao,andNingLi.\
    \ Cropclassi\uFB01cationbasedonGDSSM-CNN\nusing multi-temporal RADARSAT-2 SAR\
    \ with limited labeled data. REMOTE SENSING, 14(16), August 2022a.\ndoi: 10.3390/rs14163889.\n\
    Jingtao Li, Yonglin Shen, and Chao Yang. An Adversarial Generative Network for\
    \ Crop Classi\uFB01cation from Remote\nSensing Timeseries Images. REMOTE SENSING,\
    \ 13(1), January 2021. doi: 10.3390/rs13010065.\nMin Li, Zhijie Zhang, Liping\
    \ Lei, Xiaofan Wang, and Xudong Guo. Agricultural Greenhouses Detection in High-\n\
    Resolution Satellite Images Based on ConvolutionalNeural Networks: Comparisonof\
    \ Faster R-CNN, YOLO v3 and\nSSD. SENSORS, 20(17), September 2020. doi: 10.3390/s20174938.\n\
    Ting Li, Kasper Johansen, and Matthew F. McCabe. A machine learning approach for\
    \ identifying and delineating\nagricultural \uFB01elds and their multi-temporal\
    \ dynamics using three decades of Landsat data. ISPRS JOURNAL OF\nPHOTOGRAMMETRY\
    \ AND REMOTE SENSING, 186:83\u2013101, April 2022b. ISSN 0924-2716. doi: 10.1016/j.\n\
    isprsjprs.2022.02.002.\nWeijia Li,Runmin Dong,HaohuanFu, andLe Yu. Large-ScaleOilPalmTreeDetectionfromHigh-ResolutionSatellite\n\
    Images Using Two-Stage Convolutional Neural Networks. REMOTE SENSING, 11(1), January\
    \ 2019. doi: 10.3390/\nrs11010011.\n16Zhuqiang Li, Shengbo Chen, Xiangyu Meng,\
    \ Ruifei Zhu, Junyan Lu, Lisai Cao, and Peng Lu. Full convolution neural\nnetworkcombinedwithcontextualfeaturerepresentationforcroplandextractionfromhigh-resolutionremotesensing\n\
    images. REMOTE SENSING, 14(9), May 2022c. doi: 10.3390/rs14092157.\nChenxiLin,ZhenongJin,DavidMulla,RahulGhosh,KaiyuGuan,VipinKumar,andYapingCai.\
    \ TowardLarge-Scale\nMapping of Tree Crops with High-Resolution Satellite Imagery\
    \ and Deep Learning Algorithms: A Case Study of\nOlive Orchards in Morocco. REMOTE\
    \ SENSING, 13(9), May 2021. doi: 10.3390/rs13091740.\nYuanyuanLiu,ShaoqiangWang,XiaoboWang,BinChen,JinghuaChen,JunbangWang,MeiHuang,ZhaoshengWang,\n\
    Li Ma, Pengyuan Wang, Muhammad Amir, and Kai Zhu. Exploring the superiority of\
    \ solar-induced chlorophyll\n\uFB02uorescence data in predicting wheat yield using\
    \ machine learning and deep learning methods. COMPUTERS AND\nELECTRONICS IN AGRICULTURE,\
    \ 192, January 2022. ISSN 0168-1699. doi: 10.1016/j.compag.2021.106612.\nFabian\
    \ Loew, Christopher Conrad, and Ulrich Michel. Decision fusion and non-parametric\
    \ classi\uFB01ers for land use\nmapping using multi-temporal RapidEye data. ISPRS\
    \ JOURNAL OF PHOTOGRAMMETRY AND REMOTE\nSENSING, 108:191\u2013204,October 2015.\
    \ ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2015.07.001.\nJiang Long, Mengmeng\
    \ Li, Xiaoqin Wang, and Alfred Stein. Delineation of agricultural \uFB01elds using\
    \ multi-task BsiNet\nfromhigh-resolutionsatelliteimages. INTERNATIONALJOURNALOF\
    \ APPLIED EARTH OBSERVATIONAND\nGEOINFORMATION, 112, August 2022. ISSN 1569-8432.\
    \ doi: 10.1016/j.jag.2022.102871.\nAdolfoLozano-Tello,MarcosFernandez-Sellers,EliaQuiros,LauraFragoso-Campon,AbelardoGarcia-Martin,JoseAn-\n\
    tonio Gutierrez Gallego, Carmen Mateos, Ruben Trenado, and Pedro Munoz. Crop identi\uFB01\
    cation by massive pro-\ncessingofmultiannualsatellite imageryforEUcommonagriculturepolicysubsidy\
    \ control. EUROPEAN JOURNAL\nOF REMOTE SENSING, 54(1):1\u201312,January 2021.\
    \ doi: 10.1080/22797254.2020.1858723.\nTingting Lu, Martin Brandt, Xiaoye Tong,\
    \ Pierre Hiernaux, Louise Leroux, Babacar Ndao, and Rasmus Fensholt.\nMapping\
    \ the Abundance of Multipurpose AgroforestryFaidherbia albida Trees in Senegal.\
    \ REMOTE SENSING, 14\n(3), February 2022. doi: 10.3390/rs14030662.\nYuchuan Luo,\
    \ Zhao Zhang, Juan Cao, Liangliang Zhang, Jing Zhang, Jichong Han, Huimin Zhuang,\
    \ Fei Cheng, and\nFulu Tao. Accurately mapping globalwheat production system using\
    \ deep learning algorithms. INTERNATIONAL\nJOURNAL OF APPLIED EARTH OBSERVATION\
    \ AND GEOINFORMATION, 110, June 2022. ISSN 1569-8432.\ndoi: 10.1016/j.jag.2022.102823.\n\
    HuiqinMa,WenjiangHuang,YuanshuJing,ChenghaiYang,LiangxiuHan,YingyingDong,HuichunYe,YueShi,Qiong\n\
    Zheng, Linyi Liu, and Chao Ruan. Integrating Growth and Environmental Parameters\
    \ to Discriminate Powdery\nMildewandAphidofWinterWheatUsingBi-TemporalLandsat-8Imagery.\
    \ REMOTE SENSING,11(7),April2019.\ndoi: 10.3390/rs11070846.\nYintao Ma, Zheng\
    \ Zhou, Xiaoxiong She, Longyu Zhou, Tao Ren, Shishi Liu, and Jianwei Lu. Identifying\
    \ Dike-Pond\nSystem Using an Improved Cascade R-CNN Model and High-Resolution\
    \ Satellite Images. REMOTE SENSING, 14\n(3), February 2022. doi: 10.3390/rs14030717.\n\
    Yuchi Ma, Zhou Zhang, Yanghui Kang, and Mutlu Ozdogan. Corn yield prediction and\
    \ uncertainty analysis based on\nremotely sensed variables using a Bayesian neural\
    \ network approach. REMOTE SENSING OF ENVIRONMENT,\n259, June 2021. ISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2021.112408.\nMartino E. Malerba, Nicholas Wright, and Peter\
    \ I. Macreadie. A Continental-Scale Assessment of Density, Size,\nDistribution\
    \ and Historical Trends of Farm Dams Using Deep Learning Convolutional Neural\
    \ Networks. REMOTE\nSENSING, 13(2), January 2021. doi: 10.3390/rs13020319.\nMartino\
    \ E. Malerba, Nicholas Wright, and Peter I. Macreadie. Australian farm dams are\
    \ becoming less reliable water\nsourcesunder climate change. SCIENCE OF THE TOTAL\
    \ ENVIRONMENT,829,July 2022. ISSN 0048-9697. doi:\n10.1016/j.scitotenv.2022.154360.\n\
    Mauro Martini, Vittorio Mazzia, Aleem Khaliq, and Marcello Chiaberge. Domain-Adversarial\
    \ Training of Self-\nAttention-Based Networks for Land Cover Classi\uFB01cation\
    \ Using Multi-Temporal Sentinel-2 Satellite Imagery. RE-\nMOTE SENSING, 13(13),\
    \ July 2021. doi: 10.3390/rs13132564.\nKhairiya Mudrik Masoud, Claudio Persello,\
    \ and Valentyn A. Tolpekin. Delineation of Agricultural Field Boundaries\nfrom\
    \ Sentinel-2 Images Using a Novel Super-Resolution Contour Detector Based on Fully\
    \ Convolutional Networks.\nREMOTE SENSING, 12(1), January 2020. doi: 10.3390/rs12010059.\n\
    Vittorio Mazzia, Aleem Khaliq, and Marcello Chiaberge. Improvement in Land Cover\
    \ and Crop Classi\uFB01cation based\non Temporal Features Learning from Sentinel-2\
    \ Data Using Recurrent-Convolutional Neural Network (R-CNN).\nAPPLIED SCIENCES-BASEL,\
    \ 10(1), January 2020. doi: 10.3390/app10010238.\n17Weiye Mei, HaoyuWang, DavidFouhey,\
    \ Weiqi Zhou,Isabella Hinks, JoshM.Gray,Derek Van Berkel,andMeha Jain.\nUsing\
    \ deep learning andvery-high-resolutionimageryto mapsmallholder \uFB01eldboundaries.\
    \ REMOTE SENSING,14\n(13), July 2022. doi: 10.3390/rs14133046.\nShiyao Meng, Xinyu\
    \ Wang, Xin Hu, Chang Luo, and Yanfei Zhong. Deep learning-based crop mapping\
    \ in the cloudy\nseason using one-shot hyperspectral satellite imagery. COMPUTERS\
    \ AND ELECTRONICS IN AGRICULTURE,\n186, July 2021. ISSN 0168-1699. doi: 10.1016/j.compag.2021.106188.\n\
    Nando Metzger, Mehmet Ozgur Turkoglu, Stefano D\u2019Aronco, Jan Dirk Wegner,\
    \ and Konrad Schindler. Crop Classi\uFB01-\ncation Under Varying Cloud CoverWith\
    \ Neural OrdinaryDi\uFB00erential Equations. IEEE Transactions on Geoscience\n\
    and Remote Sensing, 60:1\u201312,2022. ISSN 1558-0644. doi: 10.1109/TGRS.2021.3101965.\n\
    Monica Y. Moreno-Revelo, Lorena Guachi-Guachi, Juan Bernardo Gomez-Mendoza, Javier\
    \ Revelo-Fuelagan, and\nDiegoH. Pelu\uFB00o-Ordonez. EnhancedConvolutional-Neural-NetworkArchitecture\
    \ forCropClassi\uFB01cation. APPLIED\nSCIENCES-BASEL, 11(9), May 2021. doi: 10.3390/app11094292.\n\
    Aicha Moumni andAbderrahmanLahrouni. Machine Learning-BasedClassi\uFB01cationfor\
    \ Crop-TypeMapping Using the\nFusion ofHigh-ResolutionSatellite Imageryin a SemiaridArea.\
    \ SCIENTIFICA, 2021,April 2021. ISSN 2090-908X.\ndoi: 10.1155/2021/8810279.\n\
    Svetlana Mukharamova, Anatoly Saveliev, Maxim Ivanov, Artur Gafurov, and Oleg\
    \ Yermolaev. Estimating the Soil\nErosion Cover-Management Factor at the European\
    \ Part of Russia. ISPRS INTERNATIONAL JOURNAL OF\nGEO-INFORMATION, 10(10), October\
    \ 2021. doi: 10.3390/ijgi10100645.\nVahagn Muradyan, Garegin Tepanosyan, Shushanik\
    \ Asmaryan, Nairuhi Maghakyan, Lilit Sahakyan, and Armen\nSaghatelyan. Estimating\
    \ Mo, Cu, Ni, Cd Contents in the Crop Leaves Growing on Small Land Plots Using\
    \ Satellite\nData. COMMUNICATIONS IN SOIL SCIENCE AND PLANT ANALYSIS, 51(11):1457\u2013\
    1468, June 2020. ISSN\n0010-3624. doi: 10.1080/00103624.2020.1784922.\nEmile Ndikumana,\
    \ Dinh Ho Tong Minh, Nicolas Baghdadi, Dominique Courault, and Laure Hossard.\
    \ Deep Recurrent\nNeuralNetworkforAgriculturalClassi\uFB01cationusingmultitemporalSARSentinel-1forCamargue,France.\
    \ REMOTE\nSENSING, 10(8), August 2018. doi: 10.3390/rs10081217.\nThanhTamNguyen,ThanhDatHoang,MinhTamPham,TuyetTrinhVu,ThanhHungNguyen,Quyet-ThangHuynh,\n\
    and Jun Jo. Monitoring agriculture areas with satellite images and deep learning.\
    \ APPLIED SOFT COMPUTING,\n95, October 2020. ISSN 1568-4946. doi: 10.1016/j.asoc.2020.106565.\n\
    Charles Nickmilder, Anthony Tedde, Isabelle Dufrasne, Francoise Lessire, Bernard\
    \ Tychon, Yannick Curnel, Jerome\nBindelle, and Helene Soyeurt. Development of\
    \ Machine Learning Models to Predict Compressed Sward Height in\nWalloon Pastures\
    \ Based on Sentinel-1, Sentinel-2 and Meteorological Data Using Multiple Data\
    \ Transformations.\nREMOTE SENSING, 13(3), February 2021. doi: 10.3390/rs13030408.\n\
    Joachim Nyborg, Charlotte Pelletier, Sebastien Lefevre, and Ira Assent. TimeMatch:\
    \ Unsupervised cross-regionadap-\ntationbytemporalshiftestimation. ISPRSJOURNALOFPHOTOGRAMMETRY\
    \ ANDREMOTESENSING,188:\n301\u2013313,June 2022. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2022.04.018.\n\
    Stella Ofori-Ampofo, Charlotte Pelletier, and Stefan Lang. Crop Type Mapping from\
    \ Optical and Radar Time Series\nUsing Attention-Based Deep Learning. Remote Sensing,\
    \ 13(22):4668,January 2021. ISSN 2072-4292. doi: 10.3390/\nrs13224668.\nSubir\
    \ Paul, Mamta Kumari, C. S. Murthy, and D. Nagesh Kumar. Generating pre-harvest\
    \ crop maps by applying\nconvolutional neural network on multi-temporal Sentinel-1\
    \ data. INTERNATIONAL JOURNAL OF REMOTE\nSENSING, February 2022. ISSN 0143-1161.\
    \ doi: 10.1080/01431161.2022.2030072.\nMarko Pavlovic, Slobodan Ilic, Nenad Antonic,\
    \ and Dubravko Culibrk. Monitoring the impact of large transport\ninfrastructure\
    \ on land use and environment using deep learning and satellite imagery. REMOTE\
    \ SENSING, 14(10),\nMay 2022. doi: 10.3390/rs14102494.\nOscar D. Pedrayes, Dario\
    \ G. Lema, Daniel F. Garcia, Ruben Usamentiaga, and Angela Alonso. Evaluation\
    \ of Seman-\ntic Segmentation Methods for Land Use with Spectral Imaging Using\
    \ Sentinel-2 and PNOA Imagery. REMOTE\nSENSING, 13(12), June 2021. doi: 10.3390/rs13122292.\n\
    JoseM.Pena,PedroA.Gutierrez,CesarHervas-Martinez,JohanSix,RichardE.Plant,andFranciscaLopez-Granados.\n\
    Object-Based Image Classi\uFB01cation of Summer Crops with Machine Learning Methods.\
    \ REMOTE SENSING, 6(6):\n5019\u20135041,June 2014. doi: 10.3390/rs6065019.\nYiping\
    \ Peng, Zhenhua Liu, Chenjie Lin, Yueming Hu, Li Zhao, Runyan Zou, Ya Wen, and\
    \ Xiaoyun Mao. A new\nmethodforestimatingsoilfertilityusingextremegradientboostingandabackpropagationneuralnetwork.\
    \ REMOTE\nSENSING, 14(14), July 2022. doi: 10.3390/rs14143311.\n18C. Persello,\
    \ V. A. Tolpekin, J. R. Bergado, and R. A. de By. Delineation of agricultural\
    \ \uFB01elds in smallholder farms\nfrom satellite images using fully convolutional\
    \ networks and combinatorial grouping. REMOTE SENSING OF\nENVIRONMENT, 231, September\
    \ 2019. ISSN 0034-4257. doi: 10.1016/j.rse.2019.111253.\nStefano Pignatti, Ra\uFB00\
    aele Casa, Giovanni Laneve, Zhenhai Li, Linyi Liu, Pablo Marzialetti, Nada Mzid,\
    \ Simone Pas-\ncucci, Paolo Cosmo Silvestro, Massimo Tolomio, Deepak Upreti, Hao\
    \ Yang, Guijun Yang, and Wenjiang Huang.\nSino-EUEarthObservationData to Supportthe\
    \ Monitoring andManagementofAgriculturalResources. REMOTE\nSENSING, 13(15), August\
    \ 2021. doi: 10.3390/rs13152889.\nVera Potopova, Miroslav Trnka, Pavel Hamouz,\
    \ Josef Soukup, and Tudor Castravet. Statistical modelling of drought-\nrelatedyieldlossesusingsoilmoisture-vegetationremotesensingandmultiscalarindicesinthesouth-easternEurope.\n\
    AGRICULTURAL WATER MANAGEMENT, 236, June 2020. ISSN 0378-3774. doi: 10.1016/j.agwat.2020.106168.\n\
    GuanghuiQi,GengxingZhao,andXueXi. SoilSalinityInversionofWinterWheatAreasBasedonSatellite-Unmanned\n\
    AerialVehicle-GroundCollaborativeSysteminCoastaloftheYellowRiverDelta. SENSORS,20(22),November2020.\n\
    doi: 10.3390/s20226521.\nMengjiaQiao,XiaohuiHe,XijieCheng,PanleLi,HaotianLuo,ZhihuiTian,andHengliangGuo.ExploitingHierarchical\n\
    Features for CropYield PredictionBased on3-D ConvolutionalNeuralNetworks and MultikernelGaussianProcess.\n\
    IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,\n\
    14:4476\u20134489,2021. ISSN 1939-1404. doi: 10.1109/JSTARS.2021.3073149.\nF\xB4\
    elixQuintonandLoicLandrieu. CropRotationModelingforDeepLearning-BasedParcelClassi\uFB01\
    cationfromSatellite\nTime Series. Remote Sensing, 13(22):4599,January 2021. ISSN\
    \ 2072-4292. doi: 10.3390/rs13224599.\nSaman Rabiei, Ehsan Jalilvand, and Massoud\
    \ Tajrishy. A Method to Estimate Surface Soil Moisture and Map the\nIrrigated\
    \ Cropland Area Using Sentinel-1 and Sentinel-2 Data. Sustainability, 13(20):11355,\
    \ January 2021. ISSN\n2071-1050. doi: 10.3390/su132011355.\nFatemeh Rahimi-Ajdadi\
    \ and Mahdi Khani. Remote sensing-based detection of tea land losses: The case\
    \ of Lahijan,\nIran. REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT,23,August2021.\
    \ ISSN 2352-9385.\ndoi: 10.1016/j.rsase.2021.100568.\nMuhammad Moshiur Rahman,\
    \ Andrew Robson, and Mila Bristow. Exploring the Potential of High Resolution\n\
    WorldView-3 Imagery for Estimating Yield of Mango. REMOTE SENSING, 10(12), December\
    \ 2018. doi:\n10.3390/rs10121866.\nUsman Rauf, Waqar S. Qureshi, Hamid Jabbar,\
    \ Ayesha Zeb, Alina Mirza, Eisa Alanazi, Umar S. Khan, and Nasir\nRashid. A new\
    \ method for pixel classi\uFB01cation for rice variety identi\uFB01cation using\
    \ spectral and time series data from\nSentinel-2 satellite imagery. COMPUTERS\
    \ AND ELECTRONICS IN AGRICULTURE, 193, February 2022. ISSN\n0168-1699. doi: 10.1016/j.compag.2022.106731.\n\
    AnuviRawat,AnilKumar,PriyadarshiUpadhyay,andShashiKumar.Deeplearning-basedmodelsfortemporalsatellite\n\
    dataprocessing: Classi\uFB01cationofpaddytransplanted\uFB01elds. ECOLOGICAL INFORMATICS,61,March2021.\
    \ ISSN\n1574-9541. doi: 10.1016/j.ecoinf.2021.101214.\nAnuvi Rawat, Anil Kumar,\
    \ Priyadarshi Upadhyay, and Shashi Kumar. A Comparative Study of 1D-Convolutional\n\
    Neural Networks with Modi\uFB01ed Possibilistic c-Mean Algorithm for Mapping Transplanted\
    \ Paddy Fields Using Tem-\nporal Data. JOURNAL OF THE INDIAN SOCIETY OF REMOTE\
    \ SENSING, 2022. ISSN 0255-660X. doi:\n10.1007/s12524-020-01303-4.\nK. Richter,\
    \ C. Atzberger, F. Vuolo, P. Weihs, and G. D\u2019Urso. Experimental assessment\
    \ of the Sentinel-2 band setting\nfor RTM-based LAI retrieval of sugar beet and\
    \ maize. CANADIAN JOURNAL OF REMOTE SENSING, 35(3):\n230\u2013247,June 2009. ISSN\
    \ 0703-8992. doi: 10.5589/m09-010.\nAndresC.Rodriguez,RodrigoCayeDaudt,Stefano\
    \ D\u2019Aronco,KonradSchindler,andJanD.Wegner. RobustDamage\nEstimation of Typhoon\
    \ Goni on Coconut Crops with Sentinel-2 Imagery. REMOTE SENSING, 13(21), November\n\
    2021. doi: 10.3390/rs13214302.\nChao Ruan, Yingying Dong, Wenjiang Huang, Linsheng\
    \ Huang, Huichun Ye, Huiqin Ma, Anting Guo, and Yu Ren.\nPrediction of Wheat Stripe\
    \ Rust Occurrence with Time Series Sentinel-2 Images. AGRICULTURE-BASEL, 11(11),\n\
    November 2021. doi: 10.3390/agriculture11111079.\nMarc Ru\xDFwurm and Marco Koerner.\
    \ Self-attention for raw optical Satellite Time Series Classi\uFB01cation. ISPRS\
    \ JOUR-\nNAL OF PHOTOGRAMMETRY AND REMOTE SENSING, 169:421\u2013435, November\
    \ 2020. ISSN 0924-2716. doi:\n10.1016/j.isprsjprs.2020.06.006.\nMarc Ru\xDFwurm\
    \ and Marco K\xA8orner. Multi-Temporal Land Cover Classi\uFB01cation with Sequential\
    \ Recurrent Encoders.\nISPRS International Journal of Geo-Information, 7(4):129,\
    \ April 2018. ISSN 2220-9964. doi: 10.3390/ijgi7040129.\n19Marc Ru\xDFwurm, Charlotte\
    \ Pelletier, Maximilian Zollner, S\xB4ebastien Lef`evre, and Marco K\xA8orner.\
    \ BreizhCrops: A time\nseries dataset for crop type mapping. International Archives\
    \ of the Photogrammetry, Remote Sensing and Spatial\nInformation Sciences ISPRS\
    \ (2020), pages 1545\u20131551,2020. doi: 10.5194/isprs-archives-XLIII-B2-2020-1545-2020.\n\
    Vasit Sagan, Maitiniyazi Maimaitijiang, Sourav Bhadra, Matthew Maimaitiyiming,\
    \ Davis R. Brown, Paheding Sidike,\nand Felix B. Fritschi. Field-scale crop yield\
    \ prediction using multi-temporal WorldView-3 and PlanetScope satellite\ndata\
    \ and deep learning. ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING, 174:265\u2013\
    281,\nApril 2021. ISSN 0924-2716. doi: 10.1016/j.isprsjprs.2021.02.008.\nIedaDel\u2019\
    ArcoSanches,RaulQueirozFeitosa,PedroMarcoAchanccarayDiaz,MarinalvaDiasSoares,AlfredoJoseBar-\n\
    reto Luiz, Bruno Schultz, and Luis Eduardo Pinheiro Maurano. Campo Verde Database,\
    \ October 2017.\nEmanuele Santi, Simonetta Paloscia, Simone Pettinato, Claudia\
    \ Notarnicola, Luca Pasolli, and Alberto Pistocchi.\nComparison between SAR Soil\
    \ Moisture Estimates and Hydrological Model Simulations over the Scrivia Test\
    \ Site.\nREMOTE SENSING, 5(10):4961\u20134976,October 2013. doi: 10.3390/rs5104961.\n\
    Marciano Saraiva, Eglen Protas, Moises Salgado, and Carlos Souza Jr. Automatic\
    \ Mapping of Center Pivot Irrigation\nSystems from Satellite Images Using Deep\
    \ Learning. REMOTE SENSING, 12(3), February 2020. doi: 10.3390/\nrs12030558.\n\
    Ekrem Saralioglu and Oguz Gungor. Semantic segmentation of land cover from high\
    \ resolution multispectral satellite\nimages by spectral-spatial convolutional\
    \ neural network. GEOCARTO INTERNATIONAL, 37(2):657\u2013677,January\n2022. ISSN\
    \ 1010-6049. doi: 10.1080/10106049.2020.1734871.\nRai A. Schwalbert, Telmo Amado,\
    \ Geomar Corassa, Luan Pierre Pott, P. V. Vara Prasad, and Ignacio A. Ciampitti.\n\
    Satellite-based soybean yield forecast: Integrating machine learning and weather\
    \ data for improving crop yield\nprediction in southern Brazil. AGRICULTURAL AND\
    \ FOREST METEOROLOGY, 284, April 2020. ISSN 0168-\n1923. doi: 10.1016/j.agrformet.2019.107886.\n\
    I. P. Senanayake, I. Y. Yeo, J. P. Walker, and G. R. Willgoose. Estimating catchment\
    \ scale soil moisture at a high\nspatialresolution: Integratingremotesensingandmachinelearning.\
    \ SCIENCE OF THE TOTAL ENVIRONMENT,\n776, July 2021. ISSN 0048-9697. doi: 10.1016/j.scitotenv.2021.145924.\n\
    Alireza Shari\uFB01, Hadi Mahdipour, Elahe Moradi, and Aqil Tariq. Agricultural\
    \ Field Extraction with Deep Learning\nAlgorithm and Satellite Imagery. JOURNAL\
    \ OF THE INDIAN SOCIETY OF REMOTE SENSING, 2022. ISSN\n0255-660X. doi: 10.1007/s12524-021-01475-7.\n\
    RamC.Sharma. Countrywidemappingofplantecologicalcommunitieswith101legendsincludinglandcovertypesfor\n\
    the \uFB01rst time at 10 m resolution through convolutional learning of satellite\
    \ images. APPLIED SCIENCES-BASEL,\n12(14), July 2022. doi: 10.3390/app12147125.\n\
    Andrii Shelestov, Mykola Lavreniuk, Nataliia Kussul, Alexei Novikov, and Sergii\
    \ Skakun. Exploring Google Earth\nEngine Platform for Big Data Processing: Classi\uFB01\
    cation of Multi-Temporal Satellite Imagery for Crop Mapping.\nFRONTIERS IN EARTH\
    \ SCIENCE, 5:1\u201310,February 2017. doi: 10.3389/feart.2017.00017.\nPahedingSidike,VasitSagan,MaitiniyaziMaimaitijiang,MatthewMaimaitiyiming,NadiaShakoor,JoelBurken,Todd\n\
    Mockler,andFelixB.Fritschi. dPEN:DeepProgressivelyExpandedNetworkformappingheterogeneousagricultural\n\
    landscape using WorldView-3 satellite imagery. REMOTE SENSING OF ENVIRONMENT,\
    \ 221:756\u2013772,February\n2019. ISSN 0034-4257. doi: 10.1016/j.rse.2018.11.031.\n\
    Ying-Qiang Song, Xin Zhao, Hui-Yue Su, Bo Li, Yue-Ming Hu, and Xue-Sen Cui. Predicting\
    \ Spatial Variations in\nSoil Nutrients with Hyperspectral Remote Sensing at Regional\
    \ Scale. SENSORS, 18(9), September 2018. doi:\n10.3390/s18093086.\nLin Sun, Weiyan\
    \ Wang, Chen Jia, and Xirong Liu. Leaf area index remote sensing based on Deep\
    \ Belief Network\nsupportedbysimulationdata. INTERNATIONALJOURNALOF REMOTE SENSING,42(20):7637\u2013\
    7661,October\n2021. ISSN 0143-1161. doi: 10.1080/01431161.2021.1942584.\nDimitrios\
    \ Sykas, Maria Sdraka, Dimitrios Zografakis, and Ioannis Papoutsis. A sentinel-2\
    \ multiyear, multicountry\nbenchmark dataset for crop classi\uFB01cation and segmentation\
    \ with deep learning. IEEE JOURNAL OF SELECTED\nTOPICS IN APPLIED EARTH OBSERVATIONSANDREMOTE\
    \ SENSING,15:3323\u20133339,2022. ISSN1939-1404.\ndoi: 10.1109/JSTARS.2022.3164771.\n\
    Pengfei Tang, Peijun Du, Junshi Xia, Peng Zhang, and Wei Zhang. Channel Attention-Based\
    \ TemporalConvolutional\nNetwork for Satellite Image Time Series Classi\uFB01\
    cation. IEEE Geoscience and Remote Sensing Letters, 19:1\u20135,2022.\nISSN 1558-0571.\
    \ doi: 10.1109/LGRS.2021.3095505.\nMaryam Teimouri, Mehdi Mokhtarzade, Nicolas\
    \ Baghdadi, and Christian Heipke. Fusion of time-series optical and\nSAR images\
    \ using 3D convolutionalneural networksfor cropclassi\uFB01cation. GEOCARTO INTERNATIONAL,2022.\n\
    ISSN 1010-6049. doi: 10.1080/10106049.2022.2095446.\n20Nima Teimouri, Mads Dyrmann,\
    \ and Rasmus Nyholm Jorgensen. A Novel Spatio-Temporal FCN-LSTM Network for\n\
    RecognizingVariousCropTypesUsing Multi-TemporalRadarImages. REMOTE SENSING,11(8),April2019.\
    \ doi:\n10.3390/rs11080990.\nK. R. Thorp and D. Drajat. Deep machine learning\
    \ with Sentinel satellite data to map paddy rice production stages\nacrossWestJava,Indonesia.\
    \ REMOTE SENSINGOF ENVIRONMENT,265,November2021. ISSN0034-4257. doi:\n10.1016/j.rse.2021.112679.\n\
    Huiren Tian, PengxinWang, Kevin Tansey, Dong Han, Jingqi Zhang, Shuyu Zhang, and\
    \ Hongmei Li. A deep learning\nframework under attention mechanism for wheat yield\
    \ estimation using remotely sensed indices in the Guanzhong\nPlain, PR China.\
    \ INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMA-\nTION, 102,\
    \ October 2021. ISSN 1569-8432. doi: 10.1016/j.jag.2021.102375.\nJiri Tomicek,\
    \ Jan Misurec, and Petr Lukes. Prototyping a Generic Algorithm for Crop Parameter\
    \ Retrieval across the\nSeason Using Radiative Transfer Model Inversion and Sentinel-2\
    \ Satellite Observations. REMOTE SENSING, 13\n(18), September 2021. doi: 10.3390/rs13183659.\n\
    Akshar Tripathi, Reet Kamal Tiwari, and Surya Prakash Tiwari. A deep learning\
    \ multi-layer perceptron and remote\nsensingapproachforsoilhealthbasedcropyieldestimation.\
    \ INTERNATIONALJOURNALOF APPLIED EARTH\nOBSERVATIONANDGEOINFORMATION,113,September2022.\
    \ ISSN1569-8432.doi: 10.1016/j.jag.2022.102959.\nMehmet Ozgur Turkoglu, Stefano\
    \ D\u2019Aronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler,\
    \ and\nJanDirkWegner. Cropmappingfromimagetime series: Deeplearningwithmulti-scalelabelhierarchies.\
    \ REMOTE\nSENSING OF ENVIRONMENT, 264, October 2021. ISSN 0034-4257. doi: 10.1016/j.rse.2021.112603.\n\
    USDA. National Agricultural Statistics Service Cropland Data Layer. Published\
    \ crop-speci\uFB01c data layer [Online].\nAvailable at: https://nassgeodata.gmu.edu/CropScape/.USDA-NASS,\
    \ Washington, DC, 2022.\nRobin van der Schalie, Richard de Jeu, Nemesio Rodriguez-Fernandez,\
    \ Amen Al-Yaari, Yann Kerr, Jean-Pierre\nWigneron, Robert Parinussa, and Matthias\
    \ Drusch. The E\uFB00ect of Three Di\uFB00erent Data Fusion Approaches on the\n\
    Quality of Soil Moisture Retrievals from Multiple Passive Microwave Sensors. REMOTE\
    \ SENSING, 10(1), January\n2018. ISSN 2072-4292. doi: 10.3390/rs10010107.\nAleixandre\
    \ Verger, Frederic Baret, and Fernando Camacho. Optimal modalities for radiative\
    \ transfer-neural net-\nwork estimation of canopy biophysical characteristics:\
    \ Evaluation over an agricultural area with CHRIS/PROBA\nobservations. REMOTE\
    \ SENSING OF ENVIRONMENT, 115(2):415\u2013426, February 2011. ISSN 0034-4257.\
    \ doi:\n10.1016/j.rse.2010.09.012.\nShyamal S. Virnodkar, Vinod K. Pachghare,\
    \ Virupakshagouda C. Patil, and Sunil Kumar Jha. DenseResUNet: An\nArchitecture\
    \ to Assess Water-Stressed Sugarcane Crops from Sentinel-2 Satellite Imagery.\
    \ TRAITEMENT DU\nSIGNAL, 38(4):1131\u20131139,August 2021. ISSN 0765-0019. doi:\
    \ 10.18280/ts.380424.\nPradeep Wagle, Prasanna H. Gowda, Xiangming Xiao, and K.\
    \ C. Anup. Parameterizing ecosystem light use\ne\uFB03ciency and water use e\uFB03\
    ciency to estimate maize gross primary production and evapotranspiration using\n\
    MODIS EVI. AGRICULTURAL AND FOREST METEOROLOGY, 222:87\u201397, May 2016. ISSN\
    \ 0168-1923. doi:\n10.1016/j.agrformet.2016.03.009.\nFran\xB8cois Waldner and\
    \ Foivos I. Diakogiannis. Deep learning onedge: Extracting \uFB01eld boundaries\
    \ from satellite images\nwith a convolutional neural network. Remote Sensing of\
    \ Environment, 2019. doi: 10.1016/j.rse.2020.111741.\nFrancois Waldner, Foivos\
    \ I. Diakogiannis, Kathryn Batchelor, Michael Ciccotosto-Camp, Elizabeth Cooper-Williams,\n\
    Chris Herrmann, Gonzalo Mata, and Andrew Toovey. Detect, Consolidate, Delineate:\
    \ Scalable Mapping of Field\nBoundaries Using Satellite Images. REMOTE SENSING,\
    \ 13(11), June 2021. doi: 10.3390/rs13112197.\nHong Wang, Xianzhong Chen, Tianxiang\
    \ Zhang, Zhiyong Xu, and Jiangyun Li. CCTNet: Coupled CNN and trans-\nformer network\
    \ for crop segmentation of remote sensing images. REMOTE SENSING, 14(9), May 2022a.\
    \ doi:\n10.3390/rs14091956.\nLi Wang, Yong Zhou, Jingyi Liu, Yujie Liu, Qian Zuo,\
    \ and Qing Li. Exploring the potential of multispectral satellite\nimages for\
    \ estimating the contents of cadmium and lead in cropland: The e\uFB00ect of the\
    \ dimidiate pixel model and\nrandom forest. JOURNAL OF CLEANER PRODUCTION, 367,\
    \ September 2022b. ISSN 0959-6526. doi: 10.1016/\nj.jclepro.2022.132922.\nLijun\
    \ Wang, Jiayao Wang, Xiwang Zhang, Laigang Wang, and Fen Qin. Deep segmentation\
    \ and classi\uFB01cation of\ncomplex crops using multi-feature satellite imagery.\
    \ COMPUTERS AND ELECTRONICS IN AGRICULTURE,\n200, September 2022c. ISSN 0168-1699.\
    \ doi: 10.1016/j.compag.2022.107249.\nSherrie Wang, Stefania Di Tommaso, Joey\
    \ Faulkner, Thomas Friedel, Alexander Kennepohl, Rob Strey, and David B.\nLobell.\
    \ Mapping Crop Types in Southeast India with Smartphone Crowdsourcing and Deep\
    \ Learning. REMOTE\nSENSING, 12(18), September 2020a. doi: 10.3390/rs12182957.\n\
    21Xiaoping Wang, Fei Zhang, Jianli Ding, Hsiang-te Kung, Aamir Latif, and Verner\
    \ C. Johnson. Estimation of soil\nsalt content (SSC) in the Ebinur Lake Wetland\
    \ National Nature Reserve (ELWNNR), Northwest China, based on a\nBootstrap-BP\
    \ neural network model and optimal spectral indices. SCIENCE OF THE TOTAL ENVIRONMENT,\n\
    615:918\u2013930,February 2018. ISSN 0048-9697. doi: 10.1016/j.scitotenv.2017.10.025.\n\
    Xue Wang, Jiahua Zhang, Lan Xun, Jingwen Wang, Zhenjiang Wu, Malak Henchiri, Shichao\
    \ Zhang, Sha Zhang, Yun\nBai,ShanshanYang,ShuaishuaiLi,andXiangYu. Evaluatingthee\uFB00\
    ectivenessofmachinelearninganddeeplearning\nmodels combined time-series satellite\
    \ data for multiple crop types classi\uFB01cation over a large-scale region. REMOTE\n\
    SENSING, 14(10), May 2022d. doi: 10.3390/rs14102341.\nYumiao Wang, Zhou Zhang,\
    \ Luwei Feng, Qingyun Du, and Troy Runge. Combining Multi-Source Data and Machine\n\
    Learning Approaches to Predict Winter Wheat Yield in the Conterminous United States.\
    \ REMOTE SENSING, 12\n(8), April 2020b. doi: 10.3390/rs12081232.\nFernandoWatson-Hernandez,NataliaGomez-Calderon,andRouversonPereiradaSilva.Oilpalmyieldestimationbased\n\
    on vegetation and humidity indices generated from satellite images and machine\
    \ learning techniques. AGRIENGI-\nNEERING, 4(1):279\u2013291,March 2022. doi:\
    \ 10.3390/agriengineering4010019.\nAleksandra Wolanin, Gustau Camps-Valls, Luis\
    \ Gomez-Chova, Gonzalo Mateo-Garcia, Christiaan van der Tol, Yong-\nguangZhang,andLuisGuanter.\
    \ EstimatingcropprimaryproductivitywithSentinel-2andLandsat8usingmachine\nlearning\
    \ methods trained with radiative transfer simulations. REMOTE SENSING OF ENVIRONMENT,\
    \ 225:441\u2013\n457, May 2019. ISSN 0034-4257. doi: 10.1016/j.rse.2019.03.002.\n\
    Aleksandra Wolanin, Gonzalo Mateo-Garcia, Gustau Camps-Valls, Luis Gomez-Chova,\
    \ Michele Meroni, Gregory Du-\nveiller,YouLiangzhi,andLuisGuanter. Estimatingandunderstandingcropyields\
    \ withexplainabledeeplearningin\nthe Indian Wheat Belt. ENVIRONMENTAL RESEARCH\
    \ LETTERS, 15(2), February 2020. ISSN 1748-9326. doi:\n10.1088/1748-9326/ab68ac.\n\
    Lin Wu, Wenwen Qi, Zhengwei Guo, Jianhui Zhao, Huijin Yang, and Ning Li. Winter\
    \ wheat planting area extraction\nusing SARchangedetection. REMOTE SENSING LETTERS,\
    \ 12(10):951\u2013960,October2021. ISSN 2150-704X. doi:\n10.1080/2150704X.2021.1951873.\n\
    Qiong Wu, Yunxiang Jin, Yuhai Bao, Quansheng Hai, Ruirui Yan, Baorui Chen, Hongbin\
    \ Zhang, Baohui Zhang,\nZhenwang Li, Xiaoyu Li, and Xiaoping Xin. Comparison of\
    \ two inversion methods for leaf area index using HJ-1\nsatellite data in a temperate\
    \ meadow steppe. INTERNATIONAL JOURNAL OF REMOTE SENSING, 36(19-20,\nSI):5192\u2013\
    5207,October 2015. ISSN 0143-1161. doi: 10.1080/01431161.2015.1040135.\nBin Xie,\
    \ Hankui K. Zhang, and Jie Xue. Deep Convolutional Neural Network for Mapping\
    \ Smallholder Agriculture\nUsing High Spatial Resolution Satellite Image. SENSORS,\
    \ 19(10), May 2019. doi: 10.3390/s19102398.\nYiXie. CombiningCERES-Wheatmodel,Sentinel-2data,anddeeplearningmethodforwinterwheatyieldestimation.\n\
    International Journal of Remote Sensing, 43(2):630\u2013648, January 2022. ISSN\
    \ 0143-1161. doi: 10.1080/01431161.\n2022.2026521.\nYiXie andJianxiHuang. IntegrationofaCropGrowthModelandDeepLearningMethodsto\
    \ ImproveSatellite-Based\nYield Estimation of Winter Wheat in Henan Province,\
    \ China. REMOTE SENSING, 13(21), November 2021. doi:\n10.3390/rs13214372.\nJinfan\
    \ Xu, Yue Zhu, Renhai Zhong, Zhixian Lin, Jialu Xu, Hao Jiang, Jingfeng Huang,\
    \ Haifeng Li, and Tao Lin.\nDeepCropMapping: A multi-temporal deep learning approach\
    \ with improved spatial generalizability for dynamic\ncornandsoybeanmapping. REMOTE\
    \ SENSING OF ENVIRONMENT,247,September2020. ISSN0034-4257. doi:\n10.1016/j.rse.2020.111946.\n\
    Mengyuan Xu, Ning Yao, Haoxuan Yang, Jia Xu, Annan Hu, Luis Gustavo Goncalves\
    \ de Goncalves, and Gang Liu.\nDownscalingSMAPsoilmoistureusingawide&deeplearningmethodovertheContinentalUnitedStates.JOURNAL\n\
    OF HYDROLOGY,609, June 2022. ISSN 0022-1694. doi: 10.1016/j.jhydrol.2022.127784.\n\
    Shuting Yang, Lingjia Gu, Xiaofeng Li, Fang Gao, and Tao Jiang. Fully Automated\
    \ Classi\uFB01cation Method for Crops\nBasedonSpatiotemporalDeep-LearningFusionTechnology.\
    \ IEEE Transactions on Geoscience and Remote Sensing,\n60:1\u201316,2022. ISSN\
    \ 1558-0644. doi: 10.1109/TGRS.2021.3113014.\nLin Yuan, Jingcheng Zhang, Yeyin\
    \ Shi, Chenwei Nie, Liguang Wei, and Jihua Wang. Damage Mapping of Powdery\nMildew\
    \ in Winter Wheat with High-Resolution Satellite Image. REMOTE SENSING, 6(5):3611\u2013\
    3623, May 2014.\ndoi: 10.3390/rs6053611.\nFrancisco Zambrano, Anton Vrieling,\
    \ Andy Nelson, Michele Meroni, and Tsegaye Tadesse. Prediction of drought-\ninducedreductionofagriculturalproductivityinChilefromMODIS,rainfallestimates,andclimateoscillationindices.\n\
    REMOTE SENSING OF ENVIRONMENT, 219:15\u201330, December 2018. ISSN 0034-4257.\
    \ doi: 10.1016/j.rse.2018.\n10.006.\n22Mohammad Zeynoddin and Hossein Bonakdari.\
    \ Structural-optimized sequential deep learning methods for surface\nsoil moisture\
    \ forecasting, case study Quebec, Canada. NEURAL COMPUTING & APPLICATIONS, 2022.\
    \ ISSN\n0941-0643. doi: 10.1007/s00521-022-07529-2.\nBo Zhang, Bin Guo, Bin Zou,\
    \ Wei Wei, Yongzhi Lei, and Tianqi Li. Retrieving soil heavy metals concentrations\
    \ based\non GaoFen-5 hyperspectral satellite image at an opencast coal mine, Inner\
    \ Mongolia, China. ENVIRONMENTAL\nPOLLUTION, 300, May 2022. ISSN 0269-7491. doi:\
    \ 10.1016/j.envpol.2022.118981.\nChenZhang,LipingDi,PengyuHao,ZhengweiYang,LiLin,HaotengZhao,andLiyingGuo.\
    \ Rapidin-seasonmapping\nofcornandsoybeansusingmachine-learnedtrustedpixelsfromCroplandDataLayer.INTERNATIONALJOURNAL\n\
    OF APPLIED EARTH OBSERVATION AND GEOINFORMATION, 102, October 2021a. ISSN 1569-8432.\
    \ doi:\n10.1016/j.jag.2021.102374.\nChenxiao Zhang, Peng Yue, Liping Di, and ZhaoyanWu.\
    \ Automatic Identi\uFB01cation of Center Pivot Irrigation Systems\nfrom Landsat\
    \ Images Using Convolutional Neural Networks. AGRICULTURE-BASEL, 8(10), October\
    \ 2018. doi:\n10.3390/agriculture8100147.\nJing Zhang, Dongli Ji, Dong Du, Jinjie\
    \ Miao, Hongwei Liu, and Yaonan Bai. Temporal paradox in soil potassium\nestimations\
    \ using spaceborne multispectral imagery. CATENA, 194, November 2020a. ISSN 0341-8162.\
    \ doi: 10.\n1016/j.catena.2020.104771.\nLi Zhang, Xiaolei Lv, Qi Chen, Guangcai\
    \ Sun, and Jingchuan Yao. Estimation of Surface Soil Moisture during Corn\nGrowthStage\
    \ fromSAR and OpticalData Using a Combined Scattering Model. REMOTE SENSING, 12(11),June\n\
    2020b. doi: 10.3390/rs12111844.\nLiangliang Zhang, Zhao Zhang, Yuchuan Luo, Juan\
    \ Cao, and Fulu Tao. Combining Optical, Fluorescence, Thermal\nSatellite,andEnvironmentalDatatoPredictCounty-LevelMaizeYieldinChinaUsingMachineLearningApproaches.\n\
    REMOTE SENSING, 12(1), January 2020c. doi: 10.3390/rs12010021.\nLiangliang Zhang,\
    \ Zhao Zhang, Yuchuan Luo, Juan Cao, Ruizhi Xie, and Shaokun Li. Integrating satellite-derived\n\
    climatic and vegetation indices to predict smallholder maize yield using deep\
    \ learning. AGRICULTURAL AND\nFOREST METEOROLOGY, 311, December 2021b. ISSN 0168-1923.\
    \ doi: 10.1016/j.agrformet.2021.108666.\nXiaopingZhang,BoCheng,JinfenChen,andChenbinLiang.\
    \ High-ResolutionBoundaryRe\uFB01nedConvolutionalNeural\nNetwork for Automatic\
    \ Agricultural Greenhouses Extraction from GaoFen-2 Satellite Imageries. REMOTE\
    \ SENS-\nING, 13(21), November 2021c. doi: 10.3390/rs13214237.\nHongwei Zhao,\
    \ Zhongxin Chen, Hao Jiang, Wenlong Jing, Liang Sun, and Min Feng. Evaluation\
    \ of Three Deep\nLearning Models for Early Crop Classi\uFB01cation Using Sentinel-1A\
    \ Imagery Time Series-A Case Study in Zhanjiang,\nChina. REMOTE SENSING, 11(22),\
    \ November 2019. doi: 10.3390/rs11222673.\nHongwei Zhao, Sibo Duan, Jia Liu, Liang\
    \ Sun, and Louis Reymondin. Evaluation of Five Deep Learning Models for\nCrop\
    \ Type Mapping Using Sentinel-2 Time Series Images with Missing Information. REMOTE\
    \ SENSING, 13(14),\nJuly 2021. doi: 10.3390/rs13142790.\nWenzhi Zhao, Yang Qu,\
    \ Liqiang Zhang, and Kaiyuan Li. Spatial-aware SAR-optical time-series deep integration\n\
    for crop phenology tracking. REMOTE SENSING OF ENVIRONMENT, 276, July 2022. ISSN\
    \ 0034-4257. doi:\n10.1016/j.rse.2022.113046.\nYa\u2019nan Zhou, Jiancheng Luo,\
    \ Li Feng, Yingpin Yang, Yuehong Chen, and Wei Wu. Long-short-term-memory-based\n\
    crop classi\uFB01cation using high-resolution optical images and multi-temporal\
    \ SAR data. GISCIENCE & REMOTE\nSENSING, 56(8):1170\u20131191,November 2019. ISSN\
    \ 1548-1603. doi: 10.1080/15481603.2019.1628412.\n23"
  format: application/pdf
- content: "GoogleSearch Images Maps Play YouTube News Gmail Drive More \xBBWeb History\
    \ | Settings | Sign in\_Advanced searchGoogle offered in:  \u0939\u093F\u0928\u094D\
    \u0926\u0940 \u09AC\u09BE\u0982\u09B2\u09BE \u0C24\u0C46\u0C32\u0C41\u0C17\u0C41\
    \ \u092E\u0930\u093E\u0920\u0940 \u0BA4\u0BAE\u0BBF\u0BB4\u0BCD \u0A97\u0AC1\u0A9C\
    \u0AB0\u0ABE\u0AA4\u0AC0 \u0C95\u0CA8\u0CCD\u0CA8\u0CA1 \u0D2E\u0D32\u0D2F\u0D3E\
    \u0D33\u0D02 \u0A2A\u0A70\u0A1C\u0A3E\u0A2C\u0A40 AdvertisingBusiness SolutionsAbout\
    \ GoogleGoogle.co.in\xA9 2024 - Privacy - Terms   "
  name: https://www.google.com
model: llama3
name: Nayan
settings:
  language: english
  tone: friendly
